---
title: "Assignment 5: Space-Time Prediction of Bike Share Demand"
author: "Katie Knox"
date: "11-24-2025"
format: 
  html:
    code-fold: false
    toc: true
    toc-location: left
    theme: cosmo
    embed-resources: true
execute:
  warning: false
  message: false
---

## Part 1: Q4 (October - December) 2024 Data

I have chosen to examine Q4 data from 2024 (last year) as we are currently in Q4 of 2025 as of writing, and I believe last year's patterns for this time of year would be best to inform predictions for Q4 2025. 

```{r}
#| echo: false
#| warning: false
#| output: false

library(tidyverse)
library(sf)
library(dplyr)
library(lubridate)
library(tigris)
library(tidycensus)
library(viridis)
library(riem)
library(gridExtra)
library(knitr)
library(kableExtra)
library(riem)  # For Philadelphia weather from ASOS stations
library(here)
library(patchwork)
# Get rid of scientific notation. We gotta look good!
options(scipen = 999)

census_api_key("42bf8a20a3df1def380f330cf7edad0dd5842ce6")
```

```{r themes}
plotTheme <- theme(
  plot.title = element_text(size = 14, face = "bold"),
  plot.subtitle = element_text(size = 10),
  plot.caption = element_text(size = 8),
  axis.text.x = element_text(size = 10, angle = 45, hjust = 1),
  axis.text.y = element_text(size = 10),
  axis.title = element_text(size = 11, face = "bold"),
  panel.background = element_blank(),
  panel.grid.major = element_line(colour = "#D0D0D0", size = 0.2),
  panel.grid.minor = element_blank(),
  axis.ticks = element_blank(),
  legend.position = "right"
)

mapTheme <- theme(
  plot.title = element_text(size = 14, face = "bold"),
  plot.subtitle = element_text(size = 10),
  plot.caption = element_text(size = 8),
  axis.line = element_blank(),
  axis.text = element_blank(),
  axis.ticks = element_blank(),
  axis.title = element_blank(),
  panel.background = element_blank(),
  panel.border = element_blank(),
  panel.grid.major = element_line(colour = 'transparent'),
  panel.grid.minor = element_blank(),
  legend.position = "right",
  plot.margin = margin(1, 1, 1, 1, 'cm'),
  legend.key.height = unit(1, "cm"),
  legend.key.width = unit(0.2, "cm")
)

palette5 <- c("#eff3ff", "#bdd7e7", "#6baed6", "#3182bd", "#08519c")
```

```{r load_indego}
# Read Q4 2024 data
indego <- read_csv("../data/indego-trips-2024-q4.csv")

# Quick look at the data
glimpse(indego)
```
#### Explore Data

```{r explore_data}
# How many trips?
cat("Total trips in Q4 2024:", nrow(indego), "\n")

# How many unique stations?
cat("Unique start stations:", length(unique(indego$start_station)), "\n")

# Trip types
table(indego$trip_route_category)

# Passholder types
table(indego$passholder_type)

# Bike types
table(indego$bike_type)
```

#### Time Bins

```{r create_time_bins}
indego <- indego %>%
  mutate(
    # Parse datetime
    start_datetime = mdy_hm(start_time),
    end_datetime = mdy_hm(end_time),
    
    # Create hourly bins
    interval60 = floor_date(start_datetime, unit = "hour"),
    
    # Extract time features
    week = week(interval60),
    month = month(interval60, label = TRUE),
    dotw = wday(interval60, label = TRUE),
    hour = hour(interval60),
    date = as.Date(interval60),
    
    # Create useful indicators
    weekend = ifelse(dotw %in% c("Sat", "Sun"), 1, 0),
    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)
  )

# Look at temporal features
head(indego %>% select(start_datetime, interval60, week, dotw, hour, weekend))
```

#### Trips Over Time

```{r trips_over_time}
# Daily trip counts
daily_trips <- indego %>%
  group_by(date) %>%
  summarize(trips = n())

ggplot(daily_trips, aes(x = date, y = trips)) +
  geom_line(color = "#3182bd", linewidth = 1) +
  geom_smooth(se = FALSE, color = "red", linetype = "dashed") +
  labs(
    title = "Indego Daily Ridership - Q4 2024",
    subtitle = "Fall demand patterns in Philadelphia",
    x = "Date",
    y = "Daily Trips",
    caption = "Source: Indego bike share"
  ) +
  plotTheme
```
**Ridership falls during autumn to winter transition.** There is also a particularly low ridership towards the end of November, perhaps November 28th, Thanksgiving 2024, as well as the end of December, likely December 25th, Christmas. We can confirm this intuition by examining those specific dates. 

```{r}
turkey_day <- daily_trips %>% filter(date == "2024-11-28")
xmas <- daily_trips %>% filter(date == "2024-12-25")

typical_boring_thurs <- indego %>%
  filter(dotw == "Thu", date != "2024-11-28") %>%
  group_by(date) %>%
  summarize(trips = n()) %>%
  summarize(avg_thurs_trips = mean(trips))

typical_boring_wed <- indego %>%
  filter(dotw == "Wed", date != "2024-12-25") %>%
  group_by(date) %>%
  summarize(trips = n()) %>%
  summarize(avg_wed_trips = mean(trips))


print(turkey_day)
print(typical_boring_thurs)

print(xmas)
print(typical_boring_wed)

```
#### Hourly Patterns

```{r hourly_patterns}
# Average trips by hour and day type
hourly_patterns <- indego %>%
  group_by(hour, weekend) %>%
  summarize(avg_trips = n() / n_distinct(date)) %>%
  mutate(day_type = ifelse(weekend == 1, "Weekend", "Weekday"))

ggplot(hourly_patterns, aes(x = hour, y = avg_trips, color = day_type)) +
  geom_line(linewidth = 1.2) +
  scale_color_manual(values = c("Weekday" = "#08519c", "Weekend" = "#6baed6")) +
  labs(
    title = "Average Hourly Ridership Patterns",
    subtitle = "Clear commute patterns on weekdays",
    x = "Hour of Day",
    y = "Average Trips per Hour",
    color = "Day Type"
  ) +
  plotTheme
```
**Weekdays see two peaks during prime work commute hours,** whereas weekends see a smooth curve of average hourly trips throughout daylight hours, peaking around mid afternoon. 

#### Top Stations

```{r top_stations}
# Most popular origin stations
top_stations <- indego %>%
  count(start_station, start_lat, start_lon, name = "trips") %>%
  arrange(desc(trips))

top_stations%>%head(20)%>%
kable(
      caption = "Top 20 Indego Stations by Trip Origins",
      format.args = list(big.mark = ",")) %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

#### Load Philadelphia Census Data


```{r load_census}
#| echo: false
#| warning: false
#| output: false

# Get Philadelphia census tracts
philly_census <- get_acs(
  geography = "tract",
  variables = c(
    "B01003_001",  # Total population
    "B19013_001",  # Median household income
    "B08301_001",  # Total commuters
    "B08301_010",  # Commute by transit
    "B02001_002",  # White alone
    "B25077_001"   # Median home value
  ),
  state = "PA",
  county = "Philadelphia",
  year = 2022,
  geometry = TRUE,
  output = "wide"
) %>%
  rename(
    Total_Pop = B01003_001E,
    Med_Inc = B19013_001E,
    Total_Commuters = B08301_001E,
    Transit_Commuters = B08301_010E,
    White_Pop = B02001_002E,
    Med_Home_Value = B25077_001E
  ) %>%
  mutate(
    Percent_Taking_Transit = (Transit_Commuters / Total_Commuters) * 100,
    Percent_White = (White_Pop / Total_Pop) * 100
  ) %>%
  st_transform(crs = 4326)  # WGS84 for lat/lon matching

# Check the data
glimpse(philly_census)
```
#### Map Philadelphia Context

```{r map_philly}
# Map median income
ggplot() +
  geom_sf(data = philly_census, aes(fill = Med_Inc), color = NA) +
  scale_fill_viridis(
    option = "viridis",
    name = "Median\nIncome",
    labels = scales::dollar
  ) +
  labs(
    title = "Philadelphia Median Household Income by Census Tract",
    subtitle = "Context for understanding bike share demand patterns"
  ) +
  # Stations 
  geom_point(
    data = top_stations,
    aes(x = start_lon, y = start_lat, color = trips),
    size = 0.75, alpha = 0.6
  ) +
  scale_color_gradientn(
    colours = c("#FAFF89", "#D3321D"),
    name = "Trips\nOriginating at Station"
  )  +
  guides(
    fill = guide_colorbar(),
    color = guide_colorbar()
  ) +
  theme(
    legend.position = "bottom",
    legend.box = "horizontal"     # <-- puts them side by side
  ) +
  mapTheme
```
#### Join Census Data to Stations

```{r join_census_to_stations}
# Create sf object for stations
stations_sf <- indego %>%
  distinct(start_station, start_lat, start_lon) %>%
  filter(!is.na(start_lat), !is.na(start_lon)) %>%
  st_as_sf(coords = c("start_lon", "start_lat"), crs = 4326)

# Spatial join to get census tract for each station
stations_census <- st_join(stations_sf, philly_census, left = TRUE) %>%
  st_drop_geometry()

# Look at the result - investigate whether all of the stations joined to census data -- according to the map above there are stations in non-residential tracts.

stations_for_map <- indego %>%
  distinct(start_station, start_lat, start_lon) %>%
  filter(!is.na(start_lat), !is.na(start_lon)) %>%
  left_join(
    stations_census %>% select(start_station, Med_Inc),
    by = "start_station"
  ) %>%
  mutate(has_census = !is.na(Med_Inc))

summary(stations_for_map$has_census)
```

```{r}
# Add back to trip data
indego_census <- indego %>%
  left_join(
    stations_census %>% 
      select(start_station, Med_Inc, Percent_Taking_Transit, 
             Percent_White, Total_Pop),
    by = "start_station"
  )


# Prepare data for visualization
stations_for_map <- indego %>%
  distinct(start_station, start_lat, start_lon) %>%
  filter(!is.na(start_lat), !is.na(start_lon)) %>%
  left_join(
    stations_census %>% select(start_station, Med_Inc),
    by = "start_station"
  ) %>%
  mutate(has_census = !is.na(Med_Inc))

# Create the map showing problem stations
ggplot() +
  geom_sf(data = philly_census, aes(fill = Med_Inc), color = "white", size = 0.1) +
  scale_fill_viridis(
    option = "viridis",
    name = "Median\nIncome",
    labels = scales::dollar,
    na.value = "grey90"
  ) +
  # Stations with census data (small grey dots)
  geom_point(
    data = stations_for_map %>% filter(has_census),
    aes(x = start_lon, y = start_lat),
    color = "grey30", size = 1, alpha = 0.6
  ) +
  # Stations WITHOUT census data (red X marks the spot)
  geom_point(
    data = stations_for_map %>% filter(!has_census),
    aes(x = start_lon, y = start_lat),
    color = "red", size = 1, shape = 4, stroke = 1.5
  ) +
  labs(
    title = "Philadelphia Median Household Income by Census Tract",
    subtitle = "Indego stations shown (RED = no census data match)",
    caption = "Red X marks indicate stations that didn't join to census tracts"
  ) +
  mapTheme



```

```{r}
# Identify which stations to keep
valid_stations <- stations_census %>%
  filter(!is.na(Med_Inc)) %>%
  pull(start_station)

# Filter trip data to valid stations only
indego_census <- indego %>%
  filter(start_station %in% valid_stations) %>%
  left_join(
    stations_census %>% 
      select(start_station, Med_Inc, Percent_Taking_Transit, 
             Percent_White, Total_Pop),
    by = "start_station"
  )

```

#### Get Weather Data

```{r get_weather}
# Get weather from Philadelphia International Airport (KPHL)
# This covers Q4 2024: October 1 - December 31
weather_data <- riem_measures(
  station = "PHL",  # Philadelphia International Airport
  date_start = "2024-10-01",
  date_end = "2024-12-31"
)

# Process weather data
weather_processed <- weather_data %>%
  mutate(
    interval60 = floor_date(valid, unit = "hour"),
    Temperature = tmpf,  # Temperature in Fahrenheit
    Precipitation = ifelse(is.na(p01i), 0, p01i),  # Hourly precip in inches
    Wind_Speed = sknt  # Wind speed in knots
  ) %>%
  select(interval60, Temperature, Precipitation, Wind_Speed) %>%
  distinct()

# Check for missing hours and interpolate if needed
weather_complete <- weather_processed %>%
  complete(interval60 = seq(min(interval60), max(interval60), by = "hour")) %>%
  fill(Temperature, Precipitation, Wind_Speed, .direction = "down")

# Look at the weather
summary(weather_complete %>% select(Temperature, Precipitation, Wind_Speed))
```

#### Visualize Weather Patterns

```{r visualize_weather}
ggplot(weather_complete, aes(x = interval60, y = Temperature)) +
  geom_line(color = "#3182bd", alpha = 0.7) +
  geom_smooth(se = FALSE, color = "red") +
  labs(
    title = "Philadelphia Temperature - Q1 2025",
    subtitle = "Winter to early spring transition",
    x = "Date",
    y = "Temperature (°F)"
  ) +
  plotTheme
```
#### Create Space-Time Panel: Aggregate Trips to Station-Hour Level

```{r aggregate_trips}
# Count trips by station-hour
trips_panel <- indego_census %>%
  group_by(interval60, start_station, start_lat, start_lon,
           Med_Inc, Percent_Taking_Transit, Percent_White, Total_Pop) %>%
  summarize(Trip_Count = n()) %>%
  ungroup()

# How many station-hour observations?
nrow(trips_panel)

# How many unique stations?
length(unique(trips_panel$start_station))

# How many unique hours?
length(unique(trips_panel$interval60))
```
#### Create Complete Panel Structure

```{r complete_panel}
# Calculate expected panel size
n_stations <- length(unique(trips_panel$start_station))
n_hours <- length(unique(trips_panel$interval60))
expected_rows <- n_stations * n_hours

cat("Expected panel rows:", format(expected_rows, big.mark = ","), "\n")
cat("Current rows:", format(nrow(trips_panel), big.mark = ","), "\n")
cat("Missing rows:", format(expected_rows - nrow(trips_panel), big.mark = ","), "\n")
```

```{r}
# Create complete panel
study_panel <- expand.grid(
  interval60 = unique(trips_panel$interval60),
  start_station = unique(trips_panel$start_station)
) %>%
  # Join trip counts
  left_join(trips_panel, by = c("interval60", "start_station")) %>%
  # Replace NA trip counts with 0
  mutate(Trip_Count = replace_na(Trip_Count, 0))

# Fill in station attributes (they're the same for all hours)
station_attributes <- trips_panel %>%
  group_by(start_station) %>%
  summarize(
    start_lat = first(start_lat),
    start_lon = first(start_lon),
    Med_Inc = first(Med_Inc),
    Percent_Taking_Transit = first(Percent_Taking_Transit),
    Percent_White = first(Percent_White),
    Total_Pop = first(Total_Pop)
  )

study_panel <- study_panel %>%
  left_join(station_attributes, by = "start_station")

# Verify we have complete panel
cat("Complete panel rows:", format(nrow(study_panel), big.mark = ","), "\n")
```
#### Add Time Features

```{r add_time_features}
study_panel <- study_panel %>%
  mutate(
    week = week(interval60),
    month = month(interval60, label = TRUE),
    dotw = wday(interval60, label = TRUE),
    hour = hour(interval60),
    date = as.Date(interval60),
    weekend = ifelse(dotw %in% c("Sat", "Sun"), 1, 0),
    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)
  )
```

#### Join Weather Data

```{r join_weather}
study_panel <- study_panel %>%
  left_join(weather_complete, by = "interval60")

# Check for missing values
summary(study_panel %>% select(Trip_Count, Temperature, Precipitation))
```

#### Create Temporal Lag Variables

```{r create_lags}
# Sort by station and time
study_panel <- study_panel %>%
  arrange(start_station, interval60)

# Create lag variables WITHIN each station
study_panel <- study_panel %>%
  group_by(start_station) %>%
  mutate(
    lag1Hour = lag(Trip_Count, 1),
    lag2Hours = lag(Trip_Count, 2),
    lag3Hours = lag(Trip_Count, 3),
    lag12Hours = lag(Trip_Count, 12),
    lag1day = lag(Trip_Count, 24)
  ) %>%
  ungroup()

# Remove rows with NA lags (first 24 hours for each station)
study_panel_complete <- study_panel %>%
  filter(!is.na(lag1day))

cat("Rows after removing NA lags:", format(nrow(study_panel_complete), big.mark = ","), "\n")
```

#### Visualize Lag Correlations

```{r lag_correlations}
# Sample one station to visualize
example_station <- study_panel_complete %>%
  filter(start_station == 3212) %>%
  head(168)  # One week

# Plot actual vs lagged demand
ggplot(example_station, aes(x = interval60)) +
  geom_line(aes(y = Trip_Count, color = "Current"), linewidth = 1) +
  geom_line(aes(y = lag1Hour, color = "1 Hour Ago"), linewidth = 1, alpha = 0.7) +
  geom_line(aes(y = lag1day, color = "24 Hours Ago"), linewidth = 1, alpha = 0.7) +
  scale_color_manual(values = c(
    "Current" = "#08519c",
    "1 Hour Ago" = "#F09B4E",
    "24 Hours Ago" = "#D3321D"
  )) +
  labs(
    title = "Temporal Lag Patterns at One Station",
    subtitle = "Past demand predicts future demand",
    x = "Date-Time",
    y = "Trip Count",
    color = "Time Period"
  ) +
  plotTheme
```
#### Temporal Train/Test Split

**Approach:** Train on weeks 1-9, test on weeks 10-13 (predicting future from past)

```{r temporal_split}
# Split by week
# Q4 has weeks 40-53 (Oct-Dec)
# Train on weeks 40-49 (Oct 1 - early December)
# Test on weeks 50-53 (rest of December)

# Which stations have trips in BOTH early and late periods?
early_stations <- study_panel_complete %>%
  filter(week < 50) %>%
  filter(Trip_Count > 0) %>%
  distinct(start_station) %>%
  pull(start_station)

late_stations <- study_panel_complete %>%
  filter(week >= 50) %>%
  filter(Trip_Count > 0) %>%
  distinct(start_station) %>%
  pull(start_station)

# Keep only stations that appear in BOTH periods
common_stations <- intersect(early_stations, late_stations)

# Filter panel to only common stations
study_panel_complete <- study_panel_complete %>%
  filter(start_station %in% common_stations)

# NOW create train/test split
train <- study_panel_complete %>%
  filter(week < 50)

test <- study_panel_complete %>%
  filter(week >= 50)

cat("Training observations:", format(nrow(train), big.mark = ","), "\n")
cat("Testing observations:", format(nrow(test), big.mark = ","), "\n")
cat("Training date range:", min(train$date), "to", max(train$date), "\n")
cat("Testing date range:", min(test$date), "to", max(test$date), "\n")
```

#### Model 1: Baseline (Time + Weather)

```{r model1}

# Create day of week factor with treatment (dummy) coding
train <- train %>%
  mutate(dotw_simple = factor(dotw, levels = c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun")))

# Set contrasts to treatment coding (dummy variables)
contrasts(train$dotw_simple) <- contr.treatment(7)

# Now run the model
model1 <- lm(
  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation,
  data = train
)

summary(model1)
```
**Patterns:**

- Tuesday and Wednesday have positive coefficients (0.066 and 0.063) 
- Thursday through Sunday have negative coefficients
- Tuesday has the highest weekday effect (+0.066)
- This might be a reflection of concentrated commuting patterns at the beginning of the week, and towards the end of the work week there may be more flexible hyrib or work from jobs influencing fewer trips than a Monday. 

**Hourly Patterns**

Hour   Coefficient   Interpretation
0      (baseline)    0.000 trips/hour (midnight)
1      -0.055       slightly fewer than midnight
...
5      +0.039       morning activity starting
...
8      +0.941       PEAK morning rush
...
10     +0.562       post-rush
...
17     +1.110       PEAK evening rush
...
23     +0.076       late night minimal

#### Model 2: Add Temporal Lags

```{r model2}
model2 <- lm(
  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +
    lag1Hour + lag3Hours + lag1day,
  data = train
)

summary(model2)
```
**Adding lags improve R² by about 20 percentage points.** This is likely because the state of the Indego station an hour or a few hours before affects how many trips can be taken hours later, and the one day lag likely accounts for the peaks and ebs at the same time a day before, so it makes sense that this model can account for more of the variance in the data. 

#### Model 3: Add Demographics

```{r model3}
model3 <- lm(
  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +
    lag1Hour + lag3Hours + lag1day +
    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y,
  data = train
)

summary(model3)
```
#### Model 4: Add Station Fixed Effects

```{r model4}
model4 <- lm(
  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +
    lag1Hour + lag3Hours + lag1day +
    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y +
    as.factor(start_station),
  data = train
)

# Summary too long with all station dummies, just show key metrics
cat("Model 4 R-squared:", summary(model4)$r.squared, "\n")
cat("Model 4 Adj R-squared:", summary(model4)$adj.r.squared, "\n")
```
#### Model 5: Add Rush Hour Interaction

```{r model5}
model5 <- lm(
  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +
    lag1Hour + lag3Hours + lag1day + rush_hour + as.factor(month) +
    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y +
    as.factor(start_station) +
    rush_hour * weekend,  # Rush hour effects different on weekends
  data = train
)

cat("Model 5 R-squared:", summary(model5)$r.squared, "\n")
cat("Model 5 Adj R-squared:", summary(model5)$adj.r.squared, "\n")
```
#### Model Evaluation: Calculate Predictions and MAE

```{r calculate_mae}
# Get predictions on test set

# Create day of week factor with treatment (dummy) coding
test <- test %>%
  mutate(dotw_simple = factor(dotw, levels = c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun")))

# Set contrasts to treatment coding (dummy variables)
contrasts(test$dotw_simple) <- contr.treatment(7)

test <- test %>%
  mutate(
    pred1 = predict(model1, newdata = test),
    pred2 = predict(model2, newdata = test),
    pred3 = predict(model3, newdata = test),
    pred4 = predict(model4, newdata = test),
    pred5 = predict(model5, newdata = test)
  )

# Calculate MAE for each model
mae_results <- data.frame(
  Model = c(
    "1. Time + Weather",
    "2. + Temporal Lags",
    "3. + Demographics",
    "4. + Station FE",
    "5. + Rush Hour Interaction"
  ),
  MAE = c(
    mean(abs(test$Trip_Count - test$pred1), na.rm = TRUE),
    mean(abs(test$Trip_Count - test$pred2), na.rm = TRUE),
    mean(abs(test$Trip_Count - test$pred3), na.rm = TRUE),
    mean(abs(test$Trip_Count - test$pred4), na.rm = TRUE),
    mean(abs(test$Trip_Count - test$pred5), na.rm = TRUE)
  )
)

kable(mae_results, 
      digits = 2,
      caption = "Mean Absolute Error by Model (Test Set)",
      col.names = c("Model", "MAE (trips)")) %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```
**Temporal Lags improved the model the most;** the biggest drop in mean absolute error was from the model accounting for time of day, day of week, and weather, and then adding in the temporal lags. In fact, adding demographics made the model perform worse than the baseline model, as well as adding station fixed effects and interaction effects on top of that. 

**Compared to Q1 2025:**

The MAE values for Q4 2024 are fairly similar across the models. I believe this might be because both quarters account for season changes into winter (Q4) and out of winter (Q1) that make it harder to predict bike share in the latter part of the quarter based on the first, even when taking into account weather effects. There are also a high concentration of winter holidays that likely affect bike travel in Q4, such as Thanksgiving and Winter Break holidays, and in Q1 New Years, Valentine's Day, and Spring Break holidays. 

## Part 2: Error Analysis 

#### Observed vs. Predicted Error Analysis

```{r obs_vs_pred}
test <- test %>%
  mutate(
    error = Trip_Count - pred2,
    abs_error = abs(error),
    time_of_day = case_when(
      hour < 7 ~ "Overnight",
      hour >= 7 & hour < 10 ~ "AM Rush",
      hour >= 10 & hour < 15 ~ "Mid-Day",
      hour >= 15 & hour <= 18 ~ "PM Rush",
      hour > 18 ~ "Evening"
    )
  )

# Scatter plot by time and day type
ggplot(test, aes(x = Trip_Count, y = pred2)) +
  geom_point(alpha = 0.2, color = "#3182bd") +
  geom_abline(slope = 1, intercept = 0, color = "red", linewidth = 1) +
  geom_smooth(method = "lm", se = FALSE, color = "darkgreen") +
  facet_grid(weekend ~ time_of_day) +
  labs(
    title = "Observed vs. Predicted Bike Trips",
    subtitle = "Model 2 performance by time period",
    x = "Observed Trips",
    y = "Predicted Trips",
    caption = "Red line = perfect predictions; Green line = actual model fit"
  ) +
  plotTheme
```

**The model consistently under predicts trips on weekdays, weekends, at all time periods of the day.** The one period that appears to be moderately better predicted is the AM Rush period of weekdays, and generally slightly better at predicting weekdays than weekends. However, the consistent under-predicting seems to signify there is a major driver of Indego trips that this model does not account for well. 

#### Spatial Error Patterns

```{r spatial_errors}
# Calculate MAE by station
station_errors <- test %>%
  group_by(start_station, start_lat.x, start_lon.y) %>%
  summarize(
    MAE = mean(abs_error, na.rm = TRUE),
    avg_demand = mean(Trip_Count, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  filter(!is.na(start_lat.x), !is.na(start_lon.y))

## Create Two Maps Side-by-Side with Proper Legends (sorry these maps are ugly)

# Calculate station errors
station_errors <- test %>%
  filter(!is.na(pred2)) %>%
  group_by(start_station, start_lat.x, start_lon.y) %>%
  summarize(
    MAE = mean(abs(Trip_Count - pred2), na.rm = TRUE),
    avg_demand = mean(Trip_Count, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  filter(!is.na(start_lat.x), !is.na(start_lon.y))

# Map 1: Prediction Errors
p1 <- ggplot() +
  geom_sf(data = philly_census, fill = "grey95", color = "white", size = 0.2) +
  geom_point(
    data = station_errors,
    aes(x = start_lon.y, y = start_lat.x, color = MAE),
    size = 3.5,
    alpha = 0.7
  ) +
  scale_color_viridis(
    option = "plasma",
    name = "MAE\n(trips)",
    direction = -1,
    breaks = c(0.5, 1.0, 1.5),  # Fewer, cleaner breaks
    labels = c("0.5", "1.0", "1.5")
  ) +
  labs(title = "Prediction Errors",
       subtitle = "Higher in Center City") +
  mapTheme +
  theme(
    legend.position = "right",
    legend.title = element_text(size = 10, face = "bold"),
    legend.text = element_text(size = 9),
    plot.title = element_text(size = 14, face = "bold"),
    plot.subtitle = element_text(size = 10)
  ) +
  guides(color = guide_colorbar(
    barwidth = 1.5,
    barheight = 12,
    title.position = "top",
    title.hjust = 0.5
  ))

# Map 2: Average Demand
p2 <- ggplot() +
  geom_sf(data = philly_census, fill = "grey95", color = "white", size = 0.2) +
  geom_point(
    data = station_errors,
    aes(x = start_lon.y, y = start_lat.x, color = avg_demand),
    size = 3.5,
    alpha = 0.7
  ) +
  scale_color_viridis(
    option = "viridis",
    name = "Avg\nDemand",
    direction = -1,
    breaks = c(0.5, 1.0, 1.5, 2.0, 2.5),  # Clear breaks
    labels = c("0.5", "1.0", "1.5", "2.0", "2.5")
  ) +
  labs(title = "Average Demand",
       subtitle = "Trips per station-hour") +
  mapTheme +
  theme(
    legend.position = "right",
    legend.title = element_text(size = 10, face = "bold"),
    legend.text = element_text(size = 9),
    plot.title = element_text(size = 14, face = "bold"),
    plot.subtitle = element_text(size = 10)
  ) +
  guides(color = guide_colorbar(
    barwidth = 1.5,
    barheight = 12,
    title.position = "top",
    title.hjust = 0.5
  ))

p1 | p2

```
**Higher MAEs are clustered around center city, where trips per hour are also higher on average.** This nuances our understanding of the model's under-performance overall, as we can see that MAEs are not equal across all stations but higher error gaps where there are higher trips. This indicates that there are spatial variables that this model lacks. 

#### Temporal Error Patterns

```{r temporal_errors}
# MAE by time of day and day type
temporal_errors <- test %>%
  group_by(time_of_day, weekend) %>%
  summarize(
    MAE = mean(abs_error, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(day_type = ifelse(weekend == 1, "Weekend", "Weekday"))

ggplot(temporal_errors, aes(x = time_of_day, y = MAE, fill = day_type)) +
  geom_col(position = "dodge") +
  scale_fill_manual(values = c("Weekday" = "#08519c", "Weekend" = "#6baed6")) +
  labs(
    title = "Prediction Errors by Time Period",
    subtitle = "When is the model struggling most?",
    x = "Time of Day",
    y = "Mean Absolute Error (trips)",
    fill = "Day Type"
  ) +
  plotTheme +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
**MAEs are higher for weekdays than weekends on average,** but combined with the previous plots of observed vs predicted values, this shows that the mean absolute errors partially higher for weekdays because of higher trip counts on weekdays typically than weekends, and higher trip counts during that AM and PM rush. In other words, this again confirms that the model is creating predictions that are too uniform accross time and space. 

#### Errors and Demographics

```{r errors_demographics}
# Join demographic data to station errors
station_errors_demo <- station_errors %>%
  left_join(
    station_attributes %>% select(start_station, Med_Inc, Percent_Taking_Transit, Percent_White),
    by = "start_station"
  ) %>%
  filter(!is.na(Med_Inc))

# Create plots
inc_plot <- ggplot(station_errors_demo, aes(x = Med_Inc, y = MAE)) +
  geom_point(alpha = 0.5, color = "#3182bd") +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  scale_x_continuous(labels = scales::dollar) +
  labs(title = "Errors vs. Median Income", x = "Median Income", y = "MAE") +
  plotTheme

transit_plot <- ggplot(station_errors_demo, aes(x = Percent_Taking_Transit, y = MAE)) +
  geom_point(alpha = 0.5, color = "#3182bd") +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  labs(title = "Errors vs. Transit Usage", x = "% Taking Transit", y = "MAE") +
  plotTheme

white_plot <- ggplot(station_errors_demo, aes(x = Percent_White, y = MAE)) +
  geom_point(alpha = 0.5, color = "#3182bd") +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  labs(title = "Errors vs. Race", x = "% White", y = "MAE") +
  plotTheme

grid.arrange(inc_plot, transit_plot, white_plot, ncol = 2)
```
**Prediction errors are higher for higher income and more White areas, but lower for higher transit-taking areas.** This again tracks with the general under-performance of the model, as percent White and median income are slightly positively correlated with trips and percent using transit is slightly negatively correlated with trips.

## Part 3: Feature Engineering & model improvement

After observing the error results from the first five models, I believe the biggest aspects the models are missing are spatial variables that influence bike share usage. Seeing as the under-counting is clustered around center city, I think some likely attributes of center city that make biking more attractive is the relative nearness of start and end destinations to each other (~80% of trips are under 1.5 miles). In other words, I think the model would be a better predictor if it took into account the potential rider's available close-by destination bike stations they could park the bike within the average trip length that riders take. Additionally, I think people are more likely to feel comfortable biking when there are bikes lanes nearby or roads with a low posted speed limit. I also want to build off the success of adding the spatial lags that improved model 1 to model 2 so much, and add another lag for the same hour in the previous week.

```{r average trip length}

# Step 1: Build LINESTRING geometry for each row
trips_sf <- indego %>%
  filter(
    !is.na(start_lat),
    !is.na(start_lon),
    !is.na(end_lat),
    !is.na(end_lon)
  )%>%
  rowwise() %>%
  mutate(
    geometry = list(
      st_linestring(
        matrix(
          c(start_lon, start_lat,
            end_lon,   end_lat),
          ncol = 2,
          byrow = TRUE
        )
      )
    )
  ) %>%
  ungroup() %>%
  st_as_sf(crs = 4326)


# Step 2: Transform to PA South (meters)
trips_sf <- st_transform(trips_sf, 6539)


# Step 3: Calculate trip distance (meters)
trips_sf <- trips_sf %>%
  mutate(distance_f = st_length(geometry))

trips_sf <- trips_sf %>%
  mutate(
    distance_mi = as.numeric(distance_f) / 5280  # 1 mile = 5280 ft
  )

summary(trips_sf$distance_mi)
```

**Spatial features:**

- Number of low-speed roads near station
- Number and type of Bike lanes near station
- Nearness of station to other stations 

```{r get roads and bike lanes}
roads_sf <- st_read("../data/RMSADMIN_(Administrative_Classifications_of_Roadway)/RMSADMIN_(Administrative_Classifications_of_Roadway).shp")

blanes_sf <- st_read("../data/Bike_Network/Bike_Network.shp")

# filter to just roadways in Phildelphia County under 25 mph 
# Phildelphia CTY CODE is 67
roads_sf<-roads_sf%>%filter(
  CTY_CODE == 67, 
  SPEED_LIMI<=25
)

roads_sf<-roads_sf%>%
  st_transform(st_crs(stations_sf))%>%
  mutate(label="Road <25mph")

blanes_sf<-blanes_sf%>%
  st_transform(st_crs(stations_sf))%>%
  mutate(label="Bike Lane")

stations_sf<-stations_sf%>%mutate(
  label="Indego Station"
)

# map with stations
ggplot() +
  geom_sf(data = roads_sf, aes(color = label), linewidth = 0.1) +
  geom_sf(data = blanes_sf, aes(color = label), linewidth = 0.1) +
  geom_sf(data = stations_sf, aes(color = label), size = 0.7, alpha = 0.7) +
  scale_color_manual(
    name = "Legend",
    values = c(
      "Road <25mph" = "#bdd7e7",
      "Bike Lane" = "#F09B4E",
      "Indego Station" = "#08519c"
    )
  ) +
  labs(title = "Indego Stations, Bike Lanes, and <25mph Roads") +
  mapTheme +
  theme(
    legend.position = "right",
    legend.title = element_text(size = 10, face = "bold"),
    legend.text = element_text(size = 9)
  )

```
```{r join to station buffers}
stations_buffered <- stations_sf %>%
  mutate(buffer_geom = st_buffer(geometry, dist = 500))

# ---- Count roads intersecting each buffer ----
road_counts <- st_intersects(stations_buffered$buffer_geom, roads_sf) %>%
  lengths()

# ---- Count bike lanes intersecting each buffer ----
blane_counts <- st_intersects(stations_buffered$buffer_geom, blanes_sf) %>%
  lengths()

# ---- Add results back onto stations_sf ----
stations_sf <- stations_sf %>%
  mutate(
    nearby_roads  = road_counts,
    nearby_bikelanes = blane_counts
  )

ggplot() +
  geom_sf(data = roads_sf, color="lightgray", linewidth = 0.1) +
  geom_sf(data = stations_sf, aes(color = nearby_bikelanes), size = 0.7, alpha = 0.7) +
  labs(title = "Stations Colored by Number of Nearby Bike Lanes") +
  mapTheme +
  theme(
    legend.position = "right",
    legend.title = element_text(size = 10, face = "bold"),
    legend.text = element_text(size = 9)
  )
```

In addition to nearby bike lanes and slow roads, I will add the number of other bike stations within a buffer of the median trip distance of 0.9063 miles.  

```{r add other stations}
# 0.9063 miles = 1458.54847 meters

stations_buffered <- stations_sf %>%
  mutate(buffer_geom = st_buffer(geometry, dist = 1458.54847))

# ---- Count indego stations intersecting each buffer ----
station_counts <- st_intersects(stations_buffered$buffer_geom, stations_sf) %>%
  lengths()

# ---- Add results back onto stations_sf ----
stations_sf <- stations_sf %>%
  mutate(
    nearby_stations  = station_counts
  )

ggplot() +
  geom_sf(data = roads_sf, color="lightgray", linewidth = 0.1) +
  geom_sf(data = stations_sf, aes(color = nearby_stations), size = 0.7, alpha = 0.7) +
  labs(title = "Stations Colored by Number of Nearby Other Stations") +
  mapTheme +
  theme(
    legend.position = "right",
    legend.title = element_text(size = 10, face = "bold"),
    legend.text = element_text(size = 9)
  )

```

```{r add to panel}
# Add back to trip data
study_panel <- study_panel %>%
  left_join(
    stations_sf %>% 
      select(start_station, nearby_roads, nearby_bikelanes, nearby_stations),
    by = "start_station"
  )
```

**Trip history features:**

- Add lag for same hour last week

```{r add week lag}
study_panel <- study_panel %>%
  group_by(start_station) %>%
  mutate(
    lag1week = lag(Trip_Count, 168)
  ) %>%
  ungroup()

# Remove rows with NA lags (first 24 hours for each station)
study_panel_complete <- study_panel %>%
  filter(!is.na(lag1week) & !is.na(lag1day))

cat("Rows after removing NA lags:", format(nrow(study_panel_complete), big.mark = ","), "\n")
```

#### Model 6: Add nearby spatial features and 1-week lag

```{r recreate train test split}
study_panel_complete <- study_panel_complete %>%
  filter(start_station %in% common_stations)

# NOW create train/test split
train <- study_panel_complete %>%
  filter(week < 50)

test <- study_panel_complete %>%
  filter(week >= 50)

train <- train %>%
  mutate(dotw_simple = factor(dotw, levels = c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun")))

# Set contrasts to treatment coding (dummy variables)
contrasts(train$dotw_simple) <- contr.treatment(7)

test <- test %>%
  mutate(dotw_simple = factor(dotw, levels = c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun")))

# Set contrasts to treatment coding (dummy variables)
contrasts(test$dotw_simple) <- contr.treatment(7)

cat("Training observations:", format(nrow(train), big.mark = ","), "\n")
cat("Testing observations:", format(nrow(test), big.mark = ","), "\n")
cat("Training date range:", min(train$date), "to", max(train$date), "\n")
cat("Testing date range:", min(test$date), "to", max(test$date), "\n")
```


```{r model 6}
model6 <- lm(
  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +
    lag1Hour + lag3Hours + lag1day + rush_hour + as.factor(month) +
    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y +
    as.factor(start_station) +
    rush_hour * weekend +  # Rush hour effects different on weekends
    nearby_roads + nearby_bikelanes + nearby_stations +
    lag1week,
  data = train
)

cat("Model 6 R-squared:", summary(model6)$r.squared, "\n")
cat("Model 6 Adj R-squared:", summary(model6)$adj.r.squared, "\n")

```

```{r build off model 2}
model7 <- lm(
  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +
    lag1Hour + lag3Hours + lag1day + lag1week + as.factor(month) +week+
    nearby_roads + nearby_bikelanes + nearby_stations,
  data = train
)

summary(model7)
```
```{r test}
test <- test %>%
  mutate(
    pred2 = predict(model2, newdata = test),
    pred6 = predict(model6, newdata = test),
    pred7 = predict(model7, newdata = test)
  )

# Calculate MAE for each model
mae_results <- data.frame(
  Model = c(
    "2. + Temporal Lags",
    "6. Model 2 + Demographics + Station FE + Rush Hour Interaction + Week Lag + Nearby Features",
    "7. Model 2 + Week Lag + Nearby Features"
  ),
  MAE = c(
    mean(abs(test$Trip_Count - test$pred2), na.rm = TRUE),
    mean(abs(test$Trip_Count - test$pred6), na.rm = TRUE),
    mean(abs(test$Trip_Count - test$pred7), na.rm = TRUE)
  )
)

kable(mae_results, 
      digits = 2,
      caption = "Mean Absolute Error by Model (Test Set)",
      col.names = c("Model", "MAE (trips)")) %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```
```{r}
test <- test %>%
  mutate(
    error = Trip_Count - pred7,
    abs_error = abs(error),
    time_of_day = case_when(
      hour < 7 ~ "Overnight",
      hour >= 7 & hour < 10 ~ "AM Rush",
      hour >= 10 & hour < 15 ~ "Mid-Day",
      hour >= 15 & hour <= 18 ~ "PM Rush",
      hour > 18 ~ "Evening"
    )
  )

# Scatter plot by time and day type
ggplot(test, aes(x = Trip_Count, y = pred7)) +
  geom_point(alpha = 0.2, color = "#3182bd") +
  geom_abline(slope = 1, intercept = 0, color = "red", linewidth = 1) +
  geom_smooth(method = "lm", se = FALSE, color = "darkgreen") +
  facet_grid(weekend ~ time_of_day) +
  labs(
    title = "Observed vs. Predicted Bike Trips",
    subtitle = "Model 2 performance by time period",
    x = "Observed Trips",
    y = "Predicted Trips",
    caption = "Red line = perfect predictions; Green line = actual model fit"
  ) +
  plotTheme
```
```{r}
# Calculate MAE by station
station_errors <- test %>%
  group_by(start_station, start_lat.x, start_lon.y) %>%
  summarize(
    MAE = mean(abs_error, na.rm = TRUE),
    avg_demand = mean(Trip_Count, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  filter(!is.na(start_lat.x), !is.na(start_lon.y))

## Create Two Maps Side-by-Side with Proper Legends (sorry these maps are ugly)

# Calculate station errors
station_errors <- test %>%
  filter(!is.na(pred7)) %>%
  group_by(start_station, start_lat.x, start_lon.y) %>%
  summarize(
    MAE = mean(abs(Trip_Count - pred6), na.rm = TRUE),
    avg_demand = mean(Trip_Count, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  filter(!is.na(start_lat.x), !is.na(start_lon.y))

# Map 1: Prediction Errors
p1.1 <- ggplot() +
  geom_sf(data = philly_census, fill = "grey95", color = "white", size = 0.2) +
  geom_point(
    data = station_errors,
    aes(x = start_lon.y, y = start_lat.x, color = MAE),
    size = 3.5,
    alpha = 0.7
  ) +
  scale_color_viridis(
    option = "plasma",
    name = "MAE\n(trips)",
    direction = -1,
    breaks = c(0.5, 1.0, 1.5),  # Fewer, cleaner breaks
    labels = c("0.5", "1.0", "1.5")
  ) +
  labs(title = "Prediction Errors ",
       subtitle = "Model 7") +
  mapTheme +
  theme(
    legend.position = "right",
    legend.title = element_text(size = 10, face = "bold"),
    legend.text = element_text(size = 9),
    plot.title = element_text(size = 14, face = "bold"),
    plot.subtitle = element_text(size = 10)
  ) +
  guides(color = guide_colorbar(
    barwidth = 1.5,
    barheight = 12,
    title.position = "top",
    title.hjust = 0.5
  ))

p1 | p1.1
```
**Model 7 MAEs are less severe in the areas just west and north of center city, however the patterns largely follow the same spatial distribution as model 2. 


**Poisson Model**

```{r poisson model}

p_model <- glm(
  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +
    lag1Hour + lag3Hours + lag1day + lag1week + as.factor(month) +week+
    nearby_roads + nearby_bikelanes + nearby_stations,
  data = train,
  family = poisson(link = "log")
)

summary(p_model)
```
```{r poisson predictions}

test <- test %>%
  mutate(
    p_pred = predict(p_model, newdata = test, type = "response")
  )

# Calculate MAE for each model
mae_results <- data.frame(
  Model = c(
    "2. + Temporal Lags",
    "6. Model 2 + Demographics + Station FE + Rush Hour Interaction + Week Lag + Nearby Features",
    "7. Model 2 + Week Lag + Nearby Features",
    "Poisson Model (Same Variables as Model 7)"
  ),
  MAE = c(
    mean(abs(test$Trip_Count - test$pred2), na.rm = TRUE),
    mean(abs(test$Trip_Count - test$pred6), na.rm = TRUE),
    mean(abs(test$Trip_Count - test$pred7), na.rm = TRUE),
    mean(abs(test$Trip_Count - test$p_pred), na.rm = TRUE)
  )
)

kable(mae_results, 
      digits = 2,
      caption = "Mean Absolute Error by Model (Test Set)",
      col.names = c("Model", "MAE (trips)")) %>%
  kable_styling(bootstrap_options = c("striped", "hover"))

```
**The Poisson Model does not improve MAE very much, however it does not result in any negative predictions,** which inherently makes it a better method for predicting trip counts in this context.

## Part 4: Critical Reflection 

Overall, I would not recommend using any of the models produced in this study in order to predict real, exact bike station counts, however they could be useful rather in posing questions for further research into what factors affect bike station use the most, and how to make more accurate predictions at the extremes while not foregoing less busy stations. The models presented in this study all fell very short of the highest traffic station-times, and these are essential to get right in a usable model because identifying them will equate to predicting where the bulk of the bikes are at a given time in order to make redistribution more efficient. The factors that improved the model the most were time lags, meaning that the trips from a station at various times previous to the current time had a strong predictive effect, however it could be that the influence of these variables makes the model less adequate at predicting the extremes of trips. In other words, the time lags create a model that is more normalized over time, but the key to a useful model would be in predicting the more extreme trip counts that will have higher redistribution needs. The spatial distribution of prediction errors is not particularly egregious from a visual inspection of the map. 

The biggest takeaway is that predicting bike share station usage by hour would benefit from additional complexity that is able to model the more extreme ends of bike share usage, perhaps using morning and evening rush as factor variables in addition to the hour of the day as a factor variable. Another aspect that might help in future iterations is accounting for holidays, again as a factor variable marking if the day is a holiday or not. Even if there is future improvement on the model, caution should be used on irregular public events or extreme weather events that will significantly skew bike trips in an unpredictable way. 








