---
title: Week 5 Notes
date: 2025-10-06
editor:
  markdown:
    wrap: 72
---
## Notes

#### Linear Regression Week!

General Problem: We observe data and we believe there's some relationship between these variables. **Statistical Learning** = a set of approaches for estimating that relationship. 

Formalizing the Relationship: For response `Y` and predicators `X_1, X_2,...X_n`:
`Y = f(X) + E` where `E` is error term. 

What is `f()`? -- the true relationship between predictors and outcome, fixed but unknown 

- We want to know `f()` not only to predict `Y`, but to learn about/infer relationship between `X`s
- Two broad approaches: 
	- **Parametric** 
		- make and assumption about the form, i.e. predefine the shape the the slope, easier to interpret, reduces problem to estimating a few parameters
		- unintuitively perhaps, modern AI is parametric, just with an insane number of parameters 
	- **Non-parametric**
		- doesn't assume a form, it's about find the best bit line, requires more data and is a bit harder to interpret 

#### Linear Regression (parametric approach)
- Assumption: Relationship between `x` and `y` is linear
- Task : What are coefficients `B` in `Y = B_1X_1 + B_2X_2 ... `
- Method: Ordinary Least Squares
- Why? Simple, well-understood
- In R : `lm(Y ~ X, data = data)`

Interpreting coefficients: 

- `B_0` is intercept, i.e. what is dependent variable when independent is 0 
- `B_1` is slope
- Recall, all stats is based on sample, we never have full universe of data. 
- True relationship is unknowable, but based on different samples, we may get relationships more or less close to unknowable true relationship. 
- Null hypothesis: The relationship actually 0, we get absolutely no information about `Y` from `X`.
- So, "statistical significance" is saying there is enough evidence to disprove null hypothesis 
- How we do this: how weird would the data sample have to be for null hypothesis to be true? 
- Is relationship real? p-value is the probability that the null hypothesis is true given the sample. We are looking for small p-values. 

#### How good is this model? 
- For inference, how explanatory is model relationship between `X` and `Y` -- R-squared tells us how fitting the line is to sample. 
- For prediction, how well would model fit new data? R-squared alone does not tell us if model is trustworthy 
- **overfitting** -- model is too good at predicting one sample, R-squared is crazy good, "following noise" essentially, won't generalize well though to other samples 
- **underfitting** -- model ignores the relationship entirely, low R-squared
- perfect fit -- "the gist of things"

#### Train/Test Split 
- Solution: hold out some data to test predictions 
	- say we have 67 counties in PA, train model on 70% of sample, test on 30%
- `set.seed()` will preserve random selection if you run code multiple times 

#### Evaluation Predictions 
- Root means square errors, RMSE -- i.e. "our predictions are off the real observations by RMSE units" -- is this good enough? 

#### Cross Validation 
- how well does models apply to new datasets?
- K-fold cross-validation - fold the 30/70 split at different segments and run train/test on each one, average RMSE across all 
- in R: `library(caret)` functions `trainControl()` sets a cross-validation method with number of folds, `train()` creates mode based on data and the object returned from `trainControl()`

#### Checking Assumptions 
- Linear regression makes assumptions, if violated: 
	- coefficients may be biased
	- SE may be wrong
		- heteroscedasticity -- variance changes across X 
		- formal test: Breusch-Pagan test, p<.05 bad 

![heteroscedasticity](Pasted%20image%2020251006120758.png)


predictions unreliable 

Normality of residuals
- Solution Q-Q Plot 

no multicollinearity 
- `vif()`

outliers 

#### Improving the Model
- add more features/variables
- create categorical variables 

#### Summary Workflow
1. understand the framework
2. visualize first
3. fit the model
4. evaluate performance (cross validation)
5. check assumptions
6. improve model if needed
7. consider ethics (who could be harmed?)


