{
  "hash": "12a68bb7fd0d556cdb4532c47bd578e2",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Assignment 5: Space-Time Prediction of Bike Share Demand\"\nauthor: \"Katie Knox\"\ndate: \"11-24-2025\"\nformat: \n  html:\n    code-fold: false\n    toc: true\n    toc-location: left\n    theme: cosmo\n    embed-resources: true\nexecute:\n  warning: false\n  message: false\n---\n\n\n\n## Part 1: Q4 (October - December) 2024 Data\n\nI have chosen to examine Q4 data from 2024 (last year) as we are currently in Q4 of 2025 as of writing, and I believe last year's patterns for this time of year would be best to inform predictions for Q4 2025. \n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplotTheme <- theme(\n  plot.title = element_text(size = 14, face = \"bold\"),\n  plot.subtitle = element_text(size = 10),\n  plot.caption = element_text(size = 8),\n  axis.text.x = element_text(size = 10, angle = 45, hjust = 1),\n  axis.text.y = element_text(size = 10),\n  axis.title = element_text(size = 11, face = \"bold\"),\n  panel.background = element_blank(),\n  panel.grid.major = element_line(colour = \"#D0D0D0\", size = 0.2),\n  panel.grid.minor = element_blank(),\n  axis.ticks = element_blank(),\n  legend.position = \"right\"\n)\n\nmapTheme <- theme(\n  plot.title = element_text(size = 14, face = \"bold\"),\n  plot.subtitle = element_text(size = 10),\n  plot.caption = element_text(size = 8),\n  axis.line = element_blank(),\n  axis.text = element_blank(),\n  axis.ticks = element_blank(),\n  axis.title = element_blank(),\n  panel.background = element_blank(),\n  panel.border = element_blank(),\n  panel.grid.major = element_line(colour = 'transparent'),\n  panel.grid.minor = element_blank(),\n  legend.position = \"right\",\n  plot.margin = margin(1, 1, 1, 1, 'cm'),\n  legend.key.height = unit(1, \"cm\"),\n  legend.key.width = unit(0.2, \"cm\")\n)\n\npalette5 <- c(\"#eff3ff\", \"#bdd7e7\", \"#6baed6\", \"#3182bd\", \"#08519c\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Read Q4 2024 data\nindego <- read_csv(\"../data/indego-trips-2024-q4.csv\")\n\n# Quick look at the data\nglimpse(indego)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 299,121\nColumns: 15\n$ trip_id             <dbl> 1050296434, 1050293063, 1050296229, 1050276817, 10…\n$ duration            <dbl> 22, 8, 12, 1, 5, 9, 5, 6, 16, 16, 16, 39, 6, 40, 1…\n$ start_time          <chr> \"10/1/2024 0:00\", \"10/1/2024 0:06\", \"10/1/2024 0:0…\n$ end_time            <chr> \"10/1/2024 0:22\", \"10/1/2024 0:14\", \"10/1/2024 0:1…\n$ start_station       <dbl> 3322, 3166, 3007, 3166, 3075, 3166, 3030, 3010, 33…\n$ start_lat           <dbl> 39.93638, 39.97195, 39.94517, 39.97195, 39.96718, …\n$ start_lon           <dbl> -75.15526, -75.13445, -75.15993, -75.13445, -75.16…\n$ end_station         <dbl> 3375, 3017, 3244, 3166, 3102, 3008, 3203, 3163, 33…\n$ end_lat             <dbl> 39.96036, 39.98003, 39.93865, 39.97195, 39.96759, …\n$ end_lon             <dbl> -75.14020, -75.14371, -75.16674, -75.13445, -75.17…\n$ bike_id             <chr> \"03580\", \"05386\", \"18082\", \"02729\", \"18519\", \"0272…\n$ plan_duration       <dbl> 365, 365, 365, 1, 30, 1, 365, 365, 30, 30, 30, 30,…\n$ trip_route_category <chr> \"One Way\", \"One Way\", \"One Way\", \"Round Trip\", \"On…\n$ passholder_type     <chr> \"Indego365\", \"Indego365\", \"Indego365\", \"Walk-up\", …\n$ bike_type           <chr> \"standard\", \"standard\", \"electric\", \"standard\", \"e…\n```\n\n\n:::\n:::\n\n\n#### Explore Data\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# How many trips?\ncat(\"Total trips in Q4 2024:\", nrow(indego), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTotal trips in Q4 2024: 299121 \n```\n\n\n:::\n\n```{.r .cell-code}\n# How many unique stations?\ncat(\"Unique start stations:\", length(unique(indego$start_station)), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nUnique start stations: 256 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Trip types\ntable(indego$trip_route_category)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n   One Way Round Trip \n    282675      16446 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Passholder types\ntable(indego$passholder_type)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  Day Pass   Indego30  Indego365 IndegoFlex       NULL    Walk-up \n     10711     159895     112690          1       1165      14659 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Bike types\ntable(indego$bike_type)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nelectric standard \n  175503   123618 \n```\n\n\n:::\n:::\n\n\n\n#### Time Bins\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nindego <- indego %>%\n  mutate(\n    # Parse datetime\n    start_datetime = mdy_hm(start_time),\n    end_datetime = mdy_hm(end_time),\n    \n    # Create hourly bins\n    interval60 = floor_date(start_datetime, unit = \"hour\"),\n    \n    # Extract time features\n    week = week(interval60),\n    month = month(interval60, label = TRUE),\n    dotw = wday(interval60, label = TRUE),\n    hour = hour(interval60),\n    date = as.Date(interval60),\n    \n    # Create useful indicators\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  )\n\n# Look at temporal features\nhead(indego %>% select(start_datetime, interval60, week, dotw, hour, weekend))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 6\n  start_datetime      interval60           week dotw   hour weekend\n  <dttm>              <dttm>              <dbl> <ord> <int>   <dbl>\n1 2024-10-01 00:00:00 2024-10-01 00:00:00    40 Tue       0       0\n2 2024-10-01 00:06:00 2024-10-01 00:00:00    40 Tue       0       0\n3 2024-10-01 00:06:00 2024-10-01 00:00:00    40 Tue       0       0\n4 2024-10-01 00:06:00 2024-10-01 00:00:00    40 Tue       0       0\n5 2024-10-01 00:07:00 2024-10-01 00:00:00    40 Tue       0       0\n6 2024-10-01 00:08:00 2024-10-01 00:00:00    40 Tue       0       0\n```\n\n\n:::\n:::\n\n\n\n#### Trips Over Time\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Daily trip counts\ndaily_trips <- indego %>%\n  group_by(date) %>%\n  summarize(trips = n())\n\nggplot(daily_trips, aes(x = date, y = trips)) +\n  geom_line(color = \"#3182bd\", linewidth = 1) +\n  geom_smooth(se = FALSE, color = \"red\", linetype = \"dashed\") +\n  labs(\n    title = \"Indego Daily Ridership - Q4 2024\",\n    subtitle = \"Fall demand patterns in Philadelphia\",\n    x = \"Date\",\n    y = \"Daily Trips\",\n    caption = \"Source: Indego bike share\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](Knox_Katie_Assignment5_files/figure-html/trips_over_time-1.png){width=672}\n:::\n:::\n\n\n**Ridership falls during autumn to winter transition.** There is also a particularly low ridership towards the end of November, perhaps November 28th, Thanksgiving 2024, as well as the end of December, likely December 25th, Christmas. We can confirm this intuition by examining those specific dates. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nturkey_day <- daily_trips %>% filter(date == \"2024-11-28\")\nxmas <- daily_trips %>% filter(date == \"2024-12-25\")\n\ntypical_boring_thurs <- indego %>%\n  filter(dotw == \"Thu\", date != \"2024-11-28\") %>%\n  group_by(date) %>%\n  summarize(trips = n()) %>%\n  summarize(avg_thurs_trips = mean(trips))\n\ntypical_boring_wed <- indego %>%\n  filter(dotw == \"Wed\", date != \"2024-12-25\") %>%\n  group_by(date) %>%\n  summarize(trips = n()) %>%\n  summarize(avg_wed_trips = mean(trips))\n\n\nprint(turkey_day)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 2\n  date       trips\n  <date>     <int>\n1 2024-11-28   604\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(typical_boring_thurs)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 1\n  avg_thurs_trips\n            <dbl>\n1           3634.\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(xmas)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 2\n  date       trips\n  <date>     <int>\n1 2024-12-25   495\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(typical_boring_wed)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 1\n  avg_wed_trips\n          <dbl>\n1         3845.\n```\n\n\n:::\n:::\n\n\n#### Hourly Patterns\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Average trips by hour and day type\nhourly_patterns <- indego %>%\n  group_by(hour, weekend) %>%\n  summarize(avg_trips = n() / n_distinct(date)) %>%\n  mutate(day_type = ifelse(weekend == 1, \"Weekend\", \"Weekday\"))\n\nggplot(hourly_patterns, aes(x = hour, y = avg_trips, color = day_type)) +\n  geom_line(linewidth = 1.2) +\n  scale_color_manual(values = c(\"Weekday\" = \"#08519c\", \"Weekend\" = \"#6baed6\")) +\n  labs(\n    title = \"Average Hourly Ridership Patterns\",\n    subtitle = \"Clear commute patterns on weekdays\",\n    x = \"Hour of Day\",\n    y = \"Average Trips per Hour\",\n    color = \"Day Type\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](Knox_Katie_Assignment5_files/figure-html/hourly_patterns-1.png){width=672}\n:::\n:::\n\n\n**Weekdays see two peaks during prime work commute hours,** whereas weekends see a smooth curve of average hourly trips throughout daylight hours, peaking around mid afternoon. \n\n#### Top Stations\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Most popular origin stations\ntop_stations <- indego %>%\n  count(start_station, start_lat, start_lon, name = \"trips\") %>%\n  arrange(desc(trips))\n\ntop_stations%>%head(20)%>%\nkable(\n      caption = \"Top 20 Indego Stations by Trip Origins\",\n      format.args = list(big.mark = \",\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Top 20 Indego Stations by Trip Origins</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> start_station </th>\n   <th style=\"text-align:right;\"> start_lat </th>\n   <th style=\"text-align:right;\"> start_lon </th>\n   <th style=\"text-align:right;\"> trips </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 3,010 </td>\n   <td style=\"text-align:right;\"> 39.94711 </td>\n   <td style=\"text-align:right;\"> -75.16618 </td>\n   <td style=\"text-align:right;\"> 5,943 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,032 </td>\n   <td style=\"text-align:right;\"> 39.94527 </td>\n   <td style=\"text-align:right;\"> -75.17971 </td>\n   <td style=\"text-align:right;\"> 4,471 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,359 </td>\n   <td style=\"text-align:right;\"> 39.94888 </td>\n   <td style=\"text-align:right;\"> -75.16978 </td>\n   <td style=\"text-align:right;\"> 3,923 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,244 </td>\n   <td style=\"text-align:right;\"> 39.93865 </td>\n   <td style=\"text-align:right;\"> -75.16674 </td>\n   <td style=\"text-align:right;\"> 3,492 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,295 </td>\n   <td style=\"text-align:right;\"> 39.95028 </td>\n   <td style=\"text-align:right;\"> -75.16027 </td>\n   <td style=\"text-align:right;\"> 3,411 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,020 </td>\n   <td style=\"text-align:right;\"> 39.94855 </td>\n   <td style=\"text-align:right;\"> -75.19007 </td>\n   <td style=\"text-align:right;\"> 3,369 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,208 </td>\n   <td style=\"text-align:right;\"> 39.95048 </td>\n   <td style=\"text-align:right;\"> -75.19324 </td>\n   <td style=\"text-align:right;\"> 3,343 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,066 </td>\n   <td style=\"text-align:right;\"> 39.94561 </td>\n   <td style=\"text-align:right;\"> -75.17348 </td>\n   <td style=\"text-align:right;\"> 3,342 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,054 </td>\n   <td style=\"text-align:right;\"> 39.96250 </td>\n   <td style=\"text-align:right;\"> -75.17420 </td>\n   <td style=\"text-align:right;\"> 3,297 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,101 </td>\n   <td style=\"text-align:right;\"> 39.94295 </td>\n   <td style=\"text-align:right;\"> -75.15955 </td>\n   <td style=\"text-align:right;\"> 3,214 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,022 </td>\n   <td style=\"text-align:right;\"> 39.95472 </td>\n   <td style=\"text-align:right;\"> -75.18323 </td>\n   <td style=\"text-align:right;\"> 3,152 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,028 </td>\n   <td style=\"text-align:right;\"> 39.94061 </td>\n   <td style=\"text-align:right;\"> -75.14958 </td>\n   <td style=\"text-align:right;\"> 3,101 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,362 </td>\n   <td style=\"text-align:right;\"> 39.94816 </td>\n   <td style=\"text-align:right;\"> -75.16226 </td>\n   <td style=\"text-align:right;\"> 3,072 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,063 </td>\n   <td style=\"text-align:right;\"> 39.94633 </td>\n   <td style=\"text-align:right;\"> -75.16980 </td>\n   <td style=\"text-align:right;\"> 2,972 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,185 </td>\n   <td style=\"text-align:right;\"> 39.95169 </td>\n   <td style=\"text-align:right;\"> -75.15888 </td>\n   <td style=\"text-align:right;\"> 2,952 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,059 </td>\n   <td style=\"text-align:right;\"> 39.96244 </td>\n   <td style=\"text-align:right;\"> -75.16121 </td>\n   <td style=\"text-align:right;\"> 2,926 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,012 </td>\n   <td style=\"text-align:right;\"> 39.94218 </td>\n   <td style=\"text-align:right;\"> -75.17747 </td>\n   <td style=\"text-align:right;\"> 2,907 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,061 </td>\n   <td style=\"text-align:right;\"> 39.95425 </td>\n   <td style=\"text-align:right;\"> -75.17761 </td>\n   <td style=\"text-align:right;\"> 2,847 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,161 </td>\n   <td style=\"text-align:right;\"> 39.95486 </td>\n   <td style=\"text-align:right;\"> -75.18091 </td>\n   <td style=\"text-align:right;\"> 2,837 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,256 </td>\n   <td style=\"text-align:right;\"> 39.95269 </td>\n   <td style=\"text-align:right;\"> -75.17779 </td>\n   <td style=\"text-align:right;\"> 2,816 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n#### Load Philadelphia Census Data\n\n\n\n\n::: {.cell}\n\n:::\n\n\n#### Map Philadelphia Context\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Map median income\nggplot() +\n  geom_sf(data = philly_census, aes(fill = Med_Inc), color = NA) +\n  scale_fill_viridis(\n    option = \"viridis\",\n    name = \"Median\\nIncome\",\n    labels = scales::dollar\n  ) +\n  labs(\n    title = \"Philadelphia Median Household Income by Census Tract\",\n    subtitle = \"Context for understanding bike share demand patterns\"\n  ) +\n  # Stations \n  geom_point(\n    data = top_stations,\n    aes(x = start_lon, y = start_lat, color = trips),\n    size = 0.75, alpha = 0.6\n  ) +\n  scale_color_gradientn(\n    colours = c(\"#FAFF89\", \"#D3321D\"),\n    name = \"Trips\\nOriginating at Station\"\n  )  +\n  guides(\n    fill = guide_colorbar(),\n    color = guide_colorbar()\n  ) +\n  theme(\n    legend.position = \"bottom\",\n    legend.box = \"horizontal\"     # <-- puts them side by side\n  ) +\n  mapTheme\n```\n\n::: {.cell-output-display}\n![](Knox_Katie_Assignment5_files/figure-html/map_philly-1.png){width=672}\n:::\n:::\n\n\n#### Join Census Data to Stations\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create sf object for stations\nstations_sf <- indego %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  st_as_sf(coords = c(\"start_lon\", \"start_lat\"), crs = 4326)\n\n# Spatial join to get census tract for each station\nstations_census <- st_join(stations_sf, philly_census, left = TRUE) %>%\n  st_drop_geometry()\n\n# Look at the result - investigate whether all of the stations joined to census data -- according to the map above there are stations in non-residential tracts.\n\nstations_for_map <- indego %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  left_join(\n    stations_census %>% select(start_station, Med_Inc),\n    by = \"start_station\"\n  ) %>%\n  mutate(has_census = !is.na(Med_Inc))\n\nsummary(stations_for_map$has_census)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Mode   FALSE    TRUE \nlogical      19     237 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Add back to trip data\nindego_census <- indego %>%\n  left_join(\n    stations_census %>% \n      select(start_station, Med_Inc, Percent_Taking_Transit, \n             Percent_White, Total_Pop),\n    by = \"start_station\"\n  )\n\n\n# Prepare data for visualization\nstations_for_map <- indego %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  left_join(\n    stations_census %>% select(start_station, Med_Inc),\n    by = \"start_station\"\n  ) %>%\n  mutate(has_census = !is.na(Med_Inc))\n\n# Create the map showing problem stations\nggplot() +\n  geom_sf(data = philly_census, aes(fill = Med_Inc), color = \"white\", size = 0.1) +\n  scale_fill_viridis(\n    option = \"viridis\",\n    name = \"Median\\nIncome\",\n    labels = scales::dollar,\n    na.value = \"grey90\"\n  ) +\n  # Stations with census data (small grey dots)\n  geom_point(\n    data = stations_for_map %>% filter(has_census),\n    aes(x = start_lon, y = start_lat),\n    color = \"grey30\", size = 1, alpha = 0.6\n  ) +\n  # Stations WITHOUT census data (red X marks the spot)\n  geom_point(\n    data = stations_for_map %>% filter(!has_census),\n    aes(x = start_lon, y = start_lat),\n    color = \"red\", size = 1, shape = 4, stroke = 1.5\n  ) +\n  labs(\n    title = \"Philadelphia Median Household Income by Census Tract\",\n    subtitle = \"Indego stations shown (RED = no census data match)\",\n    caption = \"Red X marks indicate stations that didn't join to census tracts\"\n  ) +\n  mapTheme\n```\n\n::: {.cell-output-display}\n![](Knox_Katie_Assignment5_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Identify which stations to keep\nvalid_stations <- stations_census %>%\n  filter(!is.na(Med_Inc)) %>%\n  pull(start_station)\n\n# Filter trip data to valid stations only\nindego_census <- indego %>%\n  filter(start_station %in% valid_stations) %>%\n  left_join(\n    stations_census %>% \n      select(start_station, Med_Inc, Percent_Taking_Transit, \n             Percent_White, Total_Pop),\n    by = \"start_station\"\n  )\n```\n:::\n\n\n\n#### Get Weather Data\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get weather from Philadelphia International Airport (KPHL)\n# This covers Q4 2024: October 1 - December 31\nweather_data <- riem_measures(\n  station = \"PHL\",  # Philadelphia International Airport\n  date_start = \"2024-10-01\",\n  date_end = \"2024-12-31\"\n)\n\n# Process weather data\nweather_processed <- weather_data %>%\n  mutate(\n    interval60 = floor_date(valid, unit = \"hour\"),\n    Temperature = tmpf,  # Temperature in Fahrenheit\n    Precipitation = ifelse(is.na(p01i), 0, p01i),  # Hourly precip in inches\n    Wind_Speed = sknt  # Wind speed in knots\n  ) %>%\n  select(interval60, Temperature, Precipitation, Wind_Speed) %>%\n  distinct()\n\n# Check for missing hours and interpolate if needed\nweather_complete <- weather_processed %>%\n  complete(interval60 = seq(min(interval60), max(interval60), by = \"hour\")) %>%\n  fill(Temperature, Precipitation, Wind_Speed, .direction = \"down\")\n\n# Look at the weather\nsummary(weather_complete %>% select(Temperature, Precipitation, Wind_Speed))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Temperature    Precipitation        Wind_Speed    \n Min.   :12.00   Min.   :0.000000   Min.   : 0.000  \n 1st Qu.:41.00   1st Qu.:0.000000   1st Qu.: 4.000  \n Median :51.00   Median :0.000000   Median : 7.000  \n Mean   :50.80   Mean   :0.004177   Mean   : 7.663  \n 3rd Qu.:60.95   3rd Qu.:0.000000   3rd Qu.:11.000  \n Max.   :83.00   Max.   :0.520000   Max.   :30.000  \n```\n\n\n:::\n:::\n\n\n\n#### Visualize Weather Patterns\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(weather_complete, aes(x = interval60, y = Temperature)) +\n  geom_line(color = \"#3182bd\", alpha = 0.7) +\n  geom_smooth(se = FALSE, color = \"red\") +\n  labs(\n    title = \"Philadelphia Temperature - Q1 2025\",\n    subtitle = \"Winter to early spring transition\",\n    x = \"Date\",\n    y = \"Temperature (°F)\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](Knox_Katie_Assignment5_files/figure-html/visualize_weather-1.png){width=672}\n:::\n:::\n\n\n#### Create Space-Time Panel: Aggregate Trips to Station-Hour Level\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Count trips by station-hour\ntrips_panel <- indego_census %>%\n  group_by(interval60, start_station, start_lat, start_lon,\n           Med_Inc, Percent_Taking_Transit, Percent_White, Total_Pop) %>%\n  summarize(Trip_Count = n()) %>%\n  ungroup()\n\n# How many station-hour observations?\nnrow(trips_panel)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 150972\n```\n\n\n:::\n\n```{.r .cell-code}\n# How many unique stations?\nlength(unique(trips_panel$start_station))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 237\n```\n\n\n:::\n\n```{.r .cell-code}\n# How many unique hours?\nlength(unique(trips_panel$interval60))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2208\n```\n\n\n:::\n:::\n\n\n#### Create Complete Panel Structure\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate expected panel size\nn_stations <- length(unique(trips_panel$start_station))\nn_hours <- length(unique(trips_panel$interval60))\nexpected_rows <- n_stations * n_hours\n\ncat(\"Expected panel rows:\", format(expected_rows, big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nExpected panel rows: 523,296 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Current rows:\", format(nrow(trips_panel), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCurrent rows: 150,972 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Missing rows:\", format(expected_rows - nrow(trips_panel), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMissing rows: 372,324 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create complete panel\nstudy_panel <- expand.grid(\n  interval60 = unique(trips_panel$interval60),\n  start_station = unique(trips_panel$start_station)\n) %>%\n  # Join trip counts\n  left_join(trips_panel, by = c(\"interval60\", \"start_station\")) %>%\n  # Replace NA trip counts with 0\n  mutate(Trip_Count = replace_na(Trip_Count, 0))\n\n# Fill in station attributes (they're the same for all hours)\nstation_attributes <- trips_panel %>%\n  group_by(start_station) %>%\n  summarize(\n    start_lat = first(start_lat),\n    start_lon = first(start_lon),\n    Med_Inc = first(Med_Inc),\n    Percent_Taking_Transit = first(Percent_Taking_Transit),\n    Percent_White = first(Percent_White),\n    Total_Pop = first(Total_Pop)\n  )\n\nstudy_panel <- study_panel %>%\n  left_join(station_attributes, by = \"start_station\")\n\n# Verify we have complete panel\ncat(\"Complete panel rows:\", format(nrow(study_panel), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nComplete panel rows: 523,296 \n```\n\n\n:::\n:::\n\n\n#### Add Time Features\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstudy_panel <- study_panel %>%\n  mutate(\n    week = week(interval60),\n    month = month(interval60, label = TRUE),\n    dotw = wday(interval60, label = TRUE),\n    hour = hour(interval60),\n    date = as.Date(interval60),\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  )\n```\n:::\n\n\n\n#### Join Weather Data\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstudy_panel <- study_panel %>%\n  left_join(weather_complete, by = \"interval60\")\n\n# Check for missing values\nsummary(study_panel %>% select(Trip_Count, Temperature, Precipitation))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Trip_Count       Temperature   Precipitation   \n Min.   : 0.0000   Min.   :12.0   Min.   :0.0000  \n 1st Qu.: 0.0000   1st Qu.:41.0   1st Qu.:0.0000  \n Median : 0.0000   Median :51.0   Median :0.0000  \n Mean   : 0.5178   Mean   :50.8   Mean   :0.0042  \n 3rd Qu.: 1.0000   3rd Qu.:61.0   3rd Qu.:0.0000  \n Max.   :28.0000   Max.   :83.0   Max.   :0.5200  \n                   NA's   :5688   NA's   :5688    \n```\n\n\n:::\n:::\n\n\n\n#### Create Temporal Lag Variables\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Sort by station and time\nstudy_panel <- study_panel %>%\n  arrange(start_station, interval60)\n\n# Create lag variables WITHIN each station\nstudy_panel <- study_panel %>%\n  group_by(start_station) %>%\n  mutate(\n    lag1Hour = lag(Trip_Count, 1),\n    lag2Hours = lag(Trip_Count, 2),\n    lag3Hours = lag(Trip_Count, 3),\n    lag12Hours = lag(Trip_Count, 12),\n    lag1day = lag(Trip_Count, 24)\n  ) %>%\n  ungroup()\n\n# Remove rows with NA lags (first 24 hours for each station)\nstudy_panel_complete <- study_panel %>%\n  filter(!is.na(lag1day))\n\ncat(\"Rows after removing NA lags:\", format(nrow(study_panel_complete), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows after removing NA lags: 605,298 \n```\n\n\n:::\n:::\n\n\n\n#### Visualize Lag Correlations\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Sample one station to visualize\nexample_station <- study_panel_complete %>%\n  filter(start_station == 3212) %>%\n  head(168)  # One week\n\n# Plot actual vs lagged demand\nggplot(example_station, aes(x = interval60)) +\n  geom_line(aes(y = Trip_Count, color = \"Current\"), linewidth = 1) +\n  geom_line(aes(y = lag1Hour, color = \"1 Hour Ago\"), linewidth = 1, alpha = 0.7) +\n  geom_line(aes(y = lag1day, color = \"24 Hours Ago\"), linewidth = 1, alpha = 0.7) +\n  scale_color_manual(values = c(\n    \"Current\" = \"#08519c\",\n    \"1 Hour Ago\" = \"#F09B4E\",\n    \"24 Hours Ago\" = \"#D3321D\"\n  )) +\n  labs(\n    title = \"Temporal Lag Patterns at One Station\",\n    subtitle = \"Past demand predicts future demand\",\n    x = \"Date-Time\",\n    y = \"Trip Count\",\n    color = \"Time Period\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](Knox_Katie_Assignment5_files/figure-html/lag_correlations-1.png){width=672}\n:::\n:::\n\n\n#### Temporal Train/Test Split\n\n**Approach:** Train on weeks 1-9, test on weeks 10-13 (predicting future from past)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Split by week\n# Q4 has weeks 40-53 (Oct-Dec)\n# Train on weeks 40-49 (Oct 1 - early December)\n# Test on weeks 50-53 (rest of December)\n\n# Which stations have trips in BOTH early and late periods?\nearly_stations <- study_panel_complete %>%\n  filter(week < 50) %>%\n  filter(Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\nlate_stations <- study_panel_complete %>%\n  filter(week >= 50) %>%\n  filter(Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\n# Keep only stations that appear in BOTH periods\ncommon_stations <- intersect(early_stations, late_stations)\n\n# Filter panel to only common stations\nstudy_panel_complete <- study_panel_complete %>%\n  filter(start_station %in% common_stations)\n\n# NOW create train/test split\ntrain <- study_panel_complete %>%\n  filter(week < 50)\n\ntest <- study_panel_complete %>%\n  filter(week >= 50)\n\ncat(\"Training observations:\", format(nrow(train), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTraining observations: 410,628 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Testing observations:\", format(nrow(test), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTesting observations: 171,684 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Training date range:\", min(train$date), \"to\", max(train$date), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTraining date range: 19997 to 20065 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Testing date range:\", min(test$date), \"to\", max(test$date), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTesting date range: 20066 to 20088 \n```\n\n\n:::\n:::\n\n\n\n#### Model 1: Baseline (Time + Weather)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create day of week factor with treatment (dummy) coding\ntrain <- train %>%\n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\n# Set contrasts to treatment coding (dummy variables)\ncontrasts(train$dotw_simple) <- contr.treatment(7)\n\n# Now run the model\nmodel1 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation,\n  data = train\n)\n\nsummary(model1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + \n    Precipitation, data = train)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.7089 -0.6783 -0.2159  0.1882 27.2727 \n\nCoefficients:\n                   Estimate Std. Error t value             Pr(>|t|)    \n(Intercept)       -0.489156   0.013731 -35.624 < 0.0000000000000002 ***\nas.factor(hour)1  -0.055267   0.012906  -4.282   0.0000184994686084 ***\nas.factor(hour)2  -0.078435   0.012690  -6.181   0.0000000006378151 ***\nas.factor(hour)3  -0.110234   0.012655  -8.711 < 0.0000000000000002 ***\nas.factor(hour)4  -0.074204   0.012566  -5.905   0.0000000035263476 ***\nas.factor(hour)5   0.038930   0.012623   3.084             0.002042 ** \nas.factor(hour)6   0.296063   0.012639  23.424 < 0.0000000000000002 ***\nas.factor(hour)7   0.562184   0.012853  43.738 < 0.0000000000000002 ***\nas.factor(hour)8   0.940524   0.012603  74.629 < 0.0000000000000002 ***\nas.factor(hour)9   0.681527   0.012691  53.700 < 0.0000000000000002 ***\nas.factor(hour)10  0.562441   0.012526  44.900 < 0.0000000000000002 ***\nas.factor(hour)11  0.602993   0.012538  48.094 < 0.0000000000000002 ***\nas.factor(hour)12  0.698148   0.012435  56.145 < 0.0000000000000002 ***\nas.factor(hour)13  0.667308   0.012338  54.085 < 0.0000000000000002 ***\nas.factor(hour)14  0.685610   0.012386  55.355 < 0.0000000000000002 ***\nas.factor(hour)15  0.791576   0.012780  61.940 < 0.0000000000000002 ***\nas.factor(hour)16  0.906925   0.012549  72.273 < 0.0000000000000002 ***\nas.factor(hour)17  1.110205   0.012639  87.842 < 0.0000000000000002 ***\nas.factor(hour)18  0.831297   0.012728  65.314 < 0.0000000000000002 ***\nas.factor(hour)19  0.541516   0.012768  42.412 < 0.0000000000000002 ***\nas.factor(hour)20  0.341348   0.012858  26.547 < 0.0000000000000002 ***\nas.factor(hour)21  0.233603   0.012881  18.135 < 0.0000000000000002 ***\nas.factor(hour)22  0.175194   0.012820  13.666 < 0.0000000000000002 ***\nas.factor(hour)23  0.076033   0.012906   5.891   0.0000000038337890 ***\ndotw_simple2       0.065588   0.006869   9.549 < 0.0000000000000002 ***\ndotw_simple3       0.062920   0.006857   9.177 < 0.0000000000000002 ***\ndotw_simple4      -0.050061   0.006571  -7.619   0.0000000000000257 ***\ndotw_simple5      -0.012223   0.006833  -1.789             0.073612 .  \ndotw_simple6      -0.024444   0.006806  -3.591             0.000329 ***\ndotw_simple7      -0.050983   0.006924  -7.363   0.0000000000001797 ***\nTemperature        0.012467   0.000161  77.432 < 0.0000000000000002 ***\nPrecipitation     -1.109233   0.081793 -13.562 < 0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.144 on 410596 degrees of freedom\nMultiple R-squared:  0.1141,\tAdjusted R-squared:  0.114 \nF-statistic:  1705 on 31 and 410596 DF,  p-value: < 0.00000000000000022\n```\n\n\n:::\n:::\n\n\n**Patterns:**\n\n- Tuesday and Wednesday have positive coefficients (0.066 and 0.063) \n- Thursday through Sunday have negative coefficients\n- Tuesday has the highest weekday effect (+0.066)\n- This might be a reflection of concentrated commuting patterns at the beginning of the week, and towards the end of the work week there may be more flexible hyrib or work from jobs influencing fewer trips than a Monday. \n\n**Hourly Patterns**\n\nHour   Coefficient   Interpretation\n0      (baseline)    0.000 trips/hour (midnight)\n1      -0.055       slightly fewer than midnight\n...\n5      +0.039       morning activity starting\n...\n8      +0.941       PEAK morning rush\n...\n10     +0.562       post-rush\n...\n17     +1.110       PEAK evening rush\n...\n23     +0.076       late night minimal\n\n#### Model 2: Add Temporal Lags\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel2 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day,\n  data = train\n)\n\nsummary(model2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + \n    Precipitation + lag1Hour + lag3Hours + lag1day, data = train)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-12.8428  -0.4697  -0.1265   0.1225  25.5313 \n\nCoefficients:\n                    Estimate Std. Error t value             Pr(>|t|)    \n(Intercept)       -0.1971724  0.0120171 -16.408 < 0.0000000000000002 ***\nas.factor(hour)1  -0.0175731  0.0112639  -1.560              0.11873    \nas.factor(hour)2  -0.0093400  0.0110785  -0.843              0.39918    \nas.factor(hour)3  -0.0323163  0.0110523  -2.924              0.00346 ** \nas.factor(hour)4  -0.0064036  0.0109793  -0.583              0.55973    \nas.factor(hour)5   0.0625618  0.0110386   5.668  0.00000001449553616 ***\nas.factor(hour)6   0.2581886  0.0110639  23.336 < 0.0000000000000002 ***\nas.factor(hour)7   0.4087297  0.0112659  36.280 < 0.0000000000000002 ***\nas.factor(hour)8   0.6475387  0.0110725  58.482 < 0.0000000000000002 ***\nas.factor(hour)9   0.2687374  0.0111533  24.095 < 0.0000000000000002 ***\nas.factor(hour)10  0.2122365  0.0109778  19.333 < 0.0000000000000002 ***\nas.factor(hour)11  0.2554385  0.0109944  23.234 < 0.0000000000000002 ***\nas.factor(hour)12  0.3583675  0.0108988  32.881 < 0.0000000000000002 ***\nas.factor(hour)13  0.3239304  0.0108163  29.948 < 0.0000000000000002 ***\nas.factor(hour)14  0.3531805  0.0108536  32.540 < 0.0000000000000002 ***\nas.factor(hour)15  0.4322898  0.0112024  38.589 < 0.0000000000000002 ***\nas.factor(hour)16  0.5127136  0.0110123  46.558 < 0.0000000000000002 ***\nas.factor(hour)17  0.6404994  0.0111130  57.635 < 0.0000000000000002 ***\nas.factor(hour)18  0.3266069  0.0112005  29.160 < 0.0000000000000002 ***\nas.factor(hour)19  0.1612724  0.0111995  14.400 < 0.0000000000000002 ***\nas.factor(hour)20  0.0449273  0.0112804   3.983  0.00006812693842296 ***\nas.factor(hour)21  0.0488508  0.0112677   4.335  0.00001454699054146 ***\nas.factor(hour)22  0.0606778  0.0111954   5.420  0.00000005967221309 ***\nas.factor(hour)23  0.0183651  0.0112646   1.630              0.10303    \ndotw_simple2       0.0070021  0.0059975   1.167              0.24301    \ndotw_simple3      -0.0128484  0.0059925  -2.144              0.03203 *  \ndotw_simple4      -0.0448243  0.0057357  -7.815  0.00000000000000551 ***\ndotw_simple5      -0.0422563  0.0059684  -7.080  0.00000000000144379 ***\ndotw_simple6      -0.0367596  0.0059417  -6.187  0.00000000061504630 ***\ndotw_simple7      -0.0593011  0.0060464  -9.808 < 0.0000000000000002 ***\nTemperature        0.0040641  0.0001426  28.494 < 0.0000000000000002 ***\nPrecipitation     -0.9676346  0.0714492 -13.543 < 0.0000000000000002 ***\nlag1Hour           0.3238000  0.0014825 218.412 < 0.0000000000000002 ***\nlag3Hours          0.1180469  0.0014504  81.387 < 0.0000000000000002 ***\nlag1day            0.2027487  0.0013895 145.912 < 0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9988 on 410593 degrees of freedom\nMultiple R-squared:  0.3252,\tAdjusted R-squared:  0.3252 \nF-statistic:  5821 on 34 and 410593 DF,  p-value: < 0.00000000000000022\n```\n\n\n:::\n:::\n\n\n**Adding lags improve R² by about 20 percentage points.** This is likely because the state of the Indego station an hour or a few hours before affects how many trips can be taken hours later, and the one day lag likely accounts for the peaks and ebs at the same time a day before, so it makes sense that this model can account for more of the variance in the data. \n\n#### Model 3: Add Demographics\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel3 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day +\n    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y,\n  data = train\n)\n\nsummary(model3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + \n    Precipitation + lag1Hour + lag3Hours + lag1day + Med_Inc.x + \n    Percent_Taking_Transit.y + Percent_White.y, data = train)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.2603  -0.7198  -0.2719   0.4456  24.6278 \n\nCoefficients:\n                              Estimate    Std. Error t value\n(Intercept)               0.7009115282  0.0386608126  18.130\nas.factor(hour)1         -0.0339064631  0.0443755122  -0.764\nas.factor(hour)2         -0.0733390073  0.0472207425  -1.553\nas.factor(hour)3         -0.1736198797  0.0563179188  -3.083\nas.factor(hour)4         -0.1602016516  0.0526556216  -3.042\nas.factor(hour)5         -0.0842198175  0.0392042217  -2.148\nas.factor(hour)6          0.1812725910  0.0339389718   5.341\nas.factor(hour)7          0.3659932453  0.0327798040  11.165\nas.factor(hour)8          0.6419351722  0.0315874296  20.322\nas.factor(hour)9          0.0689540443  0.0318174207   2.167\nas.factor(hour)10         0.0455849373  0.0318601406   1.431\nas.factor(hour)11         0.0951277607  0.0317831322   2.993\nas.factor(hour)12         0.1718233329  0.0312986651   5.490\nas.factor(hour)13         0.1501299648  0.0313008986   4.796\nas.factor(hour)14         0.1546199385  0.0311814820   4.959\nas.factor(hour)15         0.2738677333  0.0314129060   8.718\nas.factor(hour)16         0.3825663042  0.0310863390  12.307\nas.factor(hour)17         0.5958195674  0.0311303049  19.140\nas.factor(hour)18         0.1871034280  0.0314626011   5.947\nas.factor(hour)19         0.0105635560  0.0320040115   0.330\nas.factor(hour)20        -0.0963042374  0.0327876103  -2.937\nas.factor(hour)21        -0.0718694380  0.0336061149  -2.139\nas.factor(hour)22        -0.0356940800  0.0343008260  -1.041\nas.factor(hour)23        -0.0793554621  0.0360569574  -2.201\ndotw_simple2              0.0015399442  0.0129720488   0.119\ndotw_simple3             -0.0058302798  0.0131356919  -0.444\ndotw_simple4             -0.0584003672  0.0128820191  -4.533\ndotw_simple5             -0.0902616975  0.0132777688  -6.798\ndotw_simple6             -0.0296928615  0.0133240066  -2.229\ndotw_simple7             -0.0404284310  0.0137730955  -2.935\nTemperature               0.0060129110  0.0003255823  18.468\nPrecipitation            -2.6993476761  0.2537854011 -10.636\nlag1Hour                  0.2432506608  0.0023823455 102.106\nlag3Hours                 0.0728128784  0.0024806873  29.352\nlag1day                   0.1565602280  0.0022935086  68.262\nMed_Inc.x                -0.0000001894  0.0000001237  -1.531\nPercent_Taking_Transit.y -0.0038935558  0.0004528281  -8.598\nPercent_White.y           0.0037864819  0.0002282348  16.590\n                                     Pr(>|t|)    \n(Intercept)              < 0.0000000000000002 ***\nas.factor(hour)1                      0.44482    \nas.factor(hour)2                      0.12040    \nas.factor(hour)3                      0.00205 ** \nas.factor(hour)4                      0.00235 ** \nas.factor(hour)5                      0.03170 *  \nas.factor(hour)6              0.0000000925173 ***\nas.factor(hour)7         < 0.0000000000000002 ***\nas.factor(hour)8         < 0.0000000000000002 ***\nas.factor(hour)9                      0.03022 *  \nas.factor(hour)10                     0.15249    \nas.factor(hour)11                     0.00276 ** \nas.factor(hour)12             0.0000000403123 ***\nas.factor(hour)13             0.0000016175893 ***\nas.factor(hour)14             0.0000007104928 ***\nas.factor(hour)15        < 0.0000000000000002 ***\nas.factor(hour)16        < 0.0000000000000002 ***\nas.factor(hour)17        < 0.0000000000000002 ***\nas.factor(hour)18             0.0000000027402 ***\nas.factor(hour)19                     0.74135    \nas.factor(hour)20                     0.00331 ** \nas.factor(hour)21                     0.03247 *  \nas.factor(hour)22                     0.29805    \nas.factor(hour)23                     0.02775 *  \ndotw_simple2                          0.90550    \ndotw_simple3                          0.65715    \ndotw_simple4                  0.0000058070122 ***\ndotw_simple5                  0.0000000000107 ***\ndotw_simple6                          0.02585 *  \ndotw_simple7                          0.00333 ** \nTemperature              < 0.0000000000000002 ***\nPrecipitation            < 0.0000000000000002 ***\nlag1Hour                 < 0.0000000000000002 ***\nlag3Hours                < 0.0000000000000002 ***\nlag1day                  < 0.0000000000000002 ***\nMed_Inc.x                             0.12579    \nPercent_Taking_Transit.y < 0.0000000000000002 ***\nPercent_White.y          < 0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.274 on 133822 degrees of freedom\n  (276768 observations deleted due to missingness)\nMultiple R-squared:  0.2192,\tAdjusted R-squared:  0.219 \nF-statistic:  1015 on 37 and 133822 DF,  p-value: < 0.00000000000000022\n```\n\n\n:::\n:::\n\n\n#### Model 4: Add Station Fixed Effects\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel4 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day +\n    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y +\n    as.factor(start_station),\n  data = train\n)\n\n# Summary too long with all station dummies, just show key metrics\ncat(\"Model 4 R-squared:\", summary(model4)$r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 4 R-squared: 0.2469249 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Model 4 Adj R-squared:\", summary(model4)$adj.r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 4 Adj R-squared: 0.2454536 \n```\n\n\n:::\n:::\n\n\n#### Model 5: Add Rush Hour Interaction\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel5 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day + rush_hour + as.factor(month) +\n    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y +\n    as.factor(start_station) +\n    rush_hour * weekend,  # Rush hour effects different on weekends\n  data = train\n)\n\ncat(\"Model 5 R-squared:\", summary(model5)$r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 5 R-squared: 0.2526638 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Model 5 Adj R-squared:\", summary(model5)$adj.r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 5 Adj R-squared: 0.251187 \n```\n\n\n:::\n:::\n\n\n#### Model Evaluation: Calculate Predictions and MAE\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get predictions on test set\n\n# Create day of week factor with treatment (dummy) coding\ntest <- test %>%\n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\n# Set contrasts to treatment coding (dummy variables)\ncontrasts(test$dotw_simple) <- contr.treatment(7)\n\ntest <- test %>%\n  mutate(\n    pred1 = predict(model1, newdata = test),\n    pred2 = predict(model2, newdata = test),\n    pred3 = predict(model3, newdata = test),\n    pred4 = predict(model4, newdata = test),\n    pred5 = predict(model5, newdata = test)\n  )\n\n# Calculate MAE for each model\nmae_results <- data.frame(\n  Model = c(\n    \"1. Time + Weather\",\n    \"2. + Temporal Lags\",\n    \"3. + Demographics\",\n    \"4. + Station FE\",\n    \"5. + Rush Hour Interaction\"\n  ),\n  MAE = c(\n    mean(abs(test$Trip_Count - test$pred1), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred2), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred3), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred4), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred5), na.rm = TRUE)\n  )\n)\n\nkable(mae_results, \n      digits = 2,\n      caption = \"Mean Absolute Error by Model (Test Set)\",\n      col.names = c(\"Model\", \"MAE (trips)\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Mean Absolute Error by Model (Test Set)</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:right;\"> MAE (trips) </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 1. Time + Weather </td>\n   <td style=\"text-align:right;\"> 0.54 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2. + Temporal Lags </td>\n   <td style=\"text-align:right;\"> 0.40 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 3. + Demographics </td>\n   <td style=\"text-align:right;\"> 0.64 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 4. + Station FE </td>\n   <td style=\"text-align:right;\"> 0.66 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 5. + Rush Hour Interaction </td>\n   <td style=\"text-align:right;\"> 0.65 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n**Temporal Lags improved the model the most;** the biggest drop in mean absolute error was from the model accounting for time of day, day of week, and weather, and then adding in the temporal lags. In fact, adding demographics made the model perform worse than the baseline model, as well as adding station fixed effects and interaction effects on top of that. \n\n**Compared to Q1 2025:**\n\nThe MAE values for Q4 2024 are fairly similar across the models. I believe this might be because both quarters account for season changes into winter (Q4) and out of winter (Q1) that make it harder to predict bike share in the latter part of the quarter based on the first, even when taking into account weather effects. There are also a high concentration of winter holidays that likely affect bike travel in Q4, such as Thanksgiving and Winter Break holidays, and in Q1 New Years, Valentine's Day, and Spring Break holidays. \n\n## Part 2: Error Analysis \n\n#### Observed vs. Predicted Error Analysis\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest <- test %>%\n  mutate(\n    error = Trip_Count - pred2,\n    abs_error = abs(error),\n    time_of_day = case_when(\n      hour < 7 ~ \"Overnight\",\n      hour >= 7 & hour < 10 ~ \"AM Rush\",\n      hour >= 10 & hour < 15 ~ \"Mid-Day\",\n      hour >= 15 & hour <= 18 ~ \"PM Rush\",\n      hour > 18 ~ \"Evening\"\n    )\n  )\n\n# Scatter plot by time and day type\nggplot(test, aes(x = Trip_Count, y = pred2)) +\n  geom_point(alpha = 0.2, color = \"#3182bd\") +\n  geom_abline(slope = 1, intercept = 0, color = \"red\", linewidth = 1) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"darkgreen\") +\n  facet_grid(weekend ~ time_of_day) +\n  labs(\n    title = \"Observed vs. Predicted Bike Trips\",\n    subtitle = \"Model 2 performance by time period\",\n    x = \"Observed Trips\",\n    y = \"Predicted Trips\",\n    caption = \"Red line = perfect predictions; Green line = actual model fit\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](Knox_Katie_Assignment5_files/figure-html/obs_vs_pred-1.png){width=672}\n:::\n:::\n\n\n\n**The model consistently under predicts trips on weekdays, weekends, at all time periods of the day.** The one period that appears to be moderately better predicted is the AM Rush period of weekdays, and generally slightly better at predicting weekdays than weekends. However, the consistent under-predicting seems to signify there is a major driver of Indego trips that this model does not account for well. \n\n#### Spatial Error Patterns\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate MAE by station\nstation_errors <- test %>%\n  group_by(start_station, start_lat.x, start_lon.y) %>%\n  summarize(\n    MAE = mean(abs_error, na.rm = TRUE),\n    avg_demand = mean(Trip_Count, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  filter(!is.na(start_lat.x), !is.na(start_lon.y))\n\n## Create Two Maps Side-by-Side with Proper Legends (sorry these maps are ugly)\n\n# Calculate station errors\nstation_errors <- test %>%\n  filter(!is.na(pred2)) %>%\n  group_by(start_station, start_lat.x, start_lon.y) %>%\n  summarize(\n    MAE = mean(abs(Trip_Count - pred2), na.rm = TRUE),\n    avg_demand = mean(Trip_Count, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  filter(!is.na(start_lat.x), !is.na(start_lon.y))\n\n# Map 1: Prediction Errors\np1 <- ggplot() +\n  geom_sf(data = philly_census, fill = \"grey95\", color = \"white\", size = 0.2) +\n  geom_point(\n    data = station_errors,\n    aes(x = start_lon.y, y = start_lat.x, color = MAE),\n    size = 3.5,\n    alpha = 0.7\n  ) +\n  scale_color_viridis(\n    option = \"plasma\",\n    name = \"MAE\\n(trips)\",\n    direction = -1,\n    breaks = c(0.5, 1.0, 1.5),  # Fewer, cleaner breaks\n    labels = c(\"0.5\", \"1.0\", \"1.5\")\n  ) +\n  labs(title = \"Prediction Errors\",\n       subtitle = \"Higher in Center City\") +\n  mapTheme +\n  theme(\n    legend.position = \"right\",\n    legend.title = element_text(size = 10, face = \"bold\"),\n    legend.text = element_text(size = 9),\n    plot.title = element_text(size = 14, face = \"bold\"),\n    plot.subtitle = element_text(size = 10)\n  ) +\n  guides(color = guide_colorbar(\n    barwidth = 1.5,\n    barheight = 12,\n    title.position = \"top\",\n    title.hjust = 0.5\n  ))\n\n# Map 2: Average Demand\np2 <- ggplot() +\n  geom_sf(data = philly_census, fill = \"grey95\", color = \"white\", size = 0.2) +\n  geom_point(\n    data = station_errors,\n    aes(x = start_lon.y, y = start_lat.x, color = avg_demand),\n    size = 3.5,\n    alpha = 0.7\n  ) +\n  scale_color_viridis(\n    option = \"viridis\",\n    name = \"Avg\\nDemand\",\n    direction = -1,\n    breaks = c(0.5, 1.0, 1.5, 2.0, 2.5),  # Clear breaks\n    labels = c(\"0.5\", \"1.0\", \"1.5\", \"2.0\", \"2.5\")\n  ) +\n  labs(title = \"Average Demand\",\n       subtitle = \"Trips per station-hour\") +\n  mapTheme +\n  theme(\n    legend.position = \"right\",\n    legend.title = element_text(size = 10, face = \"bold\"),\n    legend.text = element_text(size = 9),\n    plot.title = element_text(size = 14, face = \"bold\"),\n    plot.subtitle = element_text(size = 10)\n  ) +\n  guides(color = guide_colorbar(\n    barwidth = 1.5,\n    barheight = 12,\n    title.position = \"top\",\n    title.hjust = 0.5\n  ))\n\np1 | p2\n```\n\n::: {.cell-output-display}\n![](Knox_Katie_Assignment5_files/figure-html/spatial_errors-1.png){width=672}\n:::\n:::\n\n\n**Higher MAEs are clustered around center city, where trips per hour are also higher on average.** This nuances our understanding of the model's under-performance overall, as we can see that MAEs are not equal across all stations but higher error gaps where there are higher trips. This indicates that there are spatial variables that this model lacks. \n\n#### Temporal Error Patterns\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# MAE by time of day and day type\ntemporal_errors <- test %>%\n  group_by(time_of_day, weekend) %>%\n  summarize(\n    MAE = mean(abs_error, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  mutate(day_type = ifelse(weekend == 1, \"Weekend\", \"Weekday\"))\n\nggplot(temporal_errors, aes(x = time_of_day, y = MAE, fill = day_type)) +\n  geom_col(position = \"dodge\") +\n  scale_fill_manual(values = c(\"Weekday\" = \"#08519c\", \"Weekend\" = \"#6baed6\")) +\n  labs(\n    title = \"Prediction Errors by Time Period\",\n    subtitle = \"When is the model struggling most?\",\n    x = \"Time of Day\",\n    y = \"Mean Absolute Error (trips)\",\n    fill = \"Day Type\"\n  ) +\n  plotTheme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](Knox_Katie_Assignment5_files/figure-html/temporal_errors-1.png){width=672}\n:::\n:::\n\n\n**MAEs are higher for weekdays than weekends on average,** but combined with the previous plots of observed vs predicted values, this shows that the mean absolute errors partially higher for weekdays because of higher trip counts on weekdays typically than weekends, and higher trip counts during that AM and PM rush. In other words, this again confirms that the model is creating predictions that are too uniform accross time and space. \n\n#### Errors and Demographics\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Join demographic data to station errors\nstation_errors_demo <- station_errors %>%\n  left_join(\n    station_attributes %>% select(start_station, Med_Inc, Percent_Taking_Transit, Percent_White),\n    by = \"start_station\"\n  ) %>%\n  filter(!is.na(Med_Inc))\n\n# Create plots\ninc_plot <- ggplot(station_errors_demo, aes(x = Med_Inc, y = MAE)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  scale_x_continuous(labels = scales::dollar) +\n  labs(title = \"Errors vs. Median Income\", x = \"Median Income\", y = \"MAE\") +\n  plotTheme\n\ntransit_plot <- ggplot(station_errors_demo, aes(x = Percent_Taking_Transit, y = MAE)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(title = \"Errors vs. Transit Usage\", x = \"% Taking Transit\", y = \"MAE\") +\n  plotTheme\n\nwhite_plot <- ggplot(station_errors_demo, aes(x = Percent_White, y = MAE)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(title = \"Errors vs. Race\", x = \"% White\", y = \"MAE\") +\n  plotTheme\n\ngrid.arrange(inc_plot, transit_plot, white_plot, ncol = 2)\n```\n\n::: {.cell-output-display}\n![](Knox_Katie_Assignment5_files/figure-html/errors_demographics-1.png){width=672}\n:::\n:::\n\n\n**Prediction errors are higher for higher income and more White areas, but lower for higher transit-taking areas.** This again tracks with the general under-performance of the model, as percent White and median income are slightly positively correlated with trips and percent using transit is slightly negatively correlated with trips.\n\n## Part 3: Feature Engineering & model improvement\n\nAfter observing the error results from the first five models, I believe the biggest aspects the models are missing are spatial variables that influence bike share usage. Seeing as the under-counting is clustered around center city, I think some likely attributes of center city that make biking more attractive is the relative nearness of start and end destinations to each other (~80% of trips are under 1.5 miles). In other words, I think the model would be a better predictor if it took into account the potential rider's available close-by destination bike stations they could park the bike within the average trip length that riders take. Additionally, I think people are more likely to feel comfortable biking when there are bikes lanes nearby or roads with a low posted speed limit. I also want to build off the success of adding the spatial lags that improved model 1 to model 2 so much, and add another lag for the same hour in the previous week.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Step 1: Build LINESTRING geometry for each row\ntrips_sf <- indego %>%\n  filter(\n    !is.na(start_lat),\n    !is.na(start_lon),\n    !is.na(end_lat),\n    !is.na(end_lon)\n  )%>%\n  rowwise() %>%\n  mutate(\n    geometry = list(\n      st_linestring(\n        matrix(\n          c(start_lon, start_lat,\n            end_lon,   end_lat),\n          ncol = 2,\n          byrow = TRUE\n        )\n      )\n    )\n  ) %>%\n  ungroup() %>%\n  st_as_sf(crs = 4326)\n\n\n# Step 2: Transform to PA South (meters)\ntrips_sf <- st_transform(trips_sf, 6539)\n\n\n# Step 3: Calculate trip distance (meters)\ntrips_sf <- trips_sf %>%\n  mutate(distance_f = st_length(geometry))\n\ntrips_sf <- trips_sf %>%\n  mutate(\n    distance_mi = as.numeric(distance_f) / 5280  # 1 mile = 5280 ft\n  )\n\nsummary(trips_sf$distance_mi)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.5484  0.9063  1.0439  1.3783  8.8305 \n```\n\n\n:::\n:::\n\n\n\n**Spatial features:**\n\n- Number of low-speed roads near station\n- Number and type of Bike lanes near station\n- Nearness of station to other stations \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nroads_sf <- st_read(\"../data/RMSADMIN_(Administrative_Classifications_of_Roadway)/RMSADMIN_(Administrative_Classifications_of_Roadway).shp\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `RMSADMIN_(Administrative_Classifications_of_Roadway)' from data source `/Users/kknox/Documents/GitHub/portfolio-setup-kkxix/labs/lab5/data/RMSADMIN_(Administrative_Classifications_of_Roadway)/RMSADMIN_(Administrative_Classifications_of_Roadway).shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 240887 features and 34 fields (with 1914 geometries empty)\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: -8963377 ymin: 4825317 xmax: -8314805 ymax: 5201143\nProjected CRS: WGS 84 / Pseudo-Mercator\n```\n\n\n:::\n\n```{.r .cell-code}\nblanes_sf <- st_read(\"../data/Bike_Network/Bike_Network.shp\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `Bike_Network' from data source \n  `/Users/kknox/Documents/GitHub/portfolio-setup-kkxix/labs/lab5/data/Bike_Network/Bike_Network.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5225 features and 8 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: -8378937 ymin: 4847835 xmax: -8345146 ymax: 4883978\nProjected CRS: WGS 84 / Pseudo-Mercator\n```\n\n\n:::\n\n```{.r .cell-code}\n# filter to just roadways in Phildelphia County under 25 mph \n# Phildelphia CTY CODE is 67\nroads_sf<-roads_sf%>%filter(\n  CTY_CODE == 67, \n  SPEED_LIMI<=25\n)\n\nroads_sf<-roads_sf%>%\n  st_transform(st_crs(stations_sf))%>%\n  mutate(label=\"Road <25mph\")\n\nblanes_sf<-blanes_sf%>%\n  st_transform(st_crs(stations_sf))%>%\n  mutate(label=\"Bike Lane\")\n\nstations_sf<-stations_sf%>%mutate(\n  label=\"Indego Station\"\n)\n\n# map with stations\nggplot() +\n  geom_sf(data = roads_sf, aes(color = label), linewidth = 0.1) +\n  geom_sf(data = blanes_sf, aes(color = label), linewidth = 0.1) +\n  geom_sf(data = stations_sf, aes(color = label), size = 0.7, alpha = 0.7) +\n  scale_color_manual(\n    name = \"Legend\",\n    values = c(\n      \"Road <25mph\" = \"#bdd7e7\",\n      \"Bike Lane\" = \"#F09B4E\",\n      \"Indego Station\" = \"#08519c\"\n    )\n  ) +\n  labs(title = \"Indego Stations, Bike Lanes, and <25mph Roads\") +\n  mapTheme +\n  theme(\n    legend.position = \"right\",\n    legend.title = element_text(size = 10, face = \"bold\"),\n    legend.text = element_text(size = 9)\n  )\n```\n\n::: {.cell-output-display}\n![](Knox_Katie_Assignment5_files/figure-html/get roads and bike lanes-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nstations_buffered <- stations_sf %>%\n  mutate(buffer_geom = st_buffer(geometry, dist = 500))\n\n# ---- Count roads intersecting each buffer ----\nroad_counts <- st_intersects(stations_buffered$buffer_geom, roads_sf) %>%\n  lengths()\n\n# ---- Count bike lanes intersecting each buffer ----\nblane_counts <- st_intersects(stations_buffered$buffer_geom, blanes_sf) %>%\n  lengths()\n\n# ---- Add results back onto stations_sf ----\nstations_sf <- stations_sf %>%\n  mutate(\n    nearby_roads  = road_counts,\n    nearby_bikelanes = blane_counts\n  )\n\nggplot() +\n  geom_sf(data = roads_sf, color=\"lightgray\", linewidth = 0.1) +\n  geom_sf(data = stations_sf, aes(color = nearby_bikelanes), size = 0.7, alpha = 0.7) +\n  labs(title = \"Stations Colored by Number of Nearby Bike Lanes\") +\n  mapTheme +\n  theme(\n    legend.position = \"right\",\n    legend.title = element_text(size = 10, face = \"bold\"),\n    legend.text = element_text(size = 9)\n  )\n```\n\n::: {.cell-output-display}\n![](Knox_Katie_Assignment5_files/figure-html/join to station buffers-1.png){width=672}\n:::\n:::\n\n\n\nIn addition to nearby bike lanes and slow roads, I will add the number of other bike stations within a buffer of the median trip distance of 0.9063 miles.  \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 0.9063 miles = 1458.54847 meters\n\nstations_buffered <- stations_sf %>%\n  mutate(buffer_geom = st_buffer(geometry, dist = 1458.54847))\n\n# ---- Count indego stations intersecting each buffer ----\nstation_counts <- st_intersects(stations_buffered$buffer_geom, stations_sf) %>%\n  lengths()\n\n# ---- Add results back onto stations_sf ----\nstations_sf <- stations_sf %>%\n  mutate(\n    nearby_stations  = station_counts\n  )\n\nggplot() +\n  geom_sf(data = roads_sf, color=\"lightgray\", linewidth = 0.1) +\n  geom_sf(data = stations_sf, aes(color = nearby_stations), size = 0.7, alpha = 0.7) +\n  labs(title = \"Stations Colored by Number of Nearby Other Stations\") +\n  mapTheme +\n  theme(\n    legend.position = \"right\",\n    legend.title = element_text(size = 10, face = \"bold\"),\n    legend.text = element_text(size = 9)\n  )\n```\n\n::: {.cell-output-display}\n![](Knox_Katie_Assignment5_files/figure-html/add other stations-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Add back to trip data\nstudy_panel <- study_panel %>%\n  left_join(\n    stations_sf %>% \n      select(start_station, nearby_roads, nearby_bikelanes, nearby_stations),\n    by = \"start_station\"\n  )\n```\n:::\n\n\n\n**Trip history features:**\n\n- Add lag for same hour last week\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstudy_panel <- study_panel %>%\n  group_by(start_station) %>%\n  mutate(\n    lag1week = lag(Trip_Count, 168)\n  ) %>%\n  ungroup()\n\n# Remove rows with NA lags (first 24 hours for each station)\nstudy_panel_complete <- study_panel %>%\n  filter(!is.na(lag1week) & !is.na(lag1day))\n\ncat(\"Rows after removing NA lags:\", format(nrow(study_panel_complete), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows after removing NA lags: 571,170 \n```\n\n\n:::\n:::\n\n\n\n#### Model 6: Add nearby spatial features and 1-week lag\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstudy_panel_complete <- study_panel_complete %>%\n  filter(start_station %in% common_stations)\n\n# NOW create train/test split\ntrain <- study_panel_complete %>%\n  filter(week < 50)\n\ntest <- study_panel_complete %>%\n  filter(week >= 50)\n\ntrain <- train %>%\n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\n# Set contrasts to treatment coding (dummy variables)\ncontrasts(train$dotw_simple) <- contr.treatment(7)\n\ntest <- test %>%\n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\n# Set contrasts to treatment coding (dummy variables)\ncontrasts(test$dotw_simple) <- contr.treatment(7)\n\ncat(\"Training observations:\", format(nrow(train), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTraining observations: 377,796 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Testing observations:\", format(nrow(test), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTesting observations: 171,684 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Training date range:\", min(train$date), \"to\", max(train$date), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTraining date range: 20003 to 20065 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Testing date range:\", min(test$date), \"to\", max(test$date), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTesting date range: 20066 to 20088 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel6 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day + rush_hour + as.factor(month) +\n    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y +\n    as.factor(start_station) +\n    rush_hour * weekend +  # Rush hour effects different on weekends\n    nearby_roads + nearby_bikelanes + nearby_stations +\n    lag1week,\n  data = train\n)\n\ncat(\"Model 6 R-squared:\", summary(model6)$r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 6 R-squared: 0.2569648 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Model 6 Adj R-squared:\", summary(model6)$adj.r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 6 Adj R-squared: 0.2553348 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel7 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day + lag1week + as.factor(month) +week+\n    nearby_roads + nearby_bikelanes + nearby_stations,\n  data = train\n)\n\nsummary(model7)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + \n    Precipitation + lag1Hour + lag3Hours + lag1day + lag1week + \n    as.factor(month) + week + nearby_roads + nearby_bikelanes + \n    nearby_stations, data = train)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.9185  -0.4683  -0.1218   0.1939  25.6004 \n\nCoefficients:\n                      Estimate  Std. Error t value             Pr(>|t|)    \n(Intercept)         0.43496916  0.08269874   5.260  0.00000014438239072 ***\nas.factor(hour)1   -0.02757267  0.01140429  -2.418             0.015617 *  \nas.factor(hour)2   -0.02471651  0.01120616  -2.206             0.027411 *  \nas.factor(hour)3   -0.04223159  0.01122202  -3.763             0.000168 ***\nas.factor(hour)4   -0.02301352  0.01110560  -2.072             0.038243 *  \nas.factor(hour)5    0.04958198  0.01121689   4.420  0.00000985935730785 ***\nas.factor(hour)6    0.23921149  0.01125699  21.250 < 0.0000000000000002 ***\nas.factor(hour)7    0.39229409  0.01149508  34.127 < 0.0000000000000002 ***\nas.factor(hour)8    0.65535940  0.01132090  57.889 < 0.0000000000000002 ***\nas.factor(hour)9    0.28286593  0.01137751  24.862 < 0.0000000000000002 ***\nas.factor(hour)10   0.22494720  0.01126621  19.967 < 0.0000000000000002 ***\nas.factor(hour)11   0.26742698  0.01128002  23.708 < 0.0000000000000002 ***\nas.factor(hour)12   0.35504566  0.01114650  31.853 < 0.0000000000000002 ***\nas.factor(hour)13   0.32677897  0.01096672  29.797 < 0.0000000000000002 ***\nas.factor(hour)14   0.36286831  0.01096530  33.092 < 0.0000000000000002 ***\nas.factor(hour)15   0.45463939  0.01135209  40.049 < 0.0000000000000002 ***\nas.factor(hour)16   0.54290308  0.01120398  48.456 < 0.0000000000000002 ***\nas.factor(hour)17   0.67039251  0.01129843  59.335 < 0.0000000000000002 ***\nas.factor(hour)18   0.37614606  0.01143899  32.883 < 0.0000000000000002 ***\nas.factor(hour)19   0.20110538  0.01143051  17.594 < 0.0000000000000002 ***\nas.factor(hour)20   0.09719693  0.01151132   8.444 < 0.0000000000000002 ***\nas.factor(hour)21   0.07855837  0.01147514   6.846  0.00000000000760801 ***\nas.factor(hour)22   0.06896751  0.01137705   6.062  0.00000000134576430 ***\nas.factor(hour)23   0.02218531  0.01144897   1.938             0.052654 .  \ndotw_simple2        0.02377572  0.00588873   4.037  0.00005403574372275 ***\ndotw_simple3        0.00925967  0.00600759   1.541             0.123238    \ndotw_simple4       -0.03318396  0.00574706  -5.774  0.00000000774364607 ***\ndotw_simple5       -0.03230693  0.00611195  -5.286  0.00000012518044383 ***\ndotw_simple6       -0.03062853  0.00616800  -4.966  0.00000068477166340 ***\ndotw_simple7       -0.05470911  0.00624000  -8.767 < 0.0000000000000002 ***\nTemperature         0.00293576  0.00022137  13.261 < 0.0000000000000002 ***\nPrecipitation      -0.83668132  0.07082242 -11.814 < 0.0000000000000002 ***\nlag1Hour            0.28694920  0.00155823 184.151 < 0.0000000000000002 ***\nlag3Hours           0.08684120  0.00152650  56.889 < 0.0000000000000002 ***\nlag1day             0.17362425  0.00148343 117.043 < 0.0000000000000002 ***\nlag1week            0.09151274  0.00137458  66.575 < 0.0000000000000002 ***\nas.factor(month).L  0.06170679  0.00796574   7.747  0.00000000000000947 ***\nas.factor(month).Q  0.01781405  0.00316482   5.629  0.00000001816291059 ***\nweek               -0.01881709  0.00166046 -11.332 < 0.0000000000000002 ***\nnearby_roads        0.00179729  0.00020358   8.828 < 0.0000000000000002 ***\nnearby_bikelanes    0.00126797  0.00008765  14.466 < 0.0000000000000002 ***\nnearby_stations     0.00452301  0.00015920  28.411 < 0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9737 on 377754 degrees of freedom\nMultiple R-squared:  0.3439,\tAdjusted R-squared:  0.3438 \nF-statistic:  4829 on 41 and 377754 DF,  p-value: < 0.00000000000000022\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntest <- test %>%\n  mutate(\n    pred2 = predict(model2, newdata = test),\n    pred6 = predict(model6, newdata = test),\n    pred7 = predict(model7, newdata = test)\n  )\n\n# Calculate MAE for each model\nmae_results <- data.frame(\n  Model = c(\n    \"2. + Temporal Lags\",\n    \"6. Model 2 + Demographics + Station FE + Rush Hour Interaction + Week Lag + Nearby Features\",\n    \"7. Model 2 + Week Lag + Nearby Features\"\n  ),\n  MAE = c(\n    mean(abs(test$Trip_Count - test$pred2), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred6), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred7), na.rm = TRUE)\n  )\n)\n\nkable(mae_results, \n      digits = 2,\n      caption = \"Mean Absolute Error by Model (Test Set)\",\n      col.names = c(\"Model\", \"MAE (trips)\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Mean Absolute Error by Model (Test Set)</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:right;\"> MAE (trips) </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 2. + Temporal Lags </td>\n   <td style=\"text-align:right;\"> 0.40 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 6. Model 2 + Demographics + Station FE + Rush Hour Interaction + Week Lag + Nearby Features </td>\n   <td style=\"text-align:right;\"> 0.65 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 7. Model 2 + Week Lag + Nearby Features </td>\n   <td style=\"text-align:right;\"> 0.41 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntest <- test %>%\n  mutate(\n    error = Trip_Count - pred7,\n    abs_error = abs(error),\n    time_of_day = case_when(\n      hour < 7 ~ \"Overnight\",\n      hour >= 7 & hour < 10 ~ \"AM Rush\",\n      hour >= 10 & hour < 15 ~ \"Mid-Day\",\n      hour >= 15 & hour <= 18 ~ \"PM Rush\",\n      hour > 18 ~ \"Evening\"\n    )\n  )\n\n# Scatter plot by time and day type\nggplot(test, aes(x = Trip_Count, y = pred7)) +\n  geom_point(alpha = 0.2, color = \"#3182bd\") +\n  geom_abline(slope = 1, intercept = 0, color = \"red\", linewidth = 1) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"darkgreen\") +\n  facet_grid(weekend ~ time_of_day) +\n  labs(\n    title = \"Observed vs. Predicted Bike Trips\",\n    subtitle = \"Model 2 performance by time period\",\n    x = \"Observed Trips\",\n    y = \"Predicted Trips\",\n    caption = \"Red line = perfect predictions; Green line = actual model fit\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](Knox_Katie_Assignment5_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate MAE by station\nstation_errors <- test %>%\n  group_by(start_station, start_lat.x, start_lon.y) %>%\n  summarize(\n    MAE = mean(abs_error, na.rm = TRUE),\n    avg_demand = mean(Trip_Count, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  filter(!is.na(start_lat.x), !is.na(start_lon.y))\n\n## Create Two Maps Side-by-Side with Proper Legends (sorry these maps are ugly)\n\n# Calculate station errors\nstation_errors <- test %>%\n  filter(!is.na(pred7)) %>%\n  group_by(start_station, start_lat.x, start_lon.y) %>%\n  summarize(\n    MAE = mean(abs(Trip_Count - pred6), na.rm = TRUE),\n    avg_demand = mean(Trip_Count, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  filter(!is.na(start_lat.x), !is.na(start_lon.y))\n\n# Map 1: Prediction Errors\np1.1 <- ggplot() +\n  geom_sf(data = philly_census, fill = \"grey95\", color = \"white\", size = 0.2) +\n  geom_point(\n    data = station_errors,\n    aes(x = start_lon.y, y = start_lat.x, color = MAE),\n    size = 3.5,\n    alpha = 0.7\n  ) +\n  scale_color_viridis(\n    option = \"plasma\",\n    name = \"MAE\\n(trips)\",\n    direction = -1,\n    breaks = c(0.5, 1.0, 1.5),  # Fewer, cleaner breaks\n    labels = c(\"0.5\", \"1.0\", \"1.5\")\n  ) +\n  labs(title = \"Prediction Errors \",\n       subtitle = \"Model 7\") +\n  mapTheme +\n  theme(\n    legend.position = \"right\",\n    legend.title = element_text(size = 10, face = \"bold\"),\n    legend.text = element_text(size = 9),\n    plot.title = element_text(size = 14, face = \"bold\"),\n    plot.subtitle = element_text(size = 10)\n  ) +\n  guides(color = guide_colorbar(\n    barwidth = 1.5,\n    barheight = 12,\n    title.position = \"top\",\n    title.hjust = 0.5\n  ))\n\np1 | p1.1\n```\n\n::: {.cell-output-display}\n![](Knox_Katie_Assignment5_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n**Model 7 MAEs are less severe in the areas just west and north of center city, however the patterns largely follow the same spatial distribution as model 2. \n\n\n**Poisson Model**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_model <- glm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day + lag1week + as.factor(month) +week+\n    nearby_roads + nearby_bikelanes + nearby_stations,\n  data = train,\n  family = poisson(link = \"log\")\n)\n\nsummary(p_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + \n    Precipitation + lag1Hour + lag3Hours + lag1day + lag1week + \n    as.factor(month) + week + nearby_roads + nearby_bikelanes + \n    nearby_stations, family = poisson(link = \"log\"), data = train)\n\nCoefficients:\n                     Estimate Std. Error z value             Pr(>|z|)    \n(Intercept)        -0.3008142  0.1055903  -2.849              0.00439 ** \nas.factor(hour)1   -0.4532014  0.0312112 -14.520 < 0.0000000000000002 ***\nas.factor(hour)2   -0.7459004  0.0339418 -21.976 < 0.0000000000000002 ***\nas.factor(hour)3   -1.3348163  0.0427056 -31.256 < 0.0000000000000002 ***\nas.factor(hour)4   -1.2040168  0.0400945 -30.029 < 0.0000000000000002 ***\nas.factor(hour)5   -0.0591638  0.0279322  -2.118              0.03417 *  \nas.factor(hour)6    0.8693465  0.0229103  37.946 < 0.0000000000000002 ***\nas.factor(hour)7    1.2721808  0.0217796  58.412 < 0.0000000000000002 ***\nas.factor(hour)8    1.6166590  0.0208355  77.592 < 0.0000000000000002 ***\nas.factor(hour)9    1.2273334  0.0214022  57.346 < 0.0000000000000002 ***\nas.factor(hour)10   1.1005384  0.0216460  50.843 < 0.0000000000000002 ***\nas.factor(hour)11   1.1760243  0.0215526  54.565 < 0.0000000000000002 ***\nas.factor(hour)12   1.2803074  0.0211569  60.515 < 0.0000000000000002 ***\nas.factor(hour)13   1.2686336  0.0210216  60.349 < 0.0000000000000002 ***\nas.factor(hour)14   1.2881641  0.0208965  61.645 < 0.0000000000000002 ***\nas.factor(hour)15   1.3849675  0.0209103  66.234 < 0.0000000000000002 ***\nas.factor(hour)16   1.4503161  0.0206794  70.133 < 0.0000000000000002 ***\nas.factor(hour)17   1.5076652  0.0205865  73.236 < 0.0000000000000002 ***\nas.factor(hour)18   1.2402372  0.0209488  59.203 < 0.0000000000000002 ***\nas.factor(hour)19   1.0421225  0.0214496  48.585 < 0.0000000000000002 ***\nas.factor(hour)20   0.8459129  0.0220879  38.298 < 0.0000000000000002 ***\nas.factor(hour)21   0.7262344  0.0227359  31.942 < 0.0000000000000002 ***\nas.factor(hour)22   0.5944549  0.0233785  25.427 < 0.0000000000000002 ***\nas.factor(hour)23   0.3319015  0.0249391  13.308 < 0.0000000000000002 ***\ndotw_simple2        0.0465151  0.0073389   6.338  0.00000000023258043 ***\ndotw_simple3        0.0192599  0.0076119   2.530              0.01140 *  \ndotw_simple4       -0.0706125  0.0076472  -9.234 < 0.0000000000000002 ***\ndotw_simple5       -0.0686913  0.0080993  -8.481 < 0.0000000000000002 ***\ndotw_simple6       -0.0645385  0.0082180  -7.853  0.00000000000000405 ***\ndotw_simple7       -0.1279885  0.0084311 -15.181 < 0.0000000000000002 ***\nTemperature         0.0068856  0.0002791  24.666 < 0.0000000000000002 ***\nPrecipitation      -3.4025809  0.1945009 -17.494 < 0.0000000000000002 ***\nlag1Hour            0.1370088  0.0010631 128.879 < 0.0000000000000002 ***\nlag3Hours           0.0663740  0.0012058  55.045 < 0.0000000000000002 ***\nlag1day             0.0846167  0.0011095  76.263 < 0.0000000000000002 ***\nlag1week            0.0675999  0.0011719  57.683 < 0.0000000000000002 ***\nas.factor(month).L  0.1681597  0.0109417  15.369 < 0.0000000000000002 ***\nas.factor(month).Q -0.0239398  0.0045030  -5.316  0.00000010584953979 ***\nweek               -0.0602140  0.0021050 -28.605 < 0.0000000000000002 ***\nnearby_roads        0.0054790  0.0002687  20.392 < 0.0000000000000002 ***\nnearby_bikelanes    0.0011617  0.0001093  10.626 < 0.0000000000000002 ***\nnearby_stations     0.0158128  0.0002146  73.690 < 0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 621223  on 377795  degrees of freedom\nResidual deviance: 393742  on 377754  degrees of freedom\nAIC: 685434\n\nNumber of Fisher Scoring iterations: 6\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntest <- test %>%\n  mutate(\n    p_pred = predict(p_model, newdata = test, type = \"response\")\n  )\n\n# Calculate MAE for each model\nmae_results <- data.frame(\n  Model = c(\n    \"2. + Temporal Lags\",\n    \"6. Model 2 + Demographics + Station FE + Rush Hour Interaction + Week Lag + Nearby Features\",\n    \"7. Model 2 + Week Lag + Nearby Features\",\n    \"Poisson Model (Same Variables as Model 7)\"\n  ),\n  MAE = c(\n    mean(abs(test$Trip_Count - test$pred2), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred6), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred7), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$p_pred), na.rm = TRUE)\n  )\n)\n\nkable(mae_results, \n      digits = 2,\n      caption = \"Mean Absolute Error by Model (Test Set)\",\n      col.names = c(\"Model\", \"MAE (trips)\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Mean Absolute Error by Model (Test Set)</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:right;\"> MAE (trips) </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 2. + Temporal Lags </td>\n   <td style=\"text-align:right;\"> 0.40 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 6. Model 2 + Demographics + Station FE + Rush Hour Interaction + Week Lag + Nearby Features </td>\n   <td style=\"text-align:right;\"> 0.65 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 7. Model 2 + Week Lag + Nearby Features </td>\n   <td style=\"text-align:right;\"> 0.41 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Poisson Model (Same Variables as Model 7) </td>\n   <td style=\"text-align:right;\"> 0.41 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n**The Poisson Model does not improve MAE very much, however it does not result in any negative predictions,** which inherently makes it a better method for predicting trip counts in this context.\n\n## Part 4: Critical Reflection \n\nOverall, I would not recommend using any of the models produced in this study in order to predict real, exact bike station counts, however they could be useful rather in posing questions for further research into what factors affect bike station use the most, and how to make more accurate predictions at the extremes while not foregoing less busy stations. The models presented in this study all fell very short of the highest traffic station-times, and these are essential to get right in a usable model because identifying them will equate to predicting where the bulk of the bikes are at a given time in order to make redistribution more efficient. The factors that improved the model the most were time lags, meaning that the trips from a station at various times previous to the current time had a strong predictive effect, however it could be that the influence of these variables makes the model less adequate at predicting the extremes of trips. In other words, the time lags create a model that is more normalized over time, but the key to a useful model would be in predicting the more extreme trip counts that will have higher redistribution needs. The spatial distribution of prediction errors is not particularly egregious from a visual inspection of the map. \n\nThe biggest takeaway is that predicting bike share station usage by hour would benefit from additional complexity that is able to model the more extreme ends of bike share usage, perhaps using morning and evening rush as factor variables in addition to the hour of the day as a factor variable. Another aspect that might help in future iterations is accounting for holidays, again as a factor variable marking if the day is a holiday or not. Even if there is future improvement on the model, caution should be used on irregular public events or extreme weather events that will significantly skew bike trips in an unpredictable way. \n\n\n\n\n\n\n\n\n",
    "supporting": [
      "Knox_Katie_Assignment5_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}