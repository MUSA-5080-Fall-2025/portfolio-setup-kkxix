{"title":"Assignment 4: Spatial Predictive Analysis","markdown":{"yaml":{"title":"Assignment 4: Spatial Predictive Analysis","author":"Katie Knox","date":"11-16-2025","format":{"html":{"code-fold":false,"toc":true,"toc-location":"left","theme":"cosmo","embed-resources":true}},"execute":{"warning":false,"message":false}},"headingText":"Load required packages","containsRefs":false,"markdown":"\n\n```{r}\n#| echo: false\n\n\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(tigris)\nlibrary(tidycensus)\nlibrary(patchwork)\nlibrary(units)\nlibrary(knitr)\nlibrary(ggspatial)\nlibrary(ggnewscale)\nlibrary(kableExtra)\nlibrary(gridExtra)\nlibrary(FNN)\nlibrary(spdep)\nlibrary(patchwork)\nlibrary(MASS)\nlibrary(spatstat)\nlibrary(raster)\nlibrary(scales)\n\ncensus_api_key(\"42bf8a20a3df1def380f330cf7edad0dd5842ce6\")\n```\n## Part 1: Collect 311 Violation Data\n\nI have chosen to look at \"All street lights out\" violations, because it is more cozy to commit crimes when the lights are out. \n\n```{r}\n#| echo: false\n\nall_lights_out <- read.csv(\"C:/Users/knoxk/OneDrive/Documents/musa-5080/portfolio-setup-kkxix/labs/lab_4/data/311_Service_Requests_-_Street_Lights_-_All_Out_-_Historical_20251116.csv\")\n\nall_lights_out <- all_lights_out %>%\n  filter(!is.na(Latitude), !is.na(Longitude)) %>%\n  st_as_sf(coords = c(\"Longitude\", \"Latitude\"), crs = 4326) \n\n\ntmp <- capture.output(chi_boundary <- places(state = \"IL\", cb = TRUE) %>%\n  filter(NAME == \"Chicago\") %>%\n  st_as_sf()  )\n\n```\n\n```{r}\n\nchi_boundary<-chi_boundary%>%st_transform(st_crs(all_lights_out))\n\nchi_boundary<-chi_boundary%>%st_transform(26971)\nall_lights_out<-all_lights_out%>%st_transform(26971)\n\nall_lights_out%>%\n  ggplot()+\n  geom_sf(alpha = 0.1, color = \"lightblue\")+\n  geom_sf(data = chi_boundary, fill = NA, color = \"darkgreen\")+\n  theme_void()\n```\nThe 311 complaints of all street lights out are seemingly very ubiquitous across Chicago! Every part of the city is very visual dense with instances. The only empty areas are where the airport is located, and where there are bodies of water and parks. \n\n\n## Part 2: Fishnet Grid\n\n```{r}\n# Step 1: Define cell size (in map units - meters for this projection)\ncell_size <- 500  # 500m x 500m cells\n\n# Step 2: Create grid over study area\nfishnet <- st_make_grid(\n  chi_boundary,\n  cellsize = cell_size,\n  square = TRUE,\n  what = \"polygons\"\n) %>%\n  st_sf() %>%\n  mutate(uniqueID = row_number())\n\n# Step 3: Clip to study area (remove cells outside boundary)\nfishnet <- fishnet[chi_boundary, ]\n\n# Check results\nnrow(fishnet)  # Number of cells\nst_area(fishnet[1, ])  # Area of one cell (should be 250,000 m²)\n\nfishnet %>%\n  ggplot()+\n  geom_sf()+\n  geom_sf(data = chi_boundary, fill=NA, color=\"darkgreen\")+\n  theme_void()\n```\n```{r}\n# Count lights out per cell\nlights_out_count <- st_join(all_lights_out, fishnet) %>%\n  st_drop_geometry() %>%\n  group_by(uniqueID) %>%\n  summarize(count = n())\n\n# Join back to fishnet\nfishnet <- fishnet %>%\n  left_join(lights_out_count, by = \"uniqueID\") %>%\n  mutate(count_lights_out = replace_na(count, 0))\n\n# Summary\nsummary(fishnet$count_lights_out)\n```\n## Part 3: Spatial Features\n\nFind \"Nearest Neighbor\"\n\n```{r}\n\n# Calculate distance to nearest complaint of all street lights out\nnn_dist <- get.knnx(\n  data = st_coordinates(all_lights_out),      # \"To\" locations\n  query = st_coordinates(st_centroid(fishnet)), # \"From\" locations\n  k = 1                                          # Nearest 1\n)\n\n# Extract distances\nfishnet$lights_out_dists <- nn_dist$nn.dist[, 1]\nsummary(fishnet$lights_out_dists)\n```\n\nThe median distance from a random 500x500 area in Chicago to a reported incident of all street lights out is 54 meters, and the 3rd quantile is 124 meters. This means the majority of ares in Chicago are very near one such complaint (and likely more than one given the distribution of incident counts per grid cell from the previous step). The mean is higher that the 3rd quantile, showing that max distance is an extreme outlier, likely in one of the park or airport areas where there probably aren't streets in a park let alone street lights. \n\nFind Local Moran's I\n```{r}\n\n# Step 1: Create spatial object\nfishnet_sp <- as_Spatial(fishnet)\n\n# Step 2: Define neighbors (Queen contiguity)\nneighbors <- poly2nb(fishnet_sp, queen = TRUE)\n\n# Step 3: Create spatial weights (row-standardized)\nweights <- nb2listw(neighbors, style = \"W\", zero.policy = TRUE)\n\n# Step 4: Calculate Local Moran's I\nlocal_moran <- localmoran(\n  fishnet$count_lights_out,  # Variable of interest\n  weights,                  # Spatial weights\n  zero.policy = TRUE       # Handle cells with no neighbors\n)\n\n# Step 5: Extract components\nfishnet$local_I <- local_moran[, \"Ii\"]      # Local I statistic\nfishnet$p_value <- local_moran[, \"Pr(z != E(Ii))\"]  # P-value\nfishnet$z_score <- local_moran[, \"Z.Ii\"]    # Z-score\n```\n\n```{r}\n# Standardize the variable for quadrant classification\nfishnet$standardized_value <- scale(fishnet$count_lights_out)\n\n# Calculate spatial lag (weighted mean of neighbors)\nfishnet$spatial_lag <- lag.listw(weights, fishnet$count_lights_out)\nfishnet$standardized_lag <- scale(fishnet$spatial_lag)\n\n# Identify High-High clusters\nfishnet$hotspot <- 0  # Default: not a hotspot\n\n# Criteria: \n# 1. Value above mean (standardized > 0)\n# 2. Neighbors above mean (spatial lag > 0)\n# 3. Statistically significant (p < 0.05)\n\nfishnet$hotspot[\n  fishnet$standardized_value > 0 & \n  fishnet$standardized_lag > 0 & \n  fishnet$p_value < 0.05\n] <- 1\n\n# Count hotspots\nsum(fishnet$hotspot)\n```\nIn this step, first each cell’s count of incidents is standardized to measure how much it deviates from the mean, and a spatial lag is calculated to summarize the average counts in neighboring cells based on the intution that areas with high incident counts tend to be near other areas with high counts, so clustering in space can reveal meaningful hotspots of activity. Cells are classified as High-High clusters (hotspots) if they have above-average counts, are surrounded by neighbors with above-average counts, and are statistically significant based on Local Moran’s I (p < 0.05). The fact that the sum of hotspots is 418 indicates that 418 grid cells are part of statistically significant clusters of high incident density. \n\n```{r}\nfishnet%>%filter(hotspot==1)%>%\n  ggplot()+\n  geom_sf()+\n  theme_void()+\n  geom_sf(data = chi_boundary, fill = NA, color = \"darkgreen\")\n```\nLooking at a map of these hotspots reveals they are concentrated in areas west and south of the main center city core. \n\nNext, I find distance of each grid cell to hotspot.\n```{r}\n# Step 1: Identify hotspots \nhotspot_cells <- filter(fishnet, hotspot == 1)\n\n# Step 2: Calculate distances\nhotspot_dist <- get.knnx(\n  data = st_coordinates(st_centroid(hotspot_cells)),\n  query = st_coordinates(st_centroid(fishnet)),\n  k = 1\n)\n\nfishnet$hotspot_nn <- hotspot_dist$nn.dist[, 1]\n```\n\n```{r}\n# Create comparison maps\np1 <- ggplot(fishnet) +\n  geom_sf(aes(fill = lights_out_dists), color = NA) +\n  scale_fill_viridis_c(name = \"Distance (m)\", option = \"plasma\",  direction = -1) +\n  labs(title = \"Distance to Nearest Complaint\\nof All Street Lights Out\") +\n  theme_void()\n\n\np2 <- ggplot(fishnet) +\n  geom_sf(aes(fill = hotspot_nn), color = NA) +\n  scale_fill_viridis_c(name = \"Distance (m)\", option = \"plasma\",  direction = -1) +\n  labs(title = \"Distance to Nearest Hotspot\") +\n  theme_void()\n\np1 + p2 + plot_layout(ncol = 2)\n```\nThe distribution of distances shows that individual complaints are much more spatially heterogeneous than the hotspots. While the nearest-complaint distances vary widely across the city, the nearest-hotspot distances are more uniform. This indicates that 311 service requests are concentrated in clusters, and once these clusters are aggregated into hotspots, the spatial variation smooths out. In other words, individual incidents occur in scattered patterns, but the resulting hotspots capture the broader areas of high activity, providing a clearer picture of concentrated problem areas.\n\n## Part 4: Count Regression Models \n\nCollect crimes data and join crime counts to fishnet\n```{r}\ncrimes <- read.csv(\"C:/Users/knoxk/Downloads/Crimes_-_2018_20251117.csv\")\ncrimes <- crimes%>%filter(!is.na(Latitude) & !is.na(Longitude))\ncrimes_sf <- crimes %>% st_as_sf(coords = c(\"Longitude\", \"Latitude\"), crs = 4326) \ncrimes_sf <- crimes_sf %>% st_transform(26971)\n\ncrimes_sf%>%\n  ggplot()+\n  geom_sf(alpha = 0.1, color = \"violetred\")+\n  geom_sf(data = chi_boundary, fill = NA, color = \"darkgreen\")+\n  theme_void()\n\n```\n```{r}\n# Count lights out per cell\ncrime_count <- st_join(crimes_sf, fishnet) %>%\n  st_drop_geometry() %>%\n  group_by(uniqueID) %>%\n  summarize(crime_count = n())\n\n# Join back to fishnet\nfishnet <- fishnet %>%\n  left_join(crime_count, by = \"uniqueID\") %>%\n  mutate(crime_count = replace_na(crime_count, 0))\n\n# Summary\nsummary(fishnet$crime_count)\n```\nThis shows the distribution of crimes per fishnet grid. \n\n```{r}\n# Fit Poisson model\nmodel_poisson <- glm(\n  crime_count ~ count_lights_out + lights_out_dists,\n  data = fishnet,\n  family = poisson(link = \"log\")\n)\n\n# View results\nsummary(model_poisson)\n\n# Exponentiate coefficients for interpretation\nexp(coef(model_poisson))\n```\nUsing a Poisson Regression where the dependent variable is the number of crimes in a grid cell and the dependent variables are the count of complaints of lights out and distance from grid center to nearest complaint of lights out. The model shows that areas with more “lights out” complaints tend to have slightly higher crime counts. Specifically, each additional street light reported as out in a grid cell is associated with a small increase in the expected number of crimes. Conversely, the farther a location is from the nearest street light outage, the slightly lower the expected crime count. In other words, crimes tend to be more common in areas where street lights are out or clustered, suggesting a very very small link between lighting conditions and crime risk.\n\n```{r}\n# Calculate dispersion parameter\nmodel_pois <- glm(\n  crime_count ~ count_lights_out + lights_out_dists,\n  data = fishnet,\n  family = poisson\n)\n\ndispersion <- sum(residuals(model_pois, type = \"pearson\")^2) / model_pois$df.residual\n\ncat(\"Dispersion parameter:\", round(dispersion, 3), \"\\n\")\n\n```\nThis dispersion is quite enormous, and shows that the variance is significantly higher than the mean, which violates an assumption of the Poisson Model. \n\n```{r}\n\n# Fit Negative Binomial model\nmodel_nb <- glm.nb(\n  crime_count ~ count_lights_out + lights_out_dists,\n  data = fishnet,\n  init.theta = 1,      # starting value for dispersion\n  control = glm.control(epsilon = 1e-8, maxit = 50)\n)\n\n# View results\nsummary(model_nb)\n\n# Compare to Poisson\nAIC(model_poisson)\nAIC(model_nb) \n\n```\nA Negative Binomial model is a type of count regression that estimates the relationship between predictor variables and a count outcome while accounting for overdispersion, making it appropriate when the variance of the counts exceeds the mean, as is the case here. \n\nEach additional street light reported as out is associated with an approximately 0.78% increase in expected crime counts, while each additional meter further from the nearest lights-out complaint is associated with an approximately 0.08% decrease. These effects are statistically significant, though quite small in magnitude, and the negative binomial model accounts for overdispersion in crime counts, providing more reliable estimates than the Poisson Model. This is supported by the NB model's much lower AIC.\n\n## Part 5: Spatial Cross-Validation\n\nJoin districts to fishnet:\n```{r}\ncrime_count_dist <- crimes_sf %>%\n  st_join(fishnet) %>%\n  st_drop_geometry() %>%\n  group_by(uniqueID, District) %>% \n  summarize(crime_count = n(), .groups = \"drop\")  \n\ncrime_count_dist_unique <- crime_count_dist %>%\n  group_by(uniqueID) %>%\n  summarise(\n    crime_count = sum(crime_count, na.rm = TRUE),\n    District = first(District)  # pick first district if multiple\n  )\n\n# Join back to fishnet\nfishnet_2018 <- fishnet %>%\n  left_join(crime_count_dist_unique, by = \"uniqueID\") %>%\n  mutate(\n    crime_count = replace_na(fishnet$crime_count, 0),\n    District = District  \n  )%>%filter(!is.na(District))\n\nfishnet_2018 <- fishnet_2018 %>% \n  filter(District != 1 & District != 31)\n```\n\n```{r}\n# Get unique districts\ndistricts <- unique(fishnet_2018$District)\n\n# Initialize results\ncv_results <- list()\n\n# Loop through districts\nfor (dist in districts) {\n  # Split data\n  train_data <- fishnet_2018 %>% filter(District != dist)\n  test_data <- fishnet_2018 %>% filter(District == dist)\n  \n  # Fit model on training data\n  model_cv <- glm.nb(\n  crime_count ~ count_lights_out + lights_out_dists,\n  data = train_data,\n  init.theta = .1,  # starting value for dispersion\n  control = glm.control(maxit = 50, epsilon = 1e-8)\n)\n  \n  # Predict on test data\n  test_data$prediction <- predict(model_cv, test_data, type = \"response\")\n  \n  # Store results\n  cv_results[[dist]] <- test_data\n}\n\n# Combine all predictions\nall_predictions <- bind_rows(cv_results)\n\n# Calculate metrics by district\ncv_metrics <- all_predictions %>%\n  group_by(District) %>%\n  summarize(\n    MAE = mean(abs(crime_count - prediction)),\n    RMSE = sqrt(mean((crime_count - prediction)^2)),\n    ME = mean(crime_count - prediction)\n  )\n```\n```{r}\n# Map prediction errors\nall_predictions <- all_predictions %>%\n  mutate(\n    error = crime_count - prediction,\n    abs_error = abs(error),\n    pct_error = (prediction - crime_count) / (crime_count + 1) * 100\n  )\n\n# Visualize\nggplot(all_predictions) +\n  geom_sf(aes(fill = error), color = NA) +\n  scale_fill_gradient2(\n    low = \"blue\", mid = \"white\", high = \"red\",\n    midpoint = 0,\n    name = \"Error\"\n  ) +\n  labs(title = \"Prediction Errors\",\n       subtitle = \"Red = Over-prediction, Blue = Under-prediction\") +\n  theme_void()\n```\nThis analysis shows that under-predictions of crimes produced by our model are concentrated in south Chicago, whereas over-predilections are concentrated in more central areas. This indicates that street lights outtages are not able to account for the distribution of crime across the city. \n\n## Part 6: Model Evaluation\n\n```{r}\npreds <- all_predictions %>%\n  sf::st_drop_geometry() %>%\n  dplyr::select(uniqueID, prediction)\n\nfishnet_2018 <- fishnet_2018 %>%\n  dplyr::left_join(preds, by = \"uniqueID\")\n\n# Step 1: Convert to point pattern (ppp) object\nlights_out_ppp <- as.ppp(\n  X = st_coordinates(all_lights_out),\n  W = as.owin(st_bbox(chi_boundary))\n)\n\n# Step 2: Calculate KDE\nkde_surface <- density.ppp(\n  lights_out_ppp,\n  sigma = 1000,  # Bandwidth in meters\n  edge = TRUE    # Edge correction\n)\n\n# Step 3: Extract values to fishnet cells\nfishnet_2018$kde_risk <- raster::extract(\n  raster(kde_surface),\n  st_centroid(fishnet_2018)\n)\n\n# Standardize to 0-1 scale for comparison\nfishnet_2018$kde_risk <- (fishnet_2018$kde_risk - min(fishnet_2018$kde_risk, na.rm=T)) / \n                     (max(fishnet_2018$kde_risk, na.rm=T) - min(fishnet_2018$kde_risk, na.rm=T))\n\n# Create quintiles (5 equal groups)\nfishnet_2018$model_risk_category <- cut(\n  fishnet_2018$prediction,\n  breaks = quantile(fishnet_2018$prediction, probs = seq(0, 1, 0.2)),\n  labels = c(\"1st (Lowest)\", \"2nd\", \"3rd\", \"4th\", \"5th (Highest)\"),\n  include.lowest = TRUE\n)\n\nfishnet_2018$kde_risk_category <- cut(\n  fishnet_2018$kde_risk,\n  breaks = quantile(fishnet_2018$kde_risk, probs = seq(0, 1, 0.2)),\n  labels = c(\"1st (Lowest)\", \"2nd\", \"3rd\", \"4th\", \"5th (Highest)\"),\n  include.lowest = TRUE\n)\n\n\np3 <- ggplot(fishnet_2018) +\n  geom_sf(aes(fill = model_risk_category), color = NA) +\n  labs(title = \"Model Risk Quintiles\") +\n  theme_void()\n\np4 <- ggplot(fishnet_2018) +\n  geom_sf(aes(fill = kde_risk_category), color = NA) +\n  labs(title = \"KDE Risk Quintiles\") +\n  theme_void()\n\np3 + p4\n\n```\n```{r}\n# Spatial join: 2018 crimes to fishnet with risk categories\nresults_2018 <- st_join(fishnet_2018, crimes_sf) %>%\n  group_by(model_risk_category) %>%\n  summarize(crimes_sf = n()) %>%\n  mutate(pct_of_total = 100 * crimes_sf / sum(crimes_sf))%>%\n  dplyr::select(\"model_risk_category\", \"pct_of_total\")\n\nkde_2018 <- st_join(fishnet_2018, crimes_sf) %>%\n  group_by(kde_risk_category) %>%\n  summarize(crimes_sf = n()) %>%\n  mutate(pct_of_total = 100 * crimes_sf / sum(crimes_sf))%>%\n  dplyr::select(\"kde_risk_category\", \"pct_of_total\")\n\nkde_2018<- kde_2018%>%st_drop_geometry\nresults_2018<- results_2018%>%st_drop_geometry\n\nresults_2018_clean <- results_2018 %>%\n  rename(\n    `Model Risk Category` = model_risk_category,\n    `Percent of Crimes` = pct_of_total\n  ) %>%\n  mutate(\n    `Percent of Crimes` = percent(`Percent of Crimes`/100, accuracy = 0.1)\n  )\n\nkde_2018_clean <- kde_2018 %>%\n  rename(\n    `KDE Risk Category` = kde_risk_category,\n    `Percent of Crimes` = pct_of_total\n  ) %>%\n  mutate(\n    `Percent of Crimes` = percent(`Percent of Crimes`/100, accuracy = 0.1)\n  )\n\nkbl(\n  list(results_2018_clean, kde_2018_clean),\n  caption = \"Model Risk Areas vs KDE Risk Areas and Percentage of Crimes in Risk Areas\"\n) %>% \n  kable_classic(full_width = FALSE)\n```\nAs this table shows, the highest risk area identified by the model account for a slightly smaller percentage of total crimes than the KDE highest risk area. This shows that the model based on street light outtage reports slightly underperforms simply examining peak crime location by historical data in order to account for higher proportions of crime. \n\n\n\n\n","srcMarkdownNoYaml":"\n\n```{r}\n#| echo: false\n\n\n# Load required packages\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(tigris)\nlibrary(tidycensus)\nlibrary(patchwork)\nlibrary(units)\nlibrary(knitr)\nlibrary(ggspatial)\nlibrary(ggnewscale)\nlibrary(kableExtra)\nlibrary(gridExtra)\nlibrary(FNN)\nlibrary(spdep)\nlibrary(patchwork)\nlibrary(MASS)\nlibrary(spatstat)\nlibrary(raster)\nlibrary(scales)\n\ncensus_api_key(\"42bf8a20a3df1def380f330cf7edad0dd5842ce6\")\n```\n## Part 1: Collect 311 Violation Data\n\nI have chosen to look at \"All street lights out\" violations, because it is more cozy to commit crimes when the lights are out. \n\n```{r}\n#| echo: false\n\nall_lights_out <- read.csv(\"C:/Users/knoxk/OneDrive/Documents/musa-5080/portfolio-setup-kkxix/labs/lab_4/data/311_Service_Requests_-_Street_Lights_-_All_Out_-_Historical_20251116.csv\")\n\nall_lights_out <- all_lights_out %>%\n  filter(!is.na(Latitude), !is.na(Longitude)) %>%\n  st_as_sf(coords = c(\"Longitude\", \"Latitude\"), crs = 4326) \n\n\ntmp <- capture.output(chi_boundary <- places(state = \"IL\", cb = TRUE) %>%\n  filter(NAME == \"Chicago\") %>%\n  st_as_sf()  )\n\n```\n\n```{r}\n\nchi_boundary<-chi_boundary%>%st_transform(st_crs(all_lights_out))\n\nchi_boundary<-chi_boundary%>%st_transform(26971)\nall_lights_out<-all_lights_out%>%st_transform(26971)\n\nall_lights_out%>%\n  ggplot()+\n  geom_sf(alpha = 0.1, color = \"lightblue\")+\n  geom_sf(data = chi_boundary, fill = NA, color = \"darkgreen\")+\n  theme_void()\n```\nThe 311 complaints of all street lights out are seemingly very ubiquitous across Chicago! Every part of the city is very visual dense with instances. The only empty areas are where the airport is located, and where there are bodies of water and parks. \n\n\n## Part 2: Fishnet Grid\n\n```{r}\n# Step 1: Define cell size (in map units - meters for this projection)\ncell_size <- 500  # 500m x 500m cells\n\n# Step 2: Create grid over study area\nfishnet <- st_make_grid(\n  chi_boundary,\n  cellsize = cell_size,\n  square = TRUE,\n  what = \"polygons\"\n) %>%\n  st_sf() %>%\n  mutate(uniqueID = row_number())\n\n# Step 3: Clip to study area (remove cells outside boundary)\nfishnet <- fishnet[chi_boundary, ]\n\n# Check results\nnrow(fishnet)  # Number of cells\nst_area(fishnet[1, ])  # Area of one cell (should be 250,000 m²)\n\nfishnet %>%\n  ggplot()+\n  geom_sf()+\n  geom_sf(data = chi_boundary, fill=NA, color=\"darkgreen\")+\n  theme_void()\n```\n```{r}\n# Count lights out per cell\nlights_out_count <- st_join(all_lights_out, fishnet) %>%\n  st_drop_geometry() %>%\n  group_by(uniqueID) %>%\n  summarize(count = n())\n\n# Join back to fishnet\nfishnet <- fishnet %>%\n  left_join(lights_out_count, by = \"uniqueID\") %>%\n  mutate(count_lights_out = replace_na(count, 0))\n\n# Summary\nsummary(fishnet$count_lights_out)\n```\n## Part 3: Spatial Features\n\nFind \"Nearest Neighbor\"\n\n```{r}\n\n# Calculate distance to nearest complaint of all street lights out\nnn_dist <- get.knnx(\n  data = st_coordinates(all_lights_out),      # \"To\" locations\n  query = st_coordinates(st_centroid(fishnet)), # \"From\" locations\n  k = 1                                          # Nearest 1\n)\n\n# Extract distances\nfishnet$lights_out_dists <- nn_dist$nn.dist[, 1]\nsummary(fishnet$lights_out_dists)\n```\n\nThe median distance from a random 500x500 area in Chicago to a reported incident of all street lights out is 54 meters, and the 3rd quantile is 124 meters. This means the majority of ares in Chicago are very near one such complaint (and likely more than one given the distribution of incident counts per grid cell from the previous step). The mean is higher that the 3rd quantile, showing that max distance is an extreme outlier, likely in one of the park or airport areas where there probably aren't streets in a park let alone street lights. \n\nFind Local Moran's I\n```{r}\n\n# Step 1: Create spatial object\nfishnet_sp <- as_Spatial(fishnet)\n\n# Step 2: Define neighbors (Queen contiguity)\nneighbors <- poly2nb(fishnet_sp, queen = TRUE)\n\n# Step 3: Create spatial weights (row-standardized)\nweights <- nb2listw(neighbors, style = \"W\", zero.policy = TRUE)\n\n# Step 4: Calculate Local Moran's I\nlocal_moran <- localmoran(\n  fishnet$count_lights_out,  # Variable of interest\n  weights,                  # Spatial weights\n  zero.policy = TRUE       # Handle cells with no neighbors\n)\n\n# Step 5: Extract components\nfishnet$local_I <- local_moran[, \"Ii\"]      # Local I statistic\nfishnet$p_value <- local_moran[, \"Pr(z != E(Ii))\"]  # P-value\nfishnet$z_score <- local_moran[, \"Z.Ii\"]    # Z-score\n```\n\n```{r}\n# Standardize the variable for quadrant classification\nfishnet$standardized_value <- scale(fishnet$count_lights_out)\n\n# Calculate spatial lag (weighted mean of neighbors)\nfishnet$spatial_lag <- lag.listw(weights, fishnet$count_lights_out)\nfishnet$standardized_lag <- scale(fishnet$spatial_lag)\n\n# Identify High-High clusters\nfishnet$hotspot <- 0  # Default: not a hotspot\n\n# Criteria: \n# 1. Value above mean (standardized > 0)\n# 2. Neighbors above mean (spatial lag > 0)\n# 3. Statistically significant (p < 0.05)\n\nfishnet$hotspot[\n  fishnet$standardized_value > 0 & \n  fishnet$standardized_lag > 0 & \n  fishnet$p_value < 0.05\n] <- 1\n\n# Count hotspots\nsum(fishnet$hotspot)\n```\nIn this step, first each cell’s count of incidents is standardized to measure how much it deviates from the mean, and a spatial lag is calculated to summarize the average counts in neighboring cells based on the intution that areas with high incident counts tend to be near other areas with high counts, so clustering in space can reveal meaningful hotspots of activity. Cells are classified as High-High clusters (hotspots) if they have above-average counts, are surrounded by neighbors with above-average counts, and are statistically significant based on Local Moran’s I (p < 0.05). The fact that the sum of hotspots is 418 indicates that 418 grid cells are part of statistically significant clusters of high incident density. \n\n```{r}\nfishnet%>%filter(hotspot==1)%>%\n  ggplot()+\n  geom_sf()+\n  theme_void()+\n  geom_sf(data = chi_boundary, fill = NA, color = \"darkgreen\")\n```\nLooking at a map of these hotspots reveals they are concentrated in areas west and south of the main center city core. \n\nNext, I find distance of each grid cell to hotspot.\n```{r}\n# Step 1: Identify hotspots \nhotspot_cells <- filter(fishnet, hotspot == 1)\n\n# Step 2: Calculate distances\nhotspot_dist <- get.knnx(\n  data = st_coordinates(st_centroid(hotspot_cells)),\n  query = st_coordinates(st_centroid(fishnet)),\n  k = 1\n)\n\nfishnet$hotspot_nn <- hotspot_dist$nn.dist[, 1]\n```\n\n```{r}\n# Create comparison maps\np1 <- ggplot(fishnet) +\n  geom_sf(aes(fill = lights_out_dists), color = NA) +\n  scale_fill_viridis_c(name = \"Distance (m)\", option = \"plasma\",  direction = -1) +\n  labs(title = \"Distance to Nearest Complaint\\nof All Street Lights Out\") +\n  theme_void()\n\n\np2 <- ggplot(fishnet) +\n  geom_sf(aes(fill = hotspot_nn), color = NA) +\n  scale_fill_viridis_c(name = \"Distance (m)\", option = \"plasma\",  direction = -1) +\n  labs(title = \"Distance to Nearest Hotspot\") +\n  theme_void()\n\np1 + p2 + plot_layout(ncol = 2)\n```\nThe distribution of distances shows that individual complaints are much more spatially heterogeneous than the hotspots. While the nearest-complaint distances vary widely across the city, the nearest-hotspot distances are more uniform. This indicates that 311 service requests are concentrated in clusters, and once these clusters are aggregated into hotspots, the spatial variation smooths out. In other words, individual incidents occur in scattered patterns, but the resulting hotspots capture the broader areas of high activity, providing a clearer picture of concentrated problem areas.\n\n## Part 4: Count Regression Models \n\nCollect crimes data and join crime counts to fishnet\n```{r}\ncrimes <- read.csv(\"C:/Users/knoxk/Downloads/Crimes_-_2018_20251117.csv\")\ncrimes <- crimes%>%filter(!is.na(Latitude) & !is.na(Longitude))\ncrimes_sf <- crimes %>% st_as_sf(coords = c(\"Longitude\", \"Latitude\"), crs = 4326) \ncrimes_sf <- crimes_sf %>% st_transform(26971)\n\ncrimes_sf%>%\n  ggplot()+\n  geom_sf(alpha = 0.1, color = \"violetred\")+\n  geom_sf(data = chi_boundary, fill = NA, color = \"darkgreen\")+\n  theme_void()\n\n```\n```{r}\n# Count lights out per cell\ncrime_count <- st_join(crimes_sf, fishnet) %>%\n  st_drop_geometry() %>%\n  group_by(uniqueID) %>%\n  summarize(crime_count = n())\n\n# Join back to fishnet\nfishnet <- fishnet %>%\n  left_join(crime_count, by = \"uniqueID\") %>%\n  mutate(crime_count = replace_na(crime_count, 0))\n\n# Summary\nsummary(fishnet$crime_count)\n```\nThis shows the distribution of crimes per fishnet grid. \n\n```{r}\n# Fit Poisson model\nmodel_poisson <- glm(\n  crime_count ~ count_lights_out + lights_out_dists,\n  data = fishnet,\n  family = poisson(link = \"log\")\n)\n\n# View results\nsummary(model_poisson)\n\n# Exponentiate coefficients for interpretation\nexp(coef(model_poisson))\n```\nUsing a Poisson Regression where the dependent variable is the number of crimes in a grid cell and the dependent variables are the count of complaints of lights out and distance from grid center to nearest complaint of lights out. The model shows that areas with more “lights out” complaints tend to have slightly higher crime counts. Specifically, each additional street light reported as out in a grid cell is associated with a small increase in the expected number of crimes. Conversely, the farther a location is from the nearest street light outage, the slightly lower the expected crime count. In other words, crimes tend to be more common in areas where street lights are out or clustered, suggesting a very very small link between lighting conditions and crime risk.\n\n```{r}\n# Calculate dispersion parameter\nmodel_pois <- glm(\n  crime_count ~ count_lights_out + lights_out_dists,\n  data = fishnet,\n  family = poisson\n)\n\ndispersion <- sum(residuals(model_pois, type = \"pearson\")^2) / model_pois$df.residual\n\ncat(\"Dispersion parameter:\", round(dispersion, 3), \"\\n\")\n\n```\nThis dispersion is quite enormous, and shows that the variance is significantly higher than the mean, which violates an assumption of the Poisson Model. \n\n```{r}\n\n# Fit Negative Binomial model\nmodel_nb <- glm.nb(\n  crime_count ~ count_lights_out + lights_out_dists,\n  data = fishnet,\n  init.theta = 1,      # starting value for dispersion\n  control = glm.control(epsilon = 1e-8, maxit = 50)\n)\n\n# View results\nsummary(model_nb)\n\n# Compare to Poisson\nAIC(model_poisson)\nAIC(model_nb) \n\n```\nA Negative Binomial model is a type of count regression that estimates the relationship between predictor variables and a count outcome while accounting for overdispersion, making it appropriate when the variance of the counts exceeds the mean, as is the case here. \n\nEach additional street light reported as out is associated with an approximately 0.78% increase in expected crime counts, while each additional meter further from the nearest lights-out complaint is associated with an approximately 0.08% decrease. These effects are statistically significant, though quite small in magnitude, and the negative binomial model accounts for overdispersion in crime counts, providing more reliable estimates than the Poisson Model. This is supported by the NB model's much lower AIC.\n\n## Part 5: Spatial Cross-Validation\n\nJoin districts to fishnet:\n```{r}\ncrime_count_dist <- crimes_sf %>%\n  st_join(fishnet) %>%\n  st_drop_geometry() %>%\n  group_by(uniqueID, District) %>% \n  summarize(crime_count = n(), .groups = \"drop\")  \n\ncrime_count_dist_unique <- crime_count_dist %>%\n  group_by(uniqueID) %>%\n  summarise(\n    crime_count = sum(crime_count, na.rm = TRUE),\n    District = first(District)  # pick first district if multiple\n  )\n\n# Join back to fishnet\nfishnet_2018 <- fishnet %>%\n  left_join(crime_count_dist_unique, by = \"uniqueID\") %>%\n  mutate(\n    crime_count = replace_na(fishnet$crime_count, 0),\n    District = District  \n  )%>%filter(!is.na(District))\n\nfishnet_2018 <- fishnet_2018 %>% \n  filter(District != 1 & District != 31)\n```\n\n```{r}\n# Get unique districts\ndistricts <- unique(fishnet_2018$District)\n\n# Initialize results\ncv_results <- list()\n\n# Loop through districts\nfor (dist in districts) {\n  # Split data\n  train_data <- fishnet_2018 %>% filter(District != dist)\n  test_data <- fishnet_2018 %>% filter(District == dist)\n  \n  # Fit model on training data\n  model_cv <- glm.nb(\n  crime_count ~ count_lights_out + lights_out_dists,\n  data = train_data,\n  init.theta = .1,  # starting value for dispersion\n  control = glm.control(maxit = 50, epsilon = 1e-8)\n)\n  \n  # Predict on test data\n  test_data$prediction <- predict(model_cv, test_data, type = \"response\")\n  \n  # Store results\n  cv_results[[dist]] <- test_data\n}\n\n# Combine all predictions\nall_predictions <- bind_rows(cv_results)\n\n# Calculate metrics by district\ncv_metrics <- all_predictions %>%\n  group_by(District) %>%\n  summarize(\n    MAE = mean(abs(crime_count - prediction)),\n    RMSE = sqrt(mean((crime_count - prediction)^2)),\n    ME = mean(crime_count - prediction)\n  )\n```\n```{r}\n# Map prediction errors\nall_predictions <- all_predictions %>%\n  mutate(\n    error = crime_count - prediction,\n    abs_error = abs(error),\n    pct_error = (prediction - crime_count) / (crime_count + 1) * 100\n  )\n\n# Visualize\nggplot(all_predictions) +\n  geom_sf(aes(fill = error), color = NA) +\n  scale_fill_gradient2(\n    low = \"blue\", mid = \"white\", high = \"red\",\n    midpoint = 0,\n    name = \"Error\"\n  ) +\n  labs(title = \"Prediction Errors\",\n       subtitle = \"Red = Over-prediction, Blue = Under-prediction\") +\n  theme_void()\n```\nThis analysis shows that under-predictions of crimes produced by our model are concentrated in south Chicago, whereas over-predilections are concentrated in more central areas. This indicates that street lights outtages are not able to account for the distribution of crime across the city. \n\n## Part 6: Model Evaluation\n\n```{r}\npreds <- all_predictions %>%\n  sf::st_drop_geometry() %>%\n  dplyr::select(uniqueID, prediction)\n\nfishnet_2018 <- fishnet_2018 %>%\n  dplyr::left_join(preds, by = \"uniqueID\")\n\n# Step 1: Convert to point pattern (ppp) object\nlights_out_ppp <- as.ppp(\n  X = st_coordinates(all_lights_out),\n  W = as.owin(st_bbox(chi_boundary))\n)\n\n# Step 2: Calculate KDE\nkde_surface <- density.ppp(\n  lights_out_ppp,\n  sigma = 1000,  # Bandwidth in meters\n  edge = TRUE    # Edge correction\n)\n\n# Step 3: Extract values to fishnet cells\nfishnet_2018$kde_risk <- raster::extract(\n  raster(kde_surface),\n  st_centroid(fishnet_2018)\n)\n\n# Standardize to 0-1 scale for comparison\nfishnet_2018$kde_risk <- (fishnet_2018$kde_risk - min(fishnet_2018$kde_risk, na.rm=T)) / \n                     (max(fishnet_2018$kde_risk, na.rm=T) - min(fishnet_2018$kde_risk, na.rm=T))\n\n# Create quintiles (5 equal groups)\nfishnet_2018$model_risk_category <- cut(\n  fishnet_2018$prediction,\n  breaks = quantile(fishnet_2018$prediction, probs = seq(0, 1, 0.2)),\n  labels = c(\"1st (Lowest)\", \"2nd\", \"3rd\", \"4th\", \"5th (Highest)\"),\n  include.lowest = TRUE\n)\n\nfishnet_2018$kde_risk_category <- cut(\n  fishnet_2018$kde_risk,\n  breaks = quantile(fishnet_2018$kde_risk, probs = seq(0, 1, 0.2)),\n  labels = c(\"1st (Lowest)\", \"2nd\", \"3rd\", \"4th\", \"5th (Highest)\"),\n  include.lowest = TRUE\n)\n\n\np3 <- ggplot(fishnet_2018) +\n  geom_sf(aes(fill = model_risk_category), color = NA) +\n  labs(title = \"Model Risk Quintiles\") +\n  theme_void()\n\np4 <- ggplot(fishnet_2018) +\n  geom_sf(aes(fill = kde_risk_category), color = NA) +\n  labs(title = \"KDE Risk Quintiles\") +\n  theme_void()\n\np3 + p4\n\n```\n```{r}\n# Spatial join: 2018 crimes to fishnet with risk categories\nresults_2018 <- st_join(fishnet_2018, crimes_sf) %>%\n  group_by(model_risk_category) %>%\n  summarize(crimes_sf = n()) %>%\n  mutate(pct_of_total = 100 * crimes_sf / sum(crimes_sf))%>%\n  dplyr::select(\"model_risk_category\", \"pct_of_total\")\n\nkde_2018 <- st_join(fishnet_2018, crimes_sf) %>%\n  group_by(kde_risk_category) %>%\n  summarize(crimes_sf = n()) %>%\n  mutate(pct_of_total = 100 * crimes_sf / sum(crimes_sf))%>%\n  dplyr::select(\"kde_risk_category\", \"pct_of_total\")\n\nkde_2018<- kde_2018%>%st_drop_geometry\nresults_2018<- results_2018%>%st_drop_geometry\n\nresults_2018_clean <- results_2018 %>%\n  rename(\n    `Model Risk Category` = model_risk_category,\n    `Percent of Crimes` = pct_of_total\n  ) %>%\n  mutate(\n    `Percent of Crimes` = percent(`Percent of Crimes`/100, accuracy = 0.1)\n  )\n\nkde_2018_clean <- kde_2018 %>%\n  rename(\n    `KDE Risk Category` = kde_risk_category,\n    `Percent of Crimes` = pct_of_total\n  ) %>%\n  mutate(\n    `Percent of Crimes` = percent(`Percent of Crimes`/100, accuracy = 0.1)\n  )\n\nkbl(\n  list(results_2018_clean, kde_2018_clean),\n  caption = \"Model Risk Areas vs KDE Risk Areas and Percentage of Crimes in Risk Areas\"\n) %>% \n  kable_classic(full_width = FALSE)\n```\nAs this table shows, the highest risk area identified by the model account for a slightly smaller percentage of total crimes than the KDE highest risk area. This shows that the model based on street light outtage reports slightly underperforms simply examining peak crime location by historical data in order to account for higher proportions of crime. \n\n\n\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"message":false,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"embed-resources":true,"output-file":"Knox_Katie_Assignment4.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.8.24","theme":"cosmo","title":"Assignment 4: Spatial Predictive Analysis","author":"Katie Knox","date":"11-16-2025","toc-location":"left"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}