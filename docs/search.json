[
  {
    "objectID": "weekly-notes/week-02-notes.html",
    "href": "weekly-notes/week-02-notes.html",
    "title": "Week 2 Notes",
    "section": "",
    "text": "Main concepts:\n\nBest practices for coding in R\nWhat are algorithms\nCensus data foundations\nData Analytics are Subjective\n\nTechnical skills covered:\n\ndplyr basics practice\ntidycensus"
  },
  {
    "objectID": "weekly-notes/week-02-notes.html#key-concepts-learned",
    "href": "weekly-notes/week-02-notes.html#key-concepts-learned",
    "title": "Week 2 Notes",
    "section": "",
    "text": "Main concepts:\n\nBest practices for coding in R\nWhat are algorithms\nCensus data foundations\nData Analytics are Subjective\n\nTechnical skills covered:\n\ndplyr basics practice\ntidycensus"
  },
  {
    "objectID": "weekly-notes/week-02-notes.html#coding-techniques",
    "href": "weekly-notes/week-02-notes.html#coding-techniques",
    "title": "Week 2 Notes",
    "section": "Coding Techniques",
    "text": "Coding Techniques"
  },
  {
    "objectID": "weekly-notes/week-02-notes.html#questions-challenges",
    "href": "weekly-notes/week-02-notes.html#questions-challenges",
    "title": "Week 2 Notes",
    "section": "Questions & Challenges",
    "text": "Questions & Challenges"
  },
  {
    "objectID": "weekly-notes/week-02-notes.html#connections-to-policy",
    "href": "weekly-notes/week-02-notes.html#connections-to-policy",
    "title": "Week 2 Notes",
    "section": "Connections to Policy",
    "text": "Connections to Policy"
  },
  {
    "objectID": "weekly-notes/week-02-notes.html#reflection",
    "href": "weekly-notes/week-02-notes.html#reflection",
    "title": "Week 2 Notes",
    "section": "Reflection",
    "text": "Reflection"
  },
  {
    "objectID": "instructions_week1.html",
    "href": "instructions_week1.html",
    "title": "Portfolio Setup Instructions",
    "section": "",
    "text": "Welcome to MUSA 5080! This guide will help you set up your personal portfolio repository for the semester.\n\n\nBy the end of this setup, you’ll have: - Your own portfolio repository on GitHub - live website showcasing your work - A place to document your learning journey\n\n\n\n\nThis is what you are building: Dr. Delmelle’s sample portfolio\n\n\n\n\nBefore starting, make sure you have: - [ ] A GitHub account (create one here if needed) - [ ] Quarto installed on your computer (download here) - [ ] R and RStudio installed\n\n\n\n\n\nYou should already be in your personal repository (created when you accepted the GitHub Classroom assignment). Now let’s personalize it!\n\n\n\nClick on the _quarto.yml file\nClick the pencil icon (✏️) to edit\nChange \"Your Name - MUSA 5080 Portfolio\" to include your actual name\nExample: \"Jane Smith - MUSA 5080 Portfolio\"\nClick “Commit changes” at the bottom\n\n\n\n\n\nClick on the index.qmd file\nClick the pencil icon (✏️) to edit\nUpdate the “About Me” section with your information:\n\nYour name and background\nYour email address\nYour GitHub username\nWhy you’re taking this course\n\nClick “Commit changes”\n\n\n\n\n\nNavigate to the weekly-notes folder\nClick on week-01-notes.qmd\nClick the pencil icon (✏️) to edit\nFill in your notes from the first class\nClick “Commit changes”\n\n\n\n\n\nThis step makes your portfolio visible as a live website!\n\nGo to Settings: Click the “Settings” tab at the top of your repository\nFind Pages: Scroll down and click “Pages” in the left sidebar\nConfigure Source:\n\nSource: Select “Deploy from a branch”\nBranch: Select “main”\nFolder: Select “/ docs”\n\nSave: Click “Save”\nWait: GitHub will show a message that your site is being built (this takes 1-5 minutes)\n\n\n\n\n\nFind Your URL: After a few minutes, GitHub will show your website URL at the top of the Pages settings\n\nIt will look like: https://yourusername.github.io/repository-name\n\nVisit Your Site: Click the link to see your live portfolio!\nBookmark It: Save this URL - you’ll submit it to Canvas\n\n\n\n\n\nCopy your live website URL\nGo to the Canvas assignment\nSubmit your URL\n\n\n\n\n\nIf you want to work on your computer and see changes before publishing:\n\n\n# Replace [your-repo-url] with your actual repository URL\ngit clone [your-repo-url]\ncd [your-repository-name]\n\n\n\n# Edit your files using RStudio\n# Preview your changes:\nquarto render\nquarto preview\n\n# When ready, save your changes:\ngit add .\ngit commit -m \"Update portfolio\"\ngit push\nYour live website will automatically update when you push changes!\n\n\n\n\nEach week you’ll: 1. Create a new file: weekly-notes/week-XX-notes.qmd 2. Copy the template from week-01-notes.qmd 3. Fill in your reflections and key concepts 4. Commit and push your changes\n\n\n\n\n\n\nWait longer: GitHub Pages can take up to 10 minutes to build\nCheck Actions tab: Look for any red X marks indicating build failures\nVerify Pages settings: Make sure you selected “main” branch and “/docs” folder\n\n\n\n\n\nCheck permissions: Make sure you’re in YOUR repository, not the template\nSign in: Ensure you’re signed into GitHub\n\n\n\n\n\nCheck YAML syntax: Make sure your _quarto.yml file has proper formatting\nVerify file names: Files should end in .qmd not .md\nLook at error messages: The Actions tab will show specific error details\n\n\n\n\n\nDon’t panic! Every change is tracked in Git\nSee history: Click the “History” button on any file to see previous versions\nRevert changes: You can always go back to a previous version\n\n\n\n\n\n\nCommit often: Save your work frequently with descriptive commit messages\nUse branches: For major changes, create a new branch and merge when ready\nPreview locally: Use quarto preview to see changes before publishing\nKeep it professional: This portfolio can be shared with future employers!\nDocument everything: Good documentation is as important as good analysis\n\n\n\n\n\nQuarto Documentation\nGitHub Docs\nMarkdown Guide\nGit Tutorial\n\n\n\n\nDuring Class: - Raise your hand for immediate help - Work with classmates - collaboration is encouraged for setup!\nOutside Class: - Office Hours: Mondays 1:30-3:00 PM - Email: delmelle@design.upenn.edu - GitHub Issues: Create an issue in your repository for technical problems - Canvas Discussion: Post questions others might have too\n\n\n\nBefore submitting, make sure you’ve: - [ ] Customized _quarto.yml with your name - [ ] Updated index.qmd with your information - [ ] Completed Week 1 notes - [ ] Enabled GitHub Pages - [ ] Verified your website loads correctly - [ ] Submitted your URL to Canvas\n\nNeed help? Don’t struggle alone - reach out during office hours (mine + TAs) or in class!"
  },
  {
    "objectID": "instructions_week1.html#what-youre-building",
    "href": "instructions_week1.html#what-youre-building",
    "title": "Portfolio Setup Instructions",
    "section": "",
    "text": "By the end of this setup, you’ll have: - Your own portfolio repository on GitHub - live website showcasing your work - A place to document your learning journey"
  },
  {
    "objectID": "instructions_week1.html#example",
    "href": "instructions_week1.html#example",
    "title": "Portfolio Setup Instructions",
    "section": "",
    "text": "This is what you are building: Dr. Delmelle’s sample portfolio"
  },
  {
    "objectID": "instructions_week1.html#prerequisites",
    "href": "instructions_week1.html#prerequisites",
    "title": "Portfolio Setup Instructions",
    "section": "",
    "text": "Before starting, make sure you have: - [ ] A GitHub account (create one here if needed) - [ ] Quarto installed on your computer (download here) - [ ] R and RStudio installed"
  },
  {
    "objectID": "instructions_week1.html#step-by-step-setup",
    "href": "instructions_week1.html#step-by-step-setup",
    "title": "Portfolio Setup Instructions",
    "section": "",
    "text": "You should already be in your personal repository (created when you accepted the GitHub Classroom assignment). Now let’s personalize it!\n\n\n\nClick on the _quarto.yml file\nClick the pencil icon (✏️) to edit\nChange \"Your Name - MUSA 5080 Portfolio\" to include your actual name\nExample: \"Jane Smith - MUSA 5080 Portfolio\"\nClick “Commit changes” at the bottom\n\n\n\n\n\nClick on the index.qmd file\nClick the pencil icon (✏️) to edit\nUpdate the “About Me” section with your information:\n\nYour name and background\nYour email address\nYour GitHub username\nWhy you’re taking this course\n\nClick “Commit changes”\n\n\n\n\n\nNavigate to the weekly-notes folder\nClick on week-01-notes.qmd\nClick the pencil icon (✏️) to edit\nFill in your notes from the first class\nClick “Commit changes”\n\n\n\n\n\nThis step makes your portfolio visible as a live website!\n\nGo to Settings: Click the “Settings” tab at the top of your repository\nFind Pages: Scroll down and click “Pages” in the left sidebar\nConfigure Source:\n\nSource: Select “Deploy from a branch”\nBranch: Select “main”\nFolder: Select “/ docs”\n\nSave: Click “Save”\nWait: GitHub will show a message that your site is being built (this takes 1-5 minutes)\n\n\n\n\n\nFind Your URL: After a few minutes, GitHub will show your website URL at the top of the Pages settings\n\nIt will look like: https://yourusername.github.io/repository-name\n\nVisit Your Site: Click the link to see your live portfolio!\nBookmark It: Save this URL - you’ll submit it to Canvas\n\n\n\n\n\nCopy your live website URL\nGo to the Canvas assignment\nSubmit your URL"
  },
  {
    "objectID": "instructions_week1.html#working-on-your-portfolio-locally-optional-but-recommended",
    "href": "instructions_week1.html#working-on-your-portfolio-locally-optional-but-recommended",
    "title": "Portfolio Setup Instructions",
    "section": "",
    "text": "If you want to work on your computer and see changes before publishing:\n\n\n# Replace [your-repo-url] with your actual repository URL\ngit clone [your-repo-url]\ncd [your-repository-name]\n\n\n\n# Edit your files using RStudio\n# Preview your changes:\nquarto render\nquarto preview\n\n# When ready, save your changes:\ngit add .\ngit commit -m \"Update portfolio\"\ngit push\nYour live website will automatically update when you push changes!"
  },
  {
    "objectID": "instructions_week1.html#weekly-workflow",
    "href": "instructions_week1.html#weekly-workflow",
    "title": "Portfolio Setup Instructions",
    "section": "",
    "text": "Each week you’ll: 1. Create a new file: weekly-notes/week-XX-notes.qmd 2. Copy the template from week-01-notes.qmd 3. Fill in your reflections and key concepts 4. Commit and push your changes"
  },
  {
    "objectID": "instructions_week1.html#troubleshooting",
    "href": "instructions_week1.html#troubleshooting",
    "title": "Portfolio Setup Instructions",
    "section": "",
    "text": "Wait longer: GitHub Pages can take up to 10 minutes to build\nCheck Actions tab: Look for any red X marks indicating build failures\nVerify Pages settings: Make sure you selected “main” branch and “/docs” folder\n\n\n\n\n\nCheck permissions: Make sure you’re in YOUR repository, not the template\nSign in: Ensure you’re signed into GitHub\n\n\n\n\n\nCheck YAML syntax: Make sure your _quarto.yml file has proper formatting\nVerify file names: Files should end in .qmd not .md\nLook at error messages: The Actions tab will show specific error details\n\n\n\n\n\nDon’t panic! Every change is tracked in Git\nSee history: Click the “History” button on any file to see previous versions\nRevert changes: You can always go back to a previous version"
  },
  {
    "objectID": "instructions_week1.html#pro-tips",
    "href": "instructions_week1.html#pro-tips",
    "title": "Portfolio Setup Instructions",
    "section": "",
    "text": "Commit often: Save your work frequently with descriptive commit messages\nUse branches: For major changes, create a new branch and merge when ready\nPreview locally: Use quarto preview to see changes before publishing\nKeep it professional: This portfolio can be shared with future employers!\nDocument everything: Good documentation is as important as good analysis"
  },
  {
    "objectID": "instructions_week1.html#additional-resources",
    "href": "instructions_week1.html#additional-resources",
    "title": "Portfolio Setup Instructions",
    "section": "",
    "text": "Quarto Documentation\nGitHub Docs\nMarkdown Guide\nGit Tutorial"
  },
  {
    "objectID": "instructions_week1.html#getting-help",
    "href": "instructions_week1.html#getting-help",
    "title": "Portfolio Setup Instructions",
    "section": "",
    "text": "During Class: - Raise your hand for immediate help - Work with classmates - collaboration is encouraged for setup!\nOutside Class: - Office Hours: Mondays 1:30-3:00 PM - Email: delmelle@design.upenn.edu - GitHub Issues: Create an issue in your repository for technical problems - Canvas Discussion: Post questions others might have too"
  },
  {
    "objectID": "instructions_week1.html#checklist",
    "href": "instructions_week1.html#checklist",
    "title": "Portfolio Setup Instructions",
    "section": "",
    "text": "Before submitting, make sure you’ve: - [ ] Customized _quarto.yml with your name - [ ] Updated index.qmd with your information - [ ] Completed Week 1 notes - [ ] Enabled GitHub Pages - [ ] Verified your website loads correctly - [ ] Submitted your URL to Canvas\n\nNeed help? Don’t struggle alone - reach out during office hours (mine + TAs) or in class!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MUSA 5080 Portfolio",
    "section": "",
    "text": "This portfolio documents my learning journey in Public Policy Analytics (MUSA 5080).\n\n\nAdvanced spatial analysis and data science for urban planning and public policy.\n\n\n\n\nWeekly Notes: My learning reflections and key concepts\nLabs: Completed assignments and analyses\nFinal Project: Capstone modeling challenge\n\n\n\n\nHello! I am Katie Knox, a first-year MCP student at University of Pennsylvania. By undergraduate degree was in computer science and francophone studies at Swarthmore College, and for the past three years I have worked for National Digital Inclusion Alliance. I am taking this course because I want to learn how to apply data analysis skills towards public interest problems. I just moved from Toronto back to Philadelphia, so go birds! (Raptors and Eagles)\n\n\n\n\nEmail: knox1@upenn.edu\nGitHub: @kkxix"
  },
  {
    "objectID": "index.html#about-this-course",
    "href": "index.html#about-this-course",
    "title": "MUSA 5080 Portfolio",
    "section": "",
    "text": "Advanced spatial analysis and data science for urban planning and public policy."
  },
  {
    "objectID": "index.html#portfolio-structure",
    "href": "index.html#portfolio-structure",
    "title": "MUSA 5080 Portfolio",
    "section": "",
    "text": "Weekly Notes: My learning reflections and key concepts\nLabs: Completed assignments and analyses\nFinal Project: Capstone modeling challenge"
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "MUSA 5080 Portfolio",
    "section": "",
    "text": "Hello! I am Katie Knox, a first-year MCP student at University of Pennsylvania. By undergraduate degree was in computer science and francophone studies at Swarthmore College, and for the past three years I have worked for National Digital Inclusion Alliance. I am taking this course because I want to learn how to apply data analysis skills towards public interest problems. I just moved from Toronto back to Philadelphia, so go birds! (Raptors and Eagles)"
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "MUSA 5080 Portfolio",
    "section": "",
    "text": "Email: knox1@upenn.edu\nGitHub: @kkxix"
  },
  {
    "objectID": "weekly-notes/week-01-notes.html",
    "href": "weekly-notes/week-01-notes.html",
    "title": "Week 1 Notes - Course Introduction",
    "section": "",
    "text": "Main concepts:\n\nBreakdown of syllabus (stay on toes for weekly quizzes)\n\nTechnical skills covered\n\nRStudio\nQuarto\nGit and Github"
  },
  {
    "objectID": "weekly-notes/week-01-notes.html#key-concepts-learned",
    "href": "weekly-notes/week-01-notes.html#key-concepts-learned",
    "title": "Week 1 Notes - Course Introduction",
    "section": "",
    "text": "Main concepts:\n\nBreakdown of syllabus (stay on toes for weekly quizzes)\n\nTechnical skills covered\n\nRStudio\nQuarto\nGit and Github"
  },
  {
    "objectID": "weekly-notes/week-01-notes.html#coding-techniques",
    "href": "weekly-notes/week-01-notes.html#coding-techniques",
    "title": "Week 1 Notes - Course Introduction",
    "section": "Coding Techniques",
    "text": "Coding Techniques\n\nR functions:\n\nselect() - choose columns\nfilter() - choose rows\nmutate() - create new variables\nsummarize() - calculate statistics\ngroup_by() - operate on groups\nnames() - column names\nglimpse() - little glimpse of data\n\nQuarto features learned:\n\nQuarto is cool and hip :-)\nA way to show code snippets, run code blocks, share visuals, and share text as a webpage or slides (kinda like python notebook or observable)\n\n\ncommon syntax pattern: save_to &lt;- function(df, ...)\neverything except column: select(df, -col_to_exclude)\nanother common pattern: mutate(df, new_col = case_when(condition ~ code, TRUE ~ code2)\nIconic couple: group_by() and summarize() - group_by() – create categories out of values in a column - summarize() – summarize values in another column by a user-defined function - summarize(n=n()) – basic count of grouped categories\npiped syntax pattern: save_to &lt;- df %&gt;% function(...) %&gt;% funciton(...) ^^you don’t need df as first argument if first you state df and pass to functions through pipe"
  },
  {
    "objectID": "weekly-notes/week-01-notes.html#questions-challenges",
    "href": "weekly-notes/week-01-notes.html#questions-challenges",
    "title": "Week 1 Notes - Course Introduction",
    "section": "Questions & Challenges",
    "text": "Questions & Challenges\n\nWhy don’t you need to include df as argument when you are using piping syntax?"
  },
  {
    "objectID": "weekly-notes/week-01-notes.html#connections-to-policy",
    "href": "weekly-notes/week-01-notes.html#connections-to-policy",
    "title": "Week 1 Notes - Course Introduction",
    "section": "Connections to Policy",
    "text": "Connections to Policy\n\nGot a preview of policy topics we will cover over semester:\n\nhousing\nrecidivism\nbikeshare equity\n\nWhat sets this apart from stats is emphasis on prediction"
  },
  {
    "objectID": "weekly-notes/week-01-notes.html#reflection",
    "href": "weekly-notes/week-01-notes.html#reflection",
    "title": "Week 1 Notes - Course Introduction",
    "section": "Reflection",
    "text": "Reflection\n\nHype for this course!\nPhillies &gt; Mets"
  },
  {
    "objectID": "labs/lab0/scripts/lab0_template.html",
    "href": "labs/lab0/scripts/lab0_template.html",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "",
    "text": "Welcome to your first lab! In this (not graded) assignment, you’ll practice the fundamental dplyr operations I overviewed in class using car sales data. This lab will help you get comfortable with:\n\nBasic data exploration\nColumn selection and manipulation\n\nCreating new variables\nFiltering data\nGrouping and summarizing\n\nInstructions: Copy this template into your portfolio repository under a lab_0/ folder, then complete each section with your code and answers. You will write the code under the comment section in each chunk. Be sure to also copy the data folder into your lab_0 folder."
  },
  {
    "objectID": "labs/lab0/scripts/lab0_template.html#data-structure-exploration",
    "href": "labs/lab0/scripts/lab0_template.html#data-structure-exploration",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "1.1 Data Structure Exploration",
    "text": "1.1 Data Structure Exploration\nExplore the structure of your data and answer these questions:\n\n# Use glimpse() to see the data structure\nglimpse(car_data)\n\nRows: 50,000\nColumns: 7\n$ Manufacturer          &lt;chr&gt; \"Ford\", \"Porsche\", \"Ford\", \"Toyota\", \"VW\", \"Ford…\n$ Model                 &lt;chr&gt; \"Fiesta\", \"718 Cayman\", \"Mondeo\", \"RAV4\", \"Polo\"…\n$ `Engine size`         &lt;dbl&gt; 1.0, 4.0, 1.6, 1.8, 1.0, 1.4, 1.8, 1.4, 1.2, 2.0…\n$ `Fuel type`           &lt;chr&gt; \"Petrol\", \"Petrol\", \"Diesel\", \"Hybrid\", \"Petrol\"…\n$ `Year of manufacture` &lt;dbl&gt; 2002, 2016, 2014, 1988, 2006, 2018, 2010, 2015, …\n$ Mileage               &lt;dbl&gt; 127300, 57850, 39190, 210814, 127869, 33603, 866…\n$ Price                 &lt;dbl&gt; 3074, 49704, 24072, 1705, 4101, 29204, 14350, 30…\n\n# Check the column names\nnames(car_data)\n\n[1] \"Manufacturer\"        \"Model\"               \"Engine size\"        \n[4] \"Fuel type\"           \"Year of manufacture\" \"Mileage\"            \n[7] \"Price\"              \n\n# Look at the first few rows\nhead(car_data)\n\n# A tibble: 6 × 7\n  Manufacturer Model     `Engine size` `Fuel type` `Year of manufacture` Mileage\n  &lt;chr&gt;        &lt;chr&gt;             &lt;dbl&gt; &lt;chr&gt;                       &lt;dbl&gt;   &lt;dbl&gt;\n1 Ford         Fiesta              1   Petrol                       2002  127300\n2 Porsche      718 Caym…           4   Petrol                       2016   57850\n3 Ford         Mondeo              1.6 Diesel                       2014   39190\n4 Toyota       RAV4                1.8 Hybrid                       1988  210814\n5 VW           Polo                1   Petrol                       2006  127869\n6 Ford         Focus               1.4 Petrol                       2018   33603\n# ℹ 1 more variable: Price &lt;dbl&gt;\n\n\nQuestions to answer: - How many rows and columns does the dataset have? - What types of variables do you see (numeric, character, etc.)? - Are there any column names that might cause problems? Why?\nYour answers:\n\nRows: 50k\nColumns: 7\n\nVariable types: There are both character and numeric (double) types of variables\nProblematic names: ‘Engine size’ ‘Fuel type’ and ‘Year of manufacture’ all have a space in them"
  },
  {
    "objectID": "labs/lab0/scripts/lab0_template.html#tibble-vs-data-frame",
    "href": "labs/lab0/scripts/lab0_template.html#tibble-vs-data-frame",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "1.2 Tibble vs Data Frame",
    "text": "1.2 Tibble vs Data Frame\nCompare how tibbles and data frames display:\n\n# Look at the tibble version (what we have)\ncar_data\n\n# A tibble: 50,000 × 7\n   Manufacturer Model    `Engine size` `Fuel type` `Year of manufacture` Mileage\n   &lt;chr&gt;        &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt;                       &lt;dbl&gt;   &lt;dbl&gt;\n 1 Ford         Fiesta             1   Petrol                       2002  127300\n 2 Porsche      718 Cay…           4   Petrol                       2016   57850\n 3 Ford         Mondeo             1.6 Diesel                       2014   39190\n 4 Toyota       RAV4               1.8 Hybrid                       1988  210814\n 5 VW           Polo               1   Petrol                       2006  127869\n 6 Ford         Focus              1.4 Petrol                       2018   33603\n 7 Ford         Mondeo             1.8 Diesel                       2010   86686\n 8 Toyota       Prius              1.4 Hybrid                       2015   30663\n 9 VW           Polo               1.2 Petrol                       2012   73470\n10 Ford         Focus              2   Diesel                       1992  262514\n# ℹ 49,990 more rows\n# ℹ 1 more variable: Price &lt;dbl&gt;\n\n# Convert to regular data frame and display\ncar_df &lt;- as.data.frame(car_data)\nhead(car_df)\n\n  Manufacturer      Model Engine size Fuel type Year of manufacture Mileage\n1         Ford     Fiesta         1.0    Petrol                2002  127300\n2      Porsche 718 Cayman         4.0    Petrol                2016   57850\n3         Ford     Mondeo         1.6    Diesel                2014   39190\n4       Toyota       RAV4         1.8    Hybrid                1988  210814\n5           VW       Polo         1.0    Petrol                2006  127869\n6         Ford      Focus         1.4    Petrol                2018   33603\n  Price\n1  3074\n2 49704\n3 24072\n4  1705\n5  4101\n6 29204\n\n\nQuestion: What differences do you notice in how they print?\nYour answer: The tibble automatically shows only 10 rows, and wraps the column names with spaces in them in ’’ marks. It also says what data type the different variables are. The data frame shows wayyyyyyy more rows by defaults and is formatted more consistently."
  },
  {
    "objectID": "labs/lab0/scripts/lab0_template.html#selecting-columns",
    "href": "labs/lab0/scripts/lab0_template.html#selecting-columns",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "2.1 Selecting Columns",
    "text": "2.1 Selecting Columns\nPractice selecting different combinations of columns:\n\n# Select just Model and Mileage columns\ncar_df %&gt;% select(Model, Mileage) %&gt;% head()\n\n       Model Mileage\n1     Fiesta  127300\n2 718 Cayman   57850\n3     Mondeo   39190\n4       RAV4  210814\n5       Polo  127869\n6      Focus   33603\n\n# Select Manufacturer, Price, and Fuel type\ncar_df %&gt;% select(Manufacturer, Price, 'Fuel type') %&gt;% head()\n\n  Manufacturer Price Fuel type\n1         Ford  3074    Petrol\n2      Porsche 49704    Petrol\n3         Ford 24072    Diesel\n4       Toyota  1705    Hybrid\n5           VW  4101    Petrol\n6         Ford 29204    Petrol\n\n# Challenge: Select all columns EXCEPT Engine Size\ncar_df %&gt;% select(-'Engine size') %&gt;% head()\n\n  Manufacturer      Model Fuel type Year of manufacture Mileage Price\n1         Ford     Fiesta    Petrol                2002  127300  3074\n2      Porsche 718 Cayman    Petrol                2016   57850 49704\n3         Ford     Mondeo    Diesel                2014   39190 24072\n4       Toyota       RAV4    Hybrid                1988  210814  1705\n5           VW       Polo    Petrol                2006  127869  4101\n6         Ford      Focus    Petrol                2018   33603 29204"
  },
  {
    "objectID": "labs/lab0/scripts/lab0_template.html#renaming-columns",
    "href": "labs/lab0/scripts/lab0_template.html#renaming-columns",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "2.2 Renaming Columns",
    "text": "2.2 Renaming Columns\nLet’s fix a problematic column name:\n\n# Rename 'Year of manufacture' to year\ncar_data &lt;- rename(car_data, year = 'Year of manufacture')\n\n# Check that it worked\nnames(car_data)\n\n[1] \"Manufacturer\" \"Model\"        \"Engine size\"  \"Fuel type\"    \"year\"        \n[6] \"Mileage\"      \"Price\"       \n\n\nQuestion: Why did we need backticks around Year of manufacture but not around year?\nYour answer: We don’t need backticks around year because it has no spaces."
  },
  {
    "objectID": "labs/lab0/scripts/lab0_template.html#calculate-car-age",
    "href": "labs/lab0/scripts/lab0_template.html#calculate-car-age",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "3.1 Calculate Car Age",
    "text": "3.1 Calculate Car Age\n\n# Create an 'age' column (2025 minus year of manufacture)\ncar_data &lt;- mutate(car_data, age = 2025-year)\n\n# Create a mileage_per_year column  \ncar_data &lt;- mutate(car_data, mileage_per_year = Mileage/age)\n\n# Look at your new columns\nselect(car_data, Model, year, age, Mileage, mileage_per_year)\n\n# A tibble: 50,000 × 5\n   Model       year   age Mileage mileage_per_year\n   &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;            &lt;dbl&gt;\n 1 Fiesta      2002    23  127300            5535.\n 2 718 Cayman  2016     9   57850            6428.\n 3 Mondeo      2014    11   39190            3563.\n 4 RAV4        1988    37  210814            5698.\n 5 Polo        2006    19  127869            6730.\n 6 Focus       2018     7   33603            4800.\n 7 Mondeo      2010    15   86686            5779.\n 8 Prius       2015    10   30663            3066.\n 9 Polo        2012    13   73470            5652.\n10 Focus       1992    33  262514            7955.\n# ℹ 49,990 more rows"
  },
  {
    "objectID": "labs/lab0/scripts/lab0_template.html#categorize-cars",
    "href": "labs/lab0/scripts/lab0_template.html#categorize-cars",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "3.2 Categorize Cars",
    "text": "3.2 Categorize Cars\n\n# Create a price_category column where if price is &lt; 15000, its is coded as budget, between 15000 and 30000 is midrange and greater than 30000 is mid-range (use case_when)\ncar_data &lt;- car_data %&gt;% mutate(price_category = case_when(\n  Price &lt; 15000 ~ \"budget\",\n  Price &gt;= 15000 & Price &lt; 30000 ~ \"midrange\",\n  Price &gt;= 30000 ~ \"luxury\"\n))\n\n\n# Check your categories select the new column and show it\nselect(car_data, price_category)\n\n# A tibble: 50,000 × 1\n   price_category\n   &lt;chr&gt;         \n 1 budget        \n 2 luxury        \n 3 midrange      \n 4 budget        \n 5 budget        \n 6 midrange      \n 7 budget        \n 8 luxury        \n 9 budget        \n10 budget        \n# ℹ 49,990 more rows"
  },
  {
    "objectID": "labs/lab0/scripts/lab0_template.html#basic-filtering",
    "href": "labs/lab0/scripts/lab0_template.html#basic-filtering",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "4.1 Basic Filtering",
    "text": "4.1 Basic Filtering\n\n# Find all Toyota cars\nfilter(car_data, Manufacturer == \"Toyota\")\n\n# A tibble: 12,554 × 10\n   Manufacturer Model `Engine size` `Fuel type`  year Mileage Price   age\n   &lt;chr&gt;        &lt;chr&gt;         &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Toyota       RAV4            1.8 Hybrid       1988  210814  1705    37\n 2 Toyota       Prius           1.4 Hybrid       2015   30663 30297    10\n 3 Toyota       RAV4            2.2 Petrol       2007   79393 16026    18\n 4 Toyota       Yaris           1.4 Petrol       1998   97286  4046    27\n 5 Toyota       RAV4            2.4 Hybrid       2003  117425 11667    22\n 6 Toyota       Yaris           1.2 Petrol       1992  245990   720    33\n 7 Toyota       RAV4            2   Hybrid       2018   28381 52671     7\n 8 Toyota       Prius           1   Hybrid       2003  115291  6512    22\n 9 Toyota       Prius           1   Hybrid       1990  238571   961    35\n10 Toyota       Prius           1.8 Hybrid       2017   31958 38961     8\n# ℹ 12,544 more rows\n# ℹ 2 more variables: mileage_per_year &lt;dbl&gt;, price_category &lt;chr&gt;\n\n# Find cars with mileage less than 30,000\nfilter(car_data, Mileage&lt;30000)\n\n# A tibble: 5,402 × 10\n   Manufacturer Model      `Engine size` `Fuel type`  year Mileage Price   age\n   &lt;chr&gt;        &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Toyota       RAV4                 2   Hybrid       2018   28381 52671     7\n 2 VW           Golf                 2   Petrol       2020   18985 36387     5\n 3 BMW          M5                   4   Petrol       2017   22759 97758     8\n 4 Toyota       RAV4                 2.4 Petrol       2018   24588 49125     7\n 5 VW           Golf                 2   Hybrid       2018   25017 36957     7\n 6 Porsche      718 Cayman           2.4 Petrol       2021   14070 69526     4\n 7 Ford         Focus                1.8 Petrol       2020   22371 40336     5\n 8 Ford         Mondeo               1.6 Diesel       2015   21834 28435    10\n 9 VW           Passat               1.6 Diesel       2018   22122 36634     7\n10 VW           Passat               1.4 Diesel       2020   21413 39310     5\n# ℹ 5,392 more rows\n# ℹ 2 more variables: mileage_per_year &lt;dbl&gt;, price_category &lt;chr&gt;\n\n# Find luxury cars (from price category) with low mileage\ncar_data %&gt;% filter(Mileage&lt;30000) %&gt;% filter(price_category == \"luxury\")\n\n# A tibble: 3,257 × 10\n   Manufacturer Model      `Engine size` `Fuel type`  year Mileage Price   age\n   &lt;chr&gt;        &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Toyota       RAV4                 2   Hybrid       2018   28381 52671     7\n 2 VW           Golf                 2   Petrol       2020   18985 36387     5\n 3 BMW          M5                   4   Petrol       2017   22759 97758     8\n 4 Toyota       RAV4                 2.4 Petrol       2018   24588 49125     7\n 5 VW           Golf                 2   Hybrid       2018   25017 36957     7\n 6 Porsche      718 Cayman           2.4 Petrol       2021   14070 69526     4\n 7 Ford         Focus                1.8 Petrol       2020   22371 40336     5\n 8 VW           Passat               1.6 Diesel       2018   22122 36634     7\n 9 VW           Passat               1.4 Diesel       2020   21413 39310     5\n10 Toyota       RAV4                 2.4 Petrol       2021    6829 66031     4\n# ℹ 3,247 more rows\n# ℹ 2 more variables: mileage_per_year &lt;dbl&gt;, price_category &lt;chr&gt;"
  },
  {
    "objectID": "labs/lab0/scripts/lab0_template.html#multiple-conditions",
    "href": "labs/lab0/scripts/lab0_template.html#multiple-conditions",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "4.2 Multiple Conditions",
    "text": "4.2 Multiple Conditions\n\n# Find cars that are EITHER Honda OR Nissan\nfilter(car_data, Manufacturer == \"Honda\" | Manufacturer == \"Nissan\")\n\n# A tibble: 0 × 10\n# ℹ 10 variables: Manufacturer &lt;chr&gt;, Model &lt;chr&gt;, Engine size &lt;dbl&gt;,\n#   Fuel type &lt;chr&gt;, year &lt;dbl&gt;, Mileage &lt;dbl&gt;, Price &lt;dbl&gt;, age &lt;dbl&gt;,\n#   mileage_per_year &lt;dbl&gt;, price_category &lt;chr&gt;\n\n# Find cars with price between $20,000 and $35,000\nfilter(car_data, Price &gt;20000 & Price &lt; 35000)\n\n# A tibble: 7,301 × 10\n   Manufacturer Model  `Engine size` `Fuel type`  year Mileage Price   age\n   &lt;chr&gt;        &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Ford         Mondeo           1.6 Diesel       2014   39190 24072    11\n 2 Ford         Focus            1.4 Petrol       2018   33603 29204     7\n 3 Toyota       Prius            1.4 Hybrid       2015   30663 30297    10\n 4 Toyota       Prius            1.4 Hybrid       2016   43893 29946     9\n 5 Toyota       Prius            1.4 Hybrid       2016   43130 30085     9\n 6 VW           Passat           1.6 Petrol       2016   64344 23641     9\n 7 Ford         Mondeo           1.6 Diesel       2015   21834 28435    10\n 8 BMW          M5               4.4 Petrol       2008  109941 31711    17\n 9 BMW          Z4               2.2 Petrol       2014   61332 26084    11\n10 Porsche      911              3.5 Petrol       2003  107705 24378    22\n# ℹ 7,291 more rows\n# ℹ 2 more variables: mileage_per_year &lt;dbl&gt;, price_category &lt;chr&gt;\n\n# Find diesel cars less than 10 years old\ncar_data %&gt;% filter(`Fuel type` == \"Diesel\" & age &lt; 10)\n\n# A tibble: 2,040 × 10\n   Manufacturer Model   `Engine size` `Fuel type`  year Mileage Price   age\n   &lt;chr&gt;        &lt;chr&gt;           &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Ford         Fiesta            1   Diesel       2017   38370 16257     8\n 2 VW           Passat            1.6 Diesel       2018   22122 36634     7\n 3 VW           Passat            1.4 Diesel       2020   21413 39310     5\n 4 BMW          X3                2   Diesel       2018   27389 44018     7\n 5 Ford         Mondeo            2   Diesel       2016   51724 28482     9\n 6 Porsche      Cayenne           2.6 Diesel       2019   20147 76182     6\n 7 VW           Polo              1.2 Diesel       2018   37411 19649     7\n 8 Ford         Mondeo            1.8 Diesel       2016   29439 30886     9\n 9 Ford         Mondeo            1.4 Diesel       2020   18929 37720     5\n10 Ford         Mondeo            1.4 Diesel       2018   42017 28904     7\n# ℹ 2,030 more rows\n# ℹ 2 more variables: mileage_per_year &lt;dbl&gt;, price_category &lt;chr&gt;\n\n\nQuestion: How many diesel cars are less than 10 years old?\nYour answer: 2040"
  },
  {
    "objectID": "labs/lab0/scripts/lab0_template.html#basic-summaries",
    "href": "labs/lab0/scripts/lab0_template.html#basic-summaries",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "5.1 Basic Summaries",
    "text": "5.1 Basic Summaries\n\n# Calculate average price by manufacturer\navg_price_by_brand &lt;- car_data %&gt;%\n  group_by(Manufacturer) %&gt;%\n  summarize(avg_price = mean(Price, na.rm = TRUE))\n\navg_price_by_brand\n\n# A tibble: 5 × 2\n  Manufacturer avg_price\n  &lt;chr&gt;            &lt;dbl&gt;\n1 BMW             24429.\n2 Ford            10672.\n3 Porsche         29104.\n4 Toyota          14340.\n5 VW              10363.\n\n# Calculate average mileage by fuel type\navg_mileage_by_fuel_type &lt;- car_data %&gt;%\n  group_by(`Fuel type`) %&gt;%\n  summarize(avg_mileage = mean(Mileage, na.rm = TRUE))\n\navg_mileage_by_fuel_type\n\n# A tibble: 3 × 2\n  `Fuel type` avg_mileage\n  &lt;chr&gt;             &lt;dbl&gt;\n1 Diesel          112667.\n2 Hybrid          111622.\n3 Petrol          112795.\n\n# Count cars by manufacturer\ncars_per_manufacturer &lt;- car_data %&gt;%\n  group_by(Manufacturer) %&gt;%\n  summarize(count = n())\n\ncars_per_manufacturer\n\n# A tibble: 5 × 2\n  Manufacturer count\n  &lt;chr&gt;        &lt;int&gt;\n1 BMW           4965\n2 Ford         14959\n3 Porsche       2609\n4 Toyota       12554\n5 VW           14913"
  },
  {
    "objectID": "labs/lab0/scripts/lab0_template.html#categorical-summaries",
    "href": "labs/lab0/scripts/lab0_template.html#categorical-summaries",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "5.2 Categorical Summaries",
    "text": "5.2 Categorical Summaries\n\n# Frequency table for price categories\ncar_data %&gt;% \n  group_by(price_category) %&gt;%\n  summarise(frequency = n())\n\n# A tibble: 3 × 2\n  price_category frequency\n  &lt;chr&gt;              &lt;int&gt;\n1 budget             34040\n2 luxury              6179\n3 midrange            9781"
  },
  {
    "objectID": "weekly-notes/week-02-notes.html#notes",
    "href": "weekly-notes/week-02-notes.html#notes",
    "title": "Week 2 Notes",
    "section": "Notes",
    "text": "Notes\n\nCopying labs from MUSA repo to portfolio repo\n\ntemplate goes to scripts folder, data goes to data folder\n\n\n\nLab0 / General workflow in R\n\nWant to avoid “hoarding” tibbles, try not to create a new tibble for every operation\nMay way to read in data and store as a ‘pristine’ version, but then create a working version\nUse piping to string together operations, no need to store in-between temporary tibbles\n\n\n\nAlgorithmic Decision-Making & Census Data\n\nAlgorithms = set of instructions for solving a problem/completing a task\nAlgorithmic decision-making in government\n\nSystems used to assist or replace human decision-making (humans may be inefficient, flawed/biased)\nDecisions are made based on predictions from models that process historical data relevant to the decision-making process:\n\nInputs = features = predictors = independent variables = x\nOutputs = labels - outcome = dependent variable = y\n\nExamples:\n\nRecidivism risk for bail and sentencing decisions\nMortgage lending and tenant screening\npatient care prioritization and health care resource allocation\n\n\nClarifying terms:\n\nData science -&gt; engineering, algorithms, and methods\nData analytic -&gt;applying data science to other disciplines\nMachine Learning -&gt; algorithms for classification and prediction/regression\nAI -&gt; Algorithms that adjust and improve across iterations (neural networks, deep learning)\n\nGov’t data collection historically\n\ncivic registrations systems\ncensus data\nadministration records\noperations research – post-WWII efforts to determine things like the best place for hospitals etc\n\nNew data sources\n\nMore data available from both official and ‘unofficial’ or ‘accidental’ sources like Instagram\nTurn from explanation to prediction\nMessier data\n\nWhy use algos in gov’t?\n\nEfficiency - process more cases faster\nConsistency - same process applied equally (In theory)\nObjectivity - remove human bias\nCost-saving - remove costly human labors\n\nBig But – Data Analytics are Subjective\n\nAt every step, there are human choices:\n\nData cleaning decisions\nRecoding/classification\nData collection biases\nImperfect proxies\nInterpreting results\nWhat variables you include in your model\n\n\nExample - Healthcare Algorithm Bias\n\nAlgorithm to identify high-risk patients systematically discriminated against Black patients, why?\n\nAlgo used healthcare cost as a proxy for need (high cost = more risk, less cost = low risk)\nProblem: black patients incur lower costs because of exclusion from health care and unequal access\n\nResult: Black patients were systematically not prioritized\n\nExample - COMPAS Recidivism Prediction\n\nAlgo flagged 2x as likely Black defendants as White as high risk of reoffending, why?\n\nData came from pigs\n\n\nExample - Dutch Welfare Fraud Detection\n\nAlgo disproportionately targeted vulnerable populations\n\n\n\n\nScenario\n\nAutomated traffic enforcements\n\nHighest traffic volume + Mots crashes as proxy for places needing more traffic enforcement\nBlind spot -&gt; unreported crashes (folks avoiding insurance fees for instance)\nHarm -&gt; Could under-enforce actually dangerous intersections, otherwise could be over-enforcement in over-policed areas\nSafeguard -&gt; Cap disparities across areas\n\n\n\n\nCensus Data Foundations\n\nDecennial census mandated by constitution for allocating representative governments\n\nOnly 9 questions on 10y census – age, race, sex, housing\n\nACS\n\n3% of households surveyed annually\nDetailed questions\n\n2020 Innovation: Differential Privacy\n\nadded noise to protect privacy, but this leads to weird edge cases like people living under water\n\nAccessing Census Dat ain R\n\ntidycensus !!! hooray\n\nStructure:\n\nData organized in tables\nEach table has multiple variables\n\n……E = estimate variable\n…..M = MOE variable\n\n\nRule of thumb\n\nLarge MOE : estimate means less reliable\nSmall MOE : estimate means more reliable\n\nTIGER/Line Files\n\nGeographic shape data not automatically included in ACS tables, need to add on\nNow released as shapefiles\n\nTwo types of census outputs:\n\nWide\n\nColumns: Tract, Variable_1, Variable_2…\ni.e. One row per tract\n\nLong\n\nColumns: Tract, Var, Value\ni.e. Tract * variable number of rows"
  },
  {
    "objectID": "labs/lab1/scripts/assignment1_template.html",
    "href": "labs/lab1/scripts/assignment1_template.html",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "You are a data analyst for the Michigan Department of Human Services. The department is considering implementing an algorithmic system to identify communities that should receive priority for social service funding and outreach programs. Your supervisor has asked you to evaluate the quality and reliability of available census data to inform this decision.\nDrawing on our Week 2 discussion of algorithmic bias, you need to assess not just what the data shows, but how reliable it is and what communities might be affected by data quality issues.\n\n\n\n\nApply dplyr functions to real census data for policy analysis\nEvaluate data quality using margins of error\nConnect technical analysis to algorithmic decision-making\nIdentify potential equity implications of data reliability issues\nCreate professional documentation for policy stakeholders\n\n\n\n\nSubmit by posting your updated portfolio link on Canvas. Your assignment should be accessible at your-portfolio-url/assignments/assignment_1/\nMake sure to update your _quarto.yml navigation to include this assignment under an “Assignments” menu."
  },
  {
    "objectID": "labs/lab1/scripts/assignment1_template.html#scenario",
    "href": "labs/lab1/scripts/assignment1_template.html#scenario",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "You are a data analyst for the Michigan Department of Human Services. The department is considering implementing an algorithmic system to identify communities that should receive priority for social service funding and outreach programs. Your supervisor has asked you to evaluate the quality and reliability of available census data to inform this decision.\nDrawing on our Week 2 discussion of algorithmic bias, you need to assess not just what the data shows, but how reliable it is and what communities might be affected by data quality issues."
  },
  {
    "objectID": "labs/lab1/scripts/assignment1_template.html#learning-objectives",
    "href": "labs/lab1/scripts/assignment1_template.html#learning-objectives",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "Apply dplyr functions to real census data for policy analysis\nEvaluate data quality using margins of error\nConnect technical analysis to algorithmic decision-making\nIdentify potential equity implications of data reliability issues\nCreate professional documentation for policy stakeholders"
  },
  {
    "objectID": "labs/lab1/scripts/assignment1_template.html#submission-instructions",
    "href": "labs/lab1/scripts/assignment1_template.html#submission-instructions",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "Submit by posting your updated portfolio link on Canvas. Your assignment should be accessible at your-portfolio-url/assignments/assignment_1/\nMake sure to update your _quarto.yml navigation to include this assignment under an “Assignments” menu."
  },
  {
    "objectID": "labs/lab1/scripts/assignment1_template.html#data-retrieval",
    "href": "labs/lab1/scripts/assignment1_template.html#data-retrieval",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "2.1 Data Retrieval",
    "text": "2.1 Data Retrieval\nYour Task: Use get_acs() to retrieve county-level data for your chosen state.\nRequirements: - Geography: county level - Variables: median household income (B19013_001) and total population (B01003_001)\n- Year: 2022 - Survey: acs5 - Output format: wide\nHint: Remember to give your variables descriptive names using the variables = c(name = \"code\") syntax.\n\n# Write your get_acs() code here\n\n# Clean the county names to remove state name and \"County\" \n# Hint: use mutate() with str_remove()\n\n# Display the first few rows"
  },
  {
    "objectID": "labs/lab1/scripts/assignment1_template.html#data-quality-assessment",
    "href": "labs/lab1/scripts/assignment1_template.html#data-quality-assessment",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "2.2 Data Quality Assessment",
    "text": "2.2 Data Quality Assessment\nYour Task: Calculate margin of error percentages and create reliability categories.\nRequirements: - Calculate MOE percentage: (margin of error / estimate) * 100 - Create reliability categories: - High Confidence: MOE &lt; 5% - Moderate Confidence: MOE 5-10%\n- Low Confidence: MOE &gt; 10% - Create a flag for unreliable estimates (MOE &gt; 10%)\nHint: Use mutate() with case_when() for the categories.\n\n# Calculate MOE percentage and reliability categories using mutate()\n\n# Create a summary showing count of counties in each reliability category\n# Hint: use count() and mutate() to add percentages"
  },
  {
    "objectID": "labs/lab1/scripts/assignment1_template.html#high-uncertainty-counties",
    "href": "labs/lab1/scripts/assignment1_template.html#high-uncertainty-counties",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "2.3 High Uncertainty Counties",
    "text": "2.3 High Uncertainty Counties\nYour Task: Identify the 5 counties with the highest MOE percentages.\nRequirements: - Sort by MOE percentage (highest first) - Select the top 5 counties - Display: county name, median income, margin of error, MOE percentage, reliability category - Format as a professional table using kable()\nHint: Use arrange(), slice(), and select() functions.\n\n# Create table of top 5 counties by MOE percentage\n\n# Format as table with kable() - include appropriate column names and caption\n\nData Quality Commentary:\n[Write 2-3 sentences explaining what these results mean for algorithmic decision-making. Consider: Which counties might be poorly served by algorithms that rely on this income data? What factors might contribute to higher uncertainty?]"
  },
  {
    "objectID": "labs/lab1/scripts/assignment1_template.html#focus-area-selection",
    "href": "labs/lab1/scripts/assignment1_template.html#focus-area-selection",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "3.1 Focus Area Selection",
    "text": "3.1 Focus Area Selection\nYour Task: Select 2-3 counties from your reliability analysis for detailed tract-level study.\nStrategy: Choose counties that represent different reliability levels (e.g., 1 high confidence, 1 moderate, 1 low confidence) to compare how data quality varies.\n\n# Use filter() to select 2-3 counties from your county_reliability data\n# Store the selected counties in a variable called selected_counties\n\n# Display the selected counties with their key characteristics\n# Show: county name, median income, MOE percentage, reliability category\n\nComment on the output: [write something :)]"
  },
  {
    "objectID": "labs/lab1/scripts/assignment1_template.html#tract-level-demographics",
    "href": "labs/lab1/scripts/assignment1_template.html#tract-level-demographics",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "3.2 Tract-Level Demographics",
    "text": "3.2 Tract-Level Demographics\nYour Task: Get demographic data for census tracts in your selected counties.\nRequirements: - Geography: tract level - Variables: white alone (B03002_003), Black/African American (B03002_004), Hispanic/Latino (B03002_012), total population (B03002_001) - Use the same state and year as before - Output format: wide - Challenge: You’ll need county codes, not names. Look at the GEOID patterns in your county data for hints.\n\n# Define your race/ethnicity variables with descriptive names\n\n# Use get_acs() to retrieve tract-level data\n# Hint: You may need to specify county codes in the county parameter\n\n# Calculate percentage of each group using mutate()\n# Create percentages for white, Black, and Hispanic populations\n\n# Add readable tract and county name columns using str_extract() or similar"
  },
  {
    "objectID": "labs/lab1/scripts/assignment1_template.html#demographic-analysis",
    "href": "labs/lab1/scripts/assignment1_template.html#demographic-analysis",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "3.3 Demographic Analysis",
    "text": "3.3 Demographic Analysis\nYour Task: Analyze the demographic patterns in your selected areas.\n\n# Find the tract with the highest percentage of Hispanic/Latino residents\n# Hint: use arrange() and slice() to get the top tract\n\n# Calculate average demographics by county using group_by() and summarize()\n# Show: number of tracts, average percentage for each racial/ethnic group\n\n# Create a nicely formatted table of your results using kable()"
  },
  {
    "objectID": "labs/lab1/scripts/assignment1_template.html#moe-analysis-for-demographic-variables",
    "href": "labs/lab1/scripts/assignment1_template.html#moe-analysis-for-demographic-variables",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "4.1 MOE Analysis for Demographic Variables",
    "text": "4.1 MOE Analysis for Demographic Variables\nYour Task: Examine margins of error for demographic variables to see if some communities have less reliable data.\nRequirements: - Calculate MOE percentages for each demographic variable - Flag tracts where any demographic variable has MOE &gt; 15% - Create summary statistics\n\n# Calculate MOE percentages for white, Black, and Hispanic variables\n# Hint: use the same formula as before (margin/estimate * 100)\n\n# Create a flag for tracts with high MOE on any demographic variable\n# Use logical operators (| for OR) in an ifelse() statement\n\n# Create summary statistics showing how many tracts have data quality issues"
  },
  {
    "objectID": "labs/lab1/scripts/assignment1_template.html#pattern-analysis",
    "href": "labs/lab1/scripts/assignment1_template.html#pattern-analysis",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "4.2 Pattern Analysis",
    "text": "4.2 Pattern Analysis\nYour Task: Investigate whether data quality problems are randomly distributed or concentrated in certain types of communities.\n\n# Group tracts by whether they have high MOE issues\n# Calculate average characteristics for each group:\n# - population size, demographic percentages\n\n# Use group_by() and summarize() to create this comparison\n# Create a professional table showing the patterns\n\nPattern Analysis: [Describe any patterns you observe. Do certain types of communities have less reliable data? What might explain this?]"
  },
  {
    "objectID": "labs/lab1/scripts/assignment1_template.html#analysis-integration-and-professional-summary",
    "href": "labs/lab1/scripts/assignment1_template.html#analysis-integration-and-professional-summary",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "5.1 Analysis Integration and Professional Summary",
    "text": "5.1 Analysis Integration and Professional Summary\nYour Task: Write an executive summary that integrates findings from all four analyses.\nExecutive Summary Requirements: 1. Overall Pattern Identification: What are the systematic patterns across all your analyses? 2. Equity Assessment: Which communities face the greatest risk of algorithmic bias based on your findings? 3. Root Cause Analysis: What underlying factors drive both data quality issues and bias risk? 4. Strategic Recommendations: What should the Department implement to address these systematic issues?\nExecutive Summary:\n[Your integrated 4-paragraph summary here]"
  },
  {
    "objectID": "labs/lab1/scripts/assignment1_template.html#specific-recommendations",
    "href": "labs/lab1/scripts/assignment1_template.html#specific-recommendations",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "6.3 Specific Recommendations",
    "text": "6.3 Specific Recommendations\nYour Task: Create a decision framework for algorithm implementation.\n\n# Create a summary table using your county reliability data\n# Include: county name, median income, MOE percentage, reliability category\n\n# Add a new column with algorithm recommendations using case_when():\n# - High Confidence: \"Safe for algorithmic decisions\"\n# - Moderate Confidence: \"Use with caution - monitor outcomes\"  \n# - Low Confidence: \"Requires manual review or additional data\"\n\n# Format as a professional table with kable()\n\nKey Recommendations:\nYour Task: Use your analysis results to provide specific guidance to the department.\n\nCounties suitable for immediate algorithmic implementation: [List counties with high confidence data and explain why they’re appropriate]\nCounties requiring additional oversight: [List counties with moderate confidence data and describe what kind of monitoring would be needed]\nCounties needing alternative approaches: [List counties with low confidence data and suggest specific alternatives - manual review, additional surveys, etc.]"
  },
  {
    "objectID": "labs/lab1/scripts/assignment1_template.html#questions-for-further-investigation",
    "href": "labs/lab1/scripts/assignment1_template.html#questions-for-further-investigation",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "Questions for Further Investigation",
    "text": "Questions for Further Investigation\n[List 2-3 questions that your analysis raised that you’d like to explore further in future assignments. Consider questions about spatial patterns, time trends, or other demographic factors.]"
  },
  {
    "objectID": "labs/lab1/scripts/assignment1_template.html#submission-checklist",
    "href": "labs/lab1/scripts/assignment1_template.html#submission-checklist",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "Submission Checklist",
    "text": "Submission Checklist\nBefore submitting your portfolio link on Canvas:\n\nAll code chunks run without errors\nAll “[Fill this in]” prompts have been completed\nTables are properly formatted and readable\nExecutive summary addresses all four required components\nPortfolio navigation includes this assignment\nCensus API key is properly set\nDocument renders correctly to HTML\n\nRemember: Submit your portfolio URL on Canvas, not the file itself. Your assignment should be accessible at your-portfolio-url/assignments/assignment_1/your_file_name.html"
  },
  {
    "objectID": "labs/lab1/scripts/assignment1_kk.html",
    "href": "labs/lab1/scripts/assignment1_kk.html",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "You are a data analyst for the Michigan Department of Human Services. The department is considering implementing an algorithmic system to identify communities that should receive priority for social service funding and outreach programs. Your supervisor has asked you to evaluate the quality and reliability of available census data to inform this decision.\nDrawing on our Week 2 discussion of algorithmic bias, you need to assess not just what the data shows, but how reliable it is and what communities might be affected by data quality issues.\n\n\n\n\nApply dplyr functions to real census data for policy analysis\nEvaluate data quality using margins of error\nConnect technical analysis to algorithmic decision-making\nIdentify potential equity implications of data reliability issues\nCreate professional documentation for policy stakeholders\n\n\n\n\nSubmit by posting your updated portfolio link on Canvas. Your assignment should be accessible at your-portfolio-url/assignments/assignment_1/\nMake sure to update your _quarto.yml navigation to include this assignment under an “Assignments” menu."
  },
  {
    "objectID": "labs/lab1/scripts/assignment1_kk.html#scenario",
    "href": "labs/lab1/scripts/assignment1_kk.html#scenario",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "You are a data analyst for the Michigan Department of Human Services. The department is considering implementing an algorithmic system to identify communities that should receive priority for social service funding and outreach programs. Your supervisor has asked you to evaluate the quality and reliability of available census data to inform this decision.\nDrawing on our Week 2 discussion of algorithmic bias, you need to assess not just what the data shows, but how reliable it is and what communities might be affected by data quality issues."
  },
  {
    "objectID": "labs/lab1/scripts/assignment1_kk.html#learning-objectives",
    "href": "labs/lab1/scripts/assignment1_kk.html#learning-objectives",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "Apply dplyr functions to real census data for policy analysis\nEvaluate data quality using margins of error\nConnect technical analysis to algorithmic decision-making\nIdentify potential equity implications of data reliability issues\nCreate professional documentation for policy stakeholders"
  },
  {
    "objectID": "labs/lab1/scripts/assignment1_kk.html#submission-instructions",
    "href": "labs/lab1/scripts/assignment1_kk.html#submission-instructions",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "Submit by posting your updated portfolio link on Canvas. Your assignment should be accessible at your-portfolio-url/assignments/assignment_1/\nMake sure to update your _quarto.yml navigation to include this assignment under an “Assignments” menu."
  },
  {
    "objectID": "labs/lab1/scripts/assignment1_kk.html#data-retrieval",
    "href": "labs/lab1/scripts/assignment1_kk.html#data-retrieval",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "2.1 Data Retrieval",
    "text": "2.1 Data Retrieval\nYour Task: Use get_acs() to retrieve county-level data for your chosen state.\nRequirements: - Geography: county level - Variables: median household income (B19013_001) and total population (B01003_001)\n- Year: 2022 - Survey: acs5 - Output format: wide\nHint: Remember to give your variables descriptive names using the variables = c(name = \"code\") syntax.\n\n# Write your get_acs() code here\nmi_county_pop_income &lt;- get_acs(\n  geography = \"county\", \n  variables = c(\n    median_household_income = \"B19013_001\",\n    total_pop = \"B01003_001\"),\n  state = \"MI\",\n  year = 2022,\n  output= \"wide\",\n  survey = \"acs5\")\n\n# Clean the county names to remove state name and \"County\" \n# Hint: use mutate() with str_remove()\nmi_county_pop_income &lt;- mi_county_pop_income %&gt;% \n  mutate(County_Name = str_remove(NAME, \" County, Michigan\")) \n\n# Display the first few rows\nhead(mi_county_pop_income)\n\n# A tibble: 6 × 7\n  GEOID NAME            median_household_inc…¹ median_household_inc…² total_popE\n  &lt;chr&gt; &lt;chr&gt;                            &lt;dbl&gt;                  &lt;dbl&gt;      &lt;dbl&gt;\n1 26001 Alcona County,…                  50295                   2243      10238\n2 26003 Alger County, …                  55528                   2912       8866\n3 26005 Allegan County…                  75543                   2369     120189\n4 26007 Alpena County,…                  49133                   2119      28911\n5 26009 Antrim County,…                  68850                   3115      23662\n6 26011 Arenac County,…                  53487                   2018      15031\n# ℹ abbreviated names: ¹​median_household_incomeE, ²​median_household_incomeM\n# ℹ 2 more variables: total_popM &lt;dbl&gt;, County_Name &lt;chr&gt;"
  },
  {
    "objectID": "labs/lab1/scripts/assignment1_kk.html#data-quality-assessment",
    "href": "labs/lab1/scripts/assignment1_kk.html#data-quality-assessment",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "2.2 Data Quality Assessment",
    "text": "2.2 Data Quality Assessment\nYour Task: Calculate margin of error percentages and create reliability categories.\nRequirements: - Calculate MOE percentage: (margin of error / estimate) * 100 - Create reliability categories: - High Confidence: MOE &lt; 5% - Moderate Confidence: MOE 5-10%\n- Low Confidence: MOE &gt; 10% - Create a flag for unreliable estimates (MOE &gt; 10%)\nHint: Use mutate() with case_when() for the categories.\n\n# Calculate MOE percentage and reliability categories using mutate()\nmi_county_pop_income &lt;- mi_county_pop_income %&gt;%\n  mutate(\n    income_moe_percent = (median_household_incomeM/ median_household_incomeE)*100\n      ) %&gt;%\n  mutate(\n    income_e_reliability = case_when(\n      income_moe_percent &lt; 5 ~ \"High Confidence\",\n      income_moe_percent &gt;=5 & income_moe_percent &lt;= 10 ~ \"Moderate Confidence\",\n      income_moe_percent &gt; 10 ~ \"Low Confidence\"\n    )\n  ) %&gt;%\n  mutate(\n    unreliable_income_e = case_when(\n      income_e_reliability == \"Low Confidence\" ~ TRUE,\n      TRUE ~ FALSE\n    )\n  )\n# Create a summary showing count of counties in each reliability category\n# Hint: use count() and mutate() to add percentages\nincome_reliability_summary &lt;- mi_county_pop_income %&gt;%\n  group_by(income_e_reliability) %&gt;%\n  summarise(num_counties = n()) %&gt;%\n  mutate(\n    percent_of_counties = (num_counties/ sum(num_counties)) *100\n  )"
  },
  {
    "objectID": "labs/lab1/scripts/assignment1_kk.html#high-uncertainty-counties",
    "href": "labs/lab1/scripts/assignment1_kk.html#high-uncertainty-counties",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "2.3 High Uncertainty Counties",
    "text": "2.3 High Uncertainty Counties\nYour Task: Identify the 5 counties with the highest MOE percentages.\nRequirements: - Sort by MOE percentage (highest first) - Select the top 5 counties - Display: county name, median income, margin of error, MOE percentage, reliability category - Format as a professional table using kable()\nHint: Use arrange(), slice(), and select() functions.\n\n# Create table of top 5 counties by MOE percentage\ntop_5_unreliable &lt;- mi_county_pop_income %&gt;%\n  arrange(desc(income_moe_percent)) %&gt;%\n  top_n(5, income_moe_percent) %&gt;%\n  select(NAME, median_household_incomeE, median_household_incomeM, income_moe_percent, income_e_reliability)\n  \n\n# Format as table with kable() - include appropriate column names and caption\ntop_5_unreliable_formatted &lt;- top_5_unreliable %&gt;%\n  mutate(\n    median_household_incomeE = paste0(\"$\", format(median_household_incomeE, big.mark = \",\", scientific = FALSE)),\n    median_household_incomeM = paste0(\"±\", \"$\", format(median_household_incomeM, big.mark = \",\", scientific = FALSE)),\n    income_moe_percent = paste0(round(income_moe_percent, 2), \"%\"),\n  )\n\n  kable(top_5_unreliable_formatted,\n      col.names = c(\"County Name\", \"Median Income\", \"MOE\", \"MOE Percent of Estimate\", \"Reliability of Estimate\"),\n      align = \"l\",\n      caption = \"5 Least Reliable Median Income Estimates of Counties in Michigan\",\n      digits = 2,\n      format.args = list(big.mark = \",\", scientific = FALSE))\n\n\n5 Least Reliable Median Income Estimates of Counties in Michigan\n\n\n\n\n\n\n\n\n\nCounty Name\nMedian Income\nMOE\nMOE Percent of Estimate\nReliability of Estimate\n\n\n\n\nKeweenaw County, Michigan\n$55,560\n±$7,301\n13.14%\nLow Confidence\n\n\nSchoolcraft County, Michigan\n$55,071\n±$6,328\n11.49%\nLow Confidence\n\n\nGogebic County, Michigan\n$47,913\n±$4,766\n9.95%\nModerate Confidence\n\n\nOtsego County, Michigan\n$62,865\n±$5,910\n9.4%\nModerate Confidence\n\n\nMontmorency County, Michigan\n$46,345\n±$3,796\n8.19%\nModerate Confidence\n\n\n\n\n\nData Quality Commentary:\nAssistance programs and policies aimed at community development may look at median income to identify priority areas. Areas with lower reliability may have a far lower or higher actual median income than what is reported in the census, and could affect the calculations of how resources are allocated to those areas. Additionally, higher unreliability is more likely in less population geographies because it is harder to get a representative sample, so smaller or less densely populated geographies, which are already often economically vulnerable, may be further marginalized by being overlooked in the prioritization of assistance programs based on these metrics."
  },
  {
    "objectID": "labs/lab1/scripts/assignment1_kk.html#focus-area-selection",
    "href": "labs/lab1/scripts/assignment1_kk.html#focus-area-selection",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "3.1 Focus Area Selection",
    "text": "3.1 Focus Area Selection\nYour Task: Select 2-3 counties from your reliability analysis for detailed tract-level study.\nStrategy: Choose counties that represent different reliability levels (e.g., 1 high confidence, 1 moderate, 1 low confidence) to compare how data quality varies.\n\ncounties &lt;- c(\"Kalamazoo\", \"Crawford\", \"Keweenaw\")\n\n# Use filter() to select 2-3 counties from your county_reliability data\n# Store the selected counties in a variable called selected_counties\nselected_counties &lt;- filter(mi_county_pop_income, County_Name %in% counties)\n\n# Display the selected counties with their key characteristics\n# Show: county name, median income, MOE percentage, reliability category\nselected_counties %&gt;%\n  select(NAME, median_household_incomeE, income_moe_percent, income_e_reliability) %&gt;%\n  mutate(\n    median_household_incomeE = paste0(\"$\", format(median_household_incomeE, big.mark = \",\", scientific = FALSE)),\n    income_moe_percent = paste0(round(income_moe_percent, 2), \"%\"),\n  ) %&gt;%\nkable(col.names = c(\"County Name\", \"Median Income\", \"MOE Percent of Estimate\", \"Reliability of Estimate\"),\n      align = \"l\",\n      caption = \"3 Selected Counties in Michigan\")\n\n\n3 Selected Counties in Michigan\n\n\n\n\n\n\n\n\nCounty Name\nMedian Income\nMOE Percent of Estimate\nReliability of Estimate\n\n\n\n\nCrawford County, Michigan\n$57,998\n5.93%\nModerate Confidence\n\n\nKalamazoo County, Michigan\n$67,905\n2.31%\nHigh Confidence\n\n\nKeweenaw County, Michigan\n$55,560\n13.14%\nLow Confidence\n\n\n\n\n\nComment on the output:\nI chose:\n\nKalamazoo as a high reliable county and a relatively bigger city in Western Michigan with multiple universities.\nCrawford is a moderate reliable county and where I used to go fishing with my grandpa :)\nKeweenaw is a low reliable county in the most northern tip of the upper penninsula with a very small population (I didn’t know anyone even lived there)"
  },
  {
    "objectID": "labs/lab1/scripts/assignment1_kk.html#tract-level-demographics",
    "href": "labs/lab1/scripts/assignment1_kk.html#tract-level-demographics",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "3.2 Tract-Level Demographics",
    "text": "3.2 Tract-Level Demographics\nYour Task: Get demographic data for census tracts in your selected counties.\nRequirements:\n\nGeography: tract level\nVariables: white alone (B03002_003), Black/African American (B03002_004), Hispanic/Latino (B03002_012), total population (B03002_001)\nUse the same state and year as before\nOutput format: wide\n\nChallenge: You’ll need county codes, not names. Look at the GEOID patterns in your county data for hints.\n\n# Define your race/ethnicity variables with descriptive names\n\n# Use get_acs() to retrieve tract-level data\n# Hint: You may need to specify county codes in the county parameter\ndemographics &lt;- get_acs(\n  geography = \"tract\",\n  variables = c(White = \"B03002_003\", Black = \"B03002_004\", Latinx = \"B03002_012\", Total = \"B03002_001\"),\n  state = \"MI\", \n  county = counties,\n  year = 2022,\n  output=\"wide\"\n)\n\n# Calculate percentage of each group using mutate()\n# Create percentages for white, Black, and Hispanic populations\ndemographics &lt;- demographics %&gt;%\n  mutate(percent_black = if_else(TotalE == 0, 0, BlackE / TotalE * 100),\n         percent_white = if_else(TotalE == 0, 0, WhiteE / TotalE * 100),\n         percent_latin = if_else(TotalE == 0, 0, LatinxE / TotalE * 100) \n  )%&gt;%\n  mutate(percent_black_c = paste0(round(percent_black, 2), \"%\"),\n         percent_white_c = paste0(round(percent_white), \"%\"),\n         percent_latin_c = paste0(round(percent_latin, 2), \"%\")\n  )\n\n# Add readable tract and county name columns using str_extract() or similar\ndemographics &lt;- demographics %&gt;%\n  mutate(\n    County_Name = str_extract(NAME, \"(?&lt;=;\\\\s)[A-Za-z ]+(?=\\\\sCounty;)\"),\n    Tract = str_extract(NAME, \"(?&lt;=Census Tract )[0-9.]+\")\n  )"
  },
  {
    "objectID": "labs/lab1/scripts/assignment1_kk.html#demographic-analysis",
    "href": "labs/lab1/scripts/assignment1_kk.html#demographic-analysis",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "3.3 Demographic Analysis",
    "text": "3.3 Demographic Analysis\nYour Task: Analyze the demographic patterns in your selected areas.\n\n# Find the tract with the highest percentage of Hispanic/Latino residents\n# Hint: use arrange() and slice() to get the top tract\ndemographics %&gt;% \n  filter(!is.nan(percent_latin)) %&gt;%\n  arrange(desc(percent_latin)) %&gt;% \n  slice(1) %&gt;%\n  select(County_Name, Tract, percent_latin_c) %&gt;%\n  kable(col.names = c(\"County\", \"Tract\", \"Percent Latin\"),\n        align = \"c\")\n\n\n\n\nCounty\nTract\nPercent Latin\n\n\n\n\nKalamazoo\n10.01\n25.44%\n\n\n\n\n\n\n# Calculate average demographics by county using group_by() and summarize()\n# Show: number of tracts, average percentage for each racial/ethnic group\navg_demo_by_tract &lt;- demographics %&gt;%\n  group_by(County_Name) %&gt;%\n  summarize(avg_black = mean(percent_black),\n            avg_white = mean(percent_white),\n            avg_latin = mean(percent_latin))\n\n# Create a nicely formatted table of your results using kable()\navg_demo_by_tract %&gt;%\n  mutate(avg_black_c = paste0(round(avg_black, 2), \"%\"),\n         avg_white_c = paste0(round(avg_white, 2), \"%\"),\n         avg_latin_c = paste0(round(avg_latin, 2), \"%\")) %&gt;%\n  select(County_Name, avg_black_c, avg_white_c, avg_latin_c) %&gt;% \n  kable(col.names = c(\"County\", \"Avg % Black\", \"Avg % White\", \"Avg % Latin\"),\n        caption = \"Average Demographic Makeup of All Census Tracts in 3 MI Counties\",\n        align = \"r\")\n\n\nAverage Demographic Makeup of All Census Tracts in 3 MI Counties\n\n\nCounty\nAvg % Black\nAvg % White\nAvg % Latin\n\n\n\n\nCrawford\n0.28%\n92.25%\n2.19%\n\n\nKalamazoo\n12.7%\n73.33%\n5.81%\n\n\nKeweenaw\n0%\n65.28%\n0.53%"
  },
  {
    "objectID": "labs/lab1/scripts/assignment1_kk.html#moe-analysis-for-demographic-variables",
    "href": "labs/lab1/scripts/assignment1_kk.html#moe-analysis-for-demographic-variables",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "4.1 MOE Analysis for Demographic Variables",
    "text": "4.1 MOE Analysis for Demographic Variables\nYour Task: Examine margins of error for demographic variables to see if some communities have less reliable data.\nRequirements: - Calculate MOE percentages for each demographic variable - Flag tracts where any demographic variable has MOE &gt; 15% - Create summary statistics\n\n# Calculate MOE percentages for white, Black, and Hispanic variables\n# Hint: use the same formula as before (margin/estimate * 100)\ndemographics &lt;- demographics %&gt;%\n  mutate(White_percent_MOE = WhiteM/WhiteE*100,\n         Black_percent_MOE = BlackM/BlackE*100, \n         Latin_percent_MOE = LatinxM/LatinxE*100)\n\n# Create a flag for tracts with high MOE on any demographic variable\n# Use logical operators (| for OR) in an ifelse() statement\ndemographics &lt;- demographics %&gt;% \n  mutate(\n    flag = case_when(\n      White_percent_MOE &gt;=100 |\n      Black_percent_MOE &gt;=100 | \n      Latin_percent_MOE &gt;=100 ~\n      \"MOE Higher than Estimate\",\n      (White_percent_MOE &gt;=50 & White_percent_MOE &lt; 100) |\n      (Black_percent_MOE &gt;=50 & Black_percent_MOE &lt; 100) | \n      (Latin_percent_MOE &gt;=50 & Latin_percent_MOE &lt; 100) ~\n      \"Very Unreliable\",\n      (White_percent_MOE &gt;10 & White_percent_MOE &lt; 50) |\n      (Black_percent_MOE &gt;10 & Black_percent_MOE &lt; 50) | \n      (Latin_percent_MOE &gt;10 & Latin_percent_MOE &lt; 50) ~\n      \"Unreliable\", \n      White_percent_MOE &lt;=10 |\n      Black_percent_MOE &lt;=10 | \n      Latin_percent_MOE &lt;=10 ~\n      \"Reliable\"\n    )\n  )\n\n# Create summary statistics showing how many tracts have data quality issues\nreliability_summary &lt;- demographics %&gt;%\n  group_by(flag) %&gt;% \n  summarize(count = n())\n\nkable(reliability_summary,\n      col.names = c(\"Flag\", \"Number of Tracts\"),\n      align=\"c\")\n\n\n\n\nFlag\nNumber of Tracts\n\n\n\n\nMOE Higher than Estimate\n37\n\n\nUnreliable\n3\n\n\nVery Unreliable\n36"
  },
  {
    "objectID": "labs/lab1/scripts/assignment1_kk.html#pattern-analysis",
    "href": "labs/lab1/scripts/assignment1_kk.html#pattern-analysis",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "4.2 Pattern Analysis",
    "text": "4.2 Pattern Analysis\nYour Task: Investigate whether data quality problems are randomly distributed or concentrated in certain types of communities.\n\n# Group tracts by whether they have high MOE issues\n# Calculate average characteristics for each group:\n# - population size, demographic percentages\nmoe_issues &lt;- demographics %&gt;% \n  group_by(flag) %&gt;%\n  summarise(\n    avg_pop_size = mean(TotalE),\n    avg_percent_black = mean(if_else(TotalE != 0, BlackE / TotalE * 100, NA_real_), na.rm = TRUE),\n    avg_percent_white = mean(if_else(TotalE != 0, WhiteE / TotalE * 100, NA_real_), na.rm = TRUE),\n    avg_percent_latin = mean(if_else(TotalE != 0, LatinxE / TotalE * 100, NA_real_), na.rm = TRUE)\n  )\n  \n\n# Use group_by() and summarize() to create this comparison\n# Create a professional table showing the patterns\nmoe_issues &lt;- moe_issues %&gt;%\n  arrange(desc(avg_percent_black)) %&gt;%\n  mutate(avg_percent_black_c = paste0(round(avg_percent_black, 2), \"%\"),\n         avg_percent_white_c = paste0(round(avg_percent_white, 2), \"%\"),\n         avg_percent_latin_c = paste0(round(avg_percent_latin, 2), \"%\")) \n\n\nmoe_issues %&gt;%\n  select(flag, avg_pop_size, avg_percent_black_c, avg_percent_white_c, avg_percent_latin_c) %&gt;% \n  kable(col.names = c(\"Reliability (Bad to Worst)\", \"Avg Tract Population Size\", \"Avg % Black\", \"Avg % White\", \"Avg % Latin\"),\n        caption = \"Average Demographic Makeup of All Census Tracts in 3 MI Counties\",\n        align = \"r\",\n        digits = 0)\n\n\nAverage Demographic Makeup of All Census Tracts in 3 MI Counties\n\n\n\n\n\n\n\n\n\nReliability (Bad to Worst)\nAvg Tract Population Size\nAvg % Black\nAvg % White\nAvg % Latin\n\n\n\n\nUnreliable\n2762\n21.99%\n52.73%\n19.85%\n\n\nVery Unreliable\n4112\n14.88%\n70.22%\n6.23%\n\n\nMOE Higher than Estimate\n3254\n7.32%\n82.16%\n3.43%\n\n\n\n\n\n\nmoe_issues_2 &lt;- demographics %&gt;% \n  group_by(County_Name) %&gt;%\n  summarise(\n    total_pop_size = sum(TotalE),\n    avg_moe_percent_black = mean(if_else(BlackE != 0, BlackM / BlackE * 100, NA_real_), na.rm = TRUE),\n    avg_moe_percent_white = mean(if_else(WhiteE != 0, WhiteM / WhiteE * 100, NA_real_), na.rm = TRUE),\n    avg_moe_percent_latin = mean(if_else(LatinxE != 0, LatinxM / LatinxE * 100, NA_real_), na.rm = TRUE)\n  )\n  \n\n# Use group_by() and summarize() to create this comparison\n# Create a professional table showing the patterns\nmoe_issues_2 &lt;- moe_issues_2 %&gt;%\n  mutate(avg_moe_percent_black_c = paste0(round(avg_moe_percent_black, 2), \"%\"),\n         avg_moe_percent_white_c = paste0(round(avg_moe_percent_white, 2), \"%\"),\n         avg_moe_percent_latin_c = paste0(round(avg_moe_percent_latin, 2), \"%\")) \n\nmoe_issues_2 %&gt;%\n  arrange(desc(total_pop_size))%&gt;%\n  select(County_Name, total_pop_size, avg_moe_percent_black_c, avg_moe_percent_white_c, avg_moe_percent_latin_c) %&gt;% \n  kable(col.names = c(\"County\", \"Total Population Size\", \"Avg Black MOE % of Estimate\", \"Avg White MOE % of Estimate\", \"Avg Latin MOE % of Estimate\"),\n        caption = \"Average MOE % of Estimate of Different Racial Groups by County\",\n        align = \"r\",\n        digits = 0)\n\n\nAverage MOE % of Estimate of Different Racial Groups by County\n\n\n\n\n\n\n\n\n\nCounty\nTotal Population Size\nAvg Black MOE % of Estimate\nAvg White MOE % of Estimate\nAvg Latin MOE % of Estimate\n\n\n\n\nKalamazoo\n261426\n70.69%\n17.82%\n86.12%\n\n\nCrawford\n13197\n124.44%\n11.33%\n88.48%\n\n\nKeweenaw\n2088\nNaN%\n25.15%\n12.12%\n\n\n\n\n\nPattern Analysis:\nGiven that there was not a single tract in the three counties where all three racial population MOEs were below 10% of the estimate itself, I decided to make categories “Unreliable” where MOE was up to 50% of estimate, “Very unreliable” if 50- 100 % of estimate, and then if it was over 100, that indicates the MOE is bigger than the estimate itself, or “Inf” shows that the estimate was 0, which can’t be a denominator. We can see that on this scale, the more racially homogenous an area is on average, the less reliable the estimates are for that area. I also looked at the averagve MOEs as percent of Estimate for the three different racial groups by county, and accross all three counties, the White population had the lowest average MOE % of Estimate (except in Keweenaw, but this is based on only one tract having any estimate Latinx population at all)."
  },
  {
    "objectID": "labs/lab1/scripts/assignment1_kk.html#analysis-integration-and-professional-summary",
    "href": "labs/lab1/scripts/assignment1_kk.html#analysis-integration-and-professional-summary",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "5.1 Analysis Integration and Professional Summary",
    "text": "5.1 Analysis Integration and Professional Summary\nYour Task: Write an executive summary that integrates findings from all four analyses.\nExecutive Summary Requirements:\n\nOverall Pattern Identification: What are the systematic patterns across all your analyses?\nEquity Assessment: Which communities face the greatest risk of algorithmic bias based on your findings?\nRoot Cause Analysis: What underlying factors drive both data quality issues and bias risk?\nStrategic Recommendations: What should the Department implement to address these systematic issues?\n\nExecutive Summary:\nAccross the data I analyzed, the clearest pattern that emerged is that the more homogenous a tract, the more unreliable the estimates. We also see that this unreliability is not evenly shared, but whatever population is in the minority faces more unreliable estimates, leading to a sort of double marginalization, where an already marginalized population is less accurately represented in data, and decisions made on these data could be very misguided.\nIn Michigan, Black and Latinx populations face the greatest risk of algorithmic bias, even in a county that is relatively diverse, like Kalamazoo, any given tract might have a much higher White majority and unreliable estimates of Black and Latinx populations.\nThe underlying issues that could be at play here are that when attaining a survey sample especially in a census tract with a relatively low population and very low diversity, there might be a handful of people of the demographic the census is trying to estimate the size of, causing issues in extrapolating from the sample to the overall makeup of the tract and the county. In Michigan specifically, the state is about 3/4 White, and there is a history of racialized segregration of living areas that persists today, so even in diverse areas, any given tract might have high unreliability because of a more homogenous makeup.\nThe Department could address this by supplementing census data with further sampling to add to the dataset, however this risks also overburdening minority populations with survey fatigue. The Department should at least be very cautious and skeptical of algorithmic decision-making based on data at the census tract level, and should set a higher minimum population size where data reliability of all racial/ethnic groups is adequately low for any allocations or programs that might be based on these estimates."
  },
  {
    "objectID": "labs/lab1/scripts/assignment1_kk.html#specific-recommendations",
    "href": "labs/lab1/scripts/assignment1_kk.html#specific-recommendations",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "6.3 Specific Recommendations",
    "text": "6.3 Specific Recommendations\nYour Task: Create a decision framework for algorithm implementation.\n\n# Create a summary table using your county reliability data\n# Include: county name, median income, MOE percentage, reliability category\n\nincome_summary &lt;- mi_county_pop_income %&gt;% select(County_Name, median_household_incomeE, income_moe_percent, income_e_reliability)\n\n# Add a new column with algorithm recommendations using case_when():\n# - High Confidence: \"Safe for algorithmic decisions\"\n# - Moderate Confidence: \"Use with caution - monitor outcomes\"  \n# - Low Confidence: \"Requires manual review or additional data\"\nincome_summary &lt;- income_summary %&gt;%\n  mutate(safe = case_when(\n    income_e_reliability == \"High Confidence\" ~ \"Safe for algorithmic decisions\",\n    income_e_reliability == \"Moderate Confidence\" ~ \"Use with caution - monitor outcomes\",\n    income_e_reliability == \"Low Confidence\" ~ \"Requires manual review or additional data\"\n  ))\n\n# Format as a professional table with kable()\nincome_summary %&gt;%\n  select(County_Name, median_household_incomeE, safe) %&gt;%\n  arrange(median_household_incomeE) %&gt;%\n  kable(\n    col.names = c(\"County Name\", \"Median Household Income\", \"Algorithm Recommendation\"),\n    digit = 0,\n    format.args = list(big.mark = \",\"),\n    align = \"l\",\n    caption = \"Median Income of Michigan Counties by How Safe they are to use for Algorithmic Decision-making\"\n  )\n\n\nMedian Income of Michigan Counties by How Safe they are to use for Algorithmic Decision-making\n\n\n\n\n\n\n\nCounty Name\nMedian Household Income\nAlgorithm Recommendation\n\n\n\n\nLake\n45,946\nUse with caution - monitor outcomes\n\n\nIosco\n46,224\nUse with caution - monitor outcomes\n\n\nMontmorency\n46,345\nUse with caution - monitor outcomes\n\n\nClare\n47,816\nSafe for algorithmic decisions\n\n\nGogebic\n47,913\nUse with caution - monitor outcomes\n\n\nOntonagon\n48,316\nUse with caution - monitor outcomes\n\n\nOscoda\n48,692\nUse with caution - monitor outcomes\n\n\nAlpena\n49,133\nSafe for algorithmic decisions\n\n\nRoscommon\n49,898\nUse with caution - monitor outcomes\n\n\nAlcona\n50,295\nSafe for algorithmic decisions\n\n\nOgemaw\n50,377\nSafe for algorithmic decisions\n\n\nLuce\n51,015\nUse with caution - monitor outcomes\n\n\nBaraga\n51,911\nUse with caution - monitor outcomes\n\n\nIron\n52,241\nUse with caution - monitor outcomes\n\n\nIsabella\n52,638\nSafe for algorithmic decisions\n\n\nHoughton\n52,736\nSafe for algorithmic decisions\n\n\nArenac\n53,487\nSafe for algorithmic decisions\n\n\nGladwin\n53,717\nSafe for algorithmic decisions\n\n\nDelta\n53,852\nUse with caution - monitor outcomes\n\n\nMenominee\n54,074\nUse with caution - monitor outcomes\n\n\nMecosta\n54,132\nUse with caution - monitor outcomes\n\n\nHuron\n54,475\nSafe for algorithmic decisions\n\n\nOsceola\n54,875\nSafe for algorithmic decisions\n\n\nSchoolcraft\n55,071\nRequires manual review or additional data\n\n\nAlger\n55,528\nUse with caution - monitor outcomes\n\n\nKeweenaw\n55,560\nRequires manual review or additional data\n\n\nSanilac\n55,740\nSafe for algorithmic decisions\n\n\nPresque Isle\n55,986\nUse with caution - monitor outcomes\n\n\nKalkaska\n56,380\nUse with caution - monitor outcomes\n\n\nSaginaw\n56,579\nSafe for algorithmic decisions\n\n\nWayne\n57,223\nSafe for algorithmic decisions\n\n\nMissaukee\n57,667\nUse with caution - monitor outcomes\n\n\nBay\n57,887\nSafe for algorithmic decisions\n\n\nGratiot\n57,934\nSafe for algorithmic decisions\n\n\nCrawford\n57,998\nUse with caution - monitor outcomes\n\n\nCalhoun\n58,191\nSafe for algorithmic decisions\n\n\nChippewa\n58,408\nSafe for algorithmic decisions\n\n\nGenesee\n58,594\nSafe for algorithmic decisions\n\n\nWexford\n58,652\nUse with caution - monitor outcomes\n\n\nNewaygo\n59,065\nSafe for algorithmic decisions\n\n\nHillsdale\n59,425\nSafe for algorithmic decisions\n\n\nManistee\n59,467\nSafe for algorithmic decisions\n\n\nCheboygan\n59,557\nSafe for algorithmic decisions\n\n\nDickinson\n59,651\nSafe for algorithmic decisions\n\n\nTuscola\n59,815\nSafe for algorithmic decisions\n\n\nBerrien\n60,379\nSafe for algorithmic decisions\n\n\nBranch\n60,600\nSafe for algorithmic decisions\n\n\nMackinac\n60,620\nUse with caution - monitor outcomes\n\n\nOceana\n60,691\nSafe for algorithmic decisions\n\n\nMason\n60,744\nSafe for algorithmic decisions\n\n\nMontcalm\n61,250\nSafe for algorithmic decisions\n\n\nMuskegon\n61,347\nSafe for algorithmic decisions\n\n\nSt. Joseph\n62,281\nSafe for algorithmic decisions\n\n\nShiawassee\n62,498\nSafe for algorithmic decisions\n\n\nIngham\n62,548\nSafe for algorithmic decisions\n\n\nJackson\n62,581\nSafe for algorithmic decisions\n\n\nOtsego\n62,865\nUse with caution - monitor outcomes\n\n\nMarquette\n63,115\nSafe for algorithmic decisions\n\n\nCass\n65,183\nSafe for algorithmic decisions\n\n\nLenawee\n65,484\nSafe for algorithmic decisions\n\n\nVan Buren\n65,531\nUse with caution - monitor outcomes\n\n\nSt. Clair\n66,887\nSafe for algorithmic decisions\n\n\nKalamazoo\n67,905\nSafe for algorithmic decisions\n\n\nAntrim\n68,850\nSafe for algorithmic decisions\n\n\nEmmet\n69,690\nUse with caution - monitor outcomes\n\n\nCharlevoix\n69,764\nSafe for algorithmic decisions\n\n\nBenzie\n71,327\nUse with caution - monitor outcomes\n\n\nIonia\n71,720\nSafe for algorithmic decisions\n\n\nMonroe\n72,573\nSafe for algorithmic decisions\n\n\nMidland\n73,643\nSafe for algorithmic decisions\n\n\nMacomb\n73,876\nSafe for algorithmic decisions\n\n\nBarry\n75,182\nSafe for algorithmic decisions\n\n\nLapeer\n75,402\nSafe for algorithmic decisions\n\n\nAllegan\n75,543\nSafe for algorithmic decisions\n\n\nGrand Traverse\n75,553\nSafe for algorithmic decisions\n\n\nKent\n76,247\nSafe for algorithmic decisions\n\n\nEaton\n77,158\nSafe for algorithmic decisions\n\n\nLeelanau\n82,345\nUse with caution - monitor outcomes\n\n\nClinton\n82,594\nSafe for algorithmic decisions\n\n\nOttawa\n83,932\nSafe for algorithmic decisions\n\n\nWashtenaw\n84,245\nSafe for algorithmic decisions\n\n\nOakland\n92,620\nSafe for algorithmic decisions\n\n\nLivingston\n96,135\nSafe for algorithmic decisions\n\n\n\n\n\nKey Recommendations:\nYour Task: Use your analysis results to provide specific guidance to the department.\n\nCounties suitable for immediate algorithmic implementation:\n\nThe following counties have reliable median income estimates, because the margin of error of the estimate is less than 5% of the estimate itself:\n1 Alcona\n2 Allegan\n3 Alpena\n4 Antrim\n5 Arenac\n6 Barry\n7 Bay\n8 Berrien\n9 Branch\n10 Calhoun\n11 Cass\n12 Charlevoix\n13 Cheboygan\n14 Chippewa\n15 Clare\n16 Clinton\n17 Dickinson\n18 Eaton\n19 Genesee\n20 Gladwin\n21 Grand Traverse 22 Gratiot\n23 Hillsdale\n24 Houghton\n25 Huron\n26 Ingham\n27 Ionia\n28 Isabella\n29 Jackson\n30 Kalamazoo\n31 Kent\n32 Lapeer\n33 Lenawee\n34 Livingston\n35 Macomb\n36 Manistee\n37 Marquette\n38 Mason\n39 Midland\n40 Monroe\n41 Montcalm\n42 Muskegon\n43 Newaygo\n44 Oakland\n45 Oceana\n46 Ogemaw\n47 Osceola\n48 Ottawa\n49 Saginaw\n50 St. Clair\n51 St. Joseph\n52 Sanilac\n53 Shiawassee\n54 Tuscola\n55 Washtenaw\n56 Wayne\n\nCounties requiring additional oversight:\n\nThe following counties’ median income estimates should be used with caution, given that the margin of error is 5 - 10% of the estimate. Any algorithmic decisions based on these estimates should account for the possibility that the median income is up to 10% higher or lower.\n1 Alger\n2 Baraga\n3 Benzie\n4 Crawford\n5 Delta\n6 Emmet\n7 Gogebic\n8 Iosco\n9 Iron\n10 Kalkaska\n11 Lake\n12 Leelanau\n13 Luce\n14 Mackinac\n15 Mecosta\n16 Menominee\n17 Missaukee\n18 Montmorency 19 Ontonagon\n20 Oscoda\n21 Otsego\n22 Presque Isle 23 Roscommon\n24 Van Buren\n25 Wexford\n\nCounties needing alternative approaches:\n\nThe following counties’ median income estimates are low confidence. No algorithmic decisions should be based on them without manual review or additional surveying to insure that the populations are adequately represented.\n1 Keweenaw\n2 Schoolcraft"
  },
  {
    "objectID": "labs/lab1/scripts/assignment1_kk.html#questions-for-further-investigation",
    "href": "labs/lab1/scripts/assignment1_kk.html#questions-for-further-investigation",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "Questions for Further Investigation",
    "text": "Questions for Further Investigation\nHow come even majority Black census tracts in Kalamazoo have a low confidence estimate compared to a majority White census tract?\nHow racially segregated are census tracts in Michigan in general – i.e. how many tracts are at least 3/4 one race? How does this compare to other states? How does it compare to the past?"
  },
  {
    "objectID": "labs/lab1/scripts/assignment1_kk.html#submission-checklist",
    "href": "labs/lab1/scripts/assignment1_kk.html#submission-checklist",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "Submission Checklist",
    "text": "Submission Checklist\nBefore submitting your portfolio link on Canvas:\n\nAll code chunks run without errors\nAll “[Fill this in]” prompts have been completed\nTables are properly formatted and readable\nExecutive summary addresses all four required components\nPortfolio navigation includes this assignment\nCensus API key is properly set\nDocument renders correctly to HTML\n\nRemember: Submit your portfolio URL on Canvas, not the file itself. Your assignment should be accessible at your-portfolio-url/assignments/assignment_1/your_file_name.html"
  },
  {
    "objectID": "weekly-notes/week-03-notes.html",
    "href": "weekly-notes/week-03-notes.html",
    "title": "Week 3 Notes - Course Introduction",
    "section": "",
    "text": "Main concepts:\nTechnical skills covered:"
  },
  {
    "objectID": "weekly-notes/week-03-notes.html#key-concepts-learned",
    "href": "weekly-notes/week-03-notes.html#key-concepts-learned",
    "title": "Week 3 Notes - Course Introduction",
    "section": "",
    "text": "Main concepts:\nTechnical skills covered:"
  },
  {
    "objectID": "weekly-notes/week-03-notes.html#notes",
    "href": "weekly-notes/week-03-notes.html#notes",
    "title": "Week 3 Notes - Course Introduction",
    "section": "Notes",
    "text": "Notes\n\nData Visualization\n\nAnscombe’s Quartet\n\nJust looking at summary can hide important details about trends in the data – all 4 graphs have the same variances, same correlation, and same regression line … wouldn’t realize how different they are unless looking at the graph\nPolicy Implications - policy decisions made based on misunderstood data\n\n73% of planners don’t warn user about data unreliability – violating ethics arguably\n\nCommon problems in data presentation:\n\nmisleading scales, cherry-picking, missing context\nhiding uncertainty (not communicating MOEs) – verrrryyyyyyy tempting to use census block groups with ACS5 because you can … but MOEs can be quite high at this level\n\n\n\n\n\nggplot2 Philosophy\n\nData -&gt; Aesthetics -&gt; Geometries -&gt; Visual\n\nData = dataset, df or tibble\nAesthetics = what variables map to visual properties\nGeometries = how to display the data (as points? bars? lines?) and how to decorate/stylize\nadditional layers = scales, themes, facets, annotations\n\nSyntax: -g &lt;- ggplot(data = acs_data) = “I would like to make this plot” … if after running this code you ran g, you would just get a black canvas in viewer\n\nAdding aesthetics: g &lt;- ggplot(data = acs_data) + aes(x=income, y=%_bachelor)\nAdding geometries: g &lt;- ggplot(...) + aes(...) + geom_points(decorate...colors...size...)\n\n\n\n\nEDA Mindset\n\nEDA = Exploratory Data Analysis … take the time to get to know your data\n\nLoad and inspect – dimensions, variables types, missing data\nAssess reliability – examine MOEs and calculate coeffs of variation\nvisualize distributions …\n\nFirst steps:\n\nHistogram – distribution of data\nBox plot – finding outliers\n\n\n\n\nJoining tables\n\nLeft join – preserves ‘left’ tables all ids from identifying category, add data from ‘right’ table based on identifying category but will skip mismatched ids\n\nright join is silly…just use left join and switch order\n\nFull join – combined all ids from each tables’ id category\nInner Join – only retain matching ids from each table\nCan join if columns have different names as long as they have matching values, but matching fields must have same data type"
  },
  {
    "objectID": "weekly-notes/week-03-notes.html#coding-techniques",
    "href": "weekly-notes/week-03-notes.html#coding-techniques",
    "title": "Week 3 Notes - Course Introduction",
    "section": "Coding Techniques",
    "text": "Coding Techniques\n\nGood pattern for finding census variables :\n\nfilter(str_detect(field, \"str\"))\nacs_vars_2022 &lt;- load_variables(2022, \"acs5\", cache = TRUE)\nin the load variables table, “concept” column corresponds to tables"
  },
  {
    "objectID": "weekly-notes/week-03-notes.html#questions-challenges",
    "href": "weekly-notes/week-03-notes.html#questions-challenges",
    "title": "Week 3 Notes - Course Introduction",
    "section": "Questions & Challenges",
    "text": "Questions & Challenges"
  },
  {
    "objectID": "weekly-notes/week-03-notes.html#connections-to-policy",
    "href": "weekly-notes/week-03-notes.html#connections-to-policy",
    "title": "Week 3 Notes - Course Introduction",
    "section": "Connections to Policy",
    "text": "Connections to Policy"
  },
  {
    "objectID": "weekly-notes/week-03-notes.html#reflection",
    "href": "weekly-notes/week-03-notes.html#reflection",
    "title": "Week 3 Notes - Course Introduction",
    "section": "Reflection",
    "text": "Reflection"
  },
  {
    "objectID": "labs/lab1/scripts/assignment1_kk.html#given-that-i-chose-three-relatively-low-population-counties-in-a-state-with-a-vary-large-white-majority-the-conclusions-made-about-the-link-between-racial-homogeneity-and-reliability-of-minority-estimates-is-a-limited-conclusion.",
    "href": "labs/lab1/scripts/assignment1_kk.html#given-that-i-chose-three-relatively-low-population-counties-in-a-state-with-a-vary-large-white-majority-the-conclusions-made-about-the-link-between-racial-homogeneity-and-reliability-of-minority-estimates-is-a-limited-conclusion.",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "Given that I chose three relatively low population counties in a state with a vary large White majority, the conclusions made about the link between racial homogeneity and reliability of minority estimates is a limited conclusion.",
    "text": "Given that I chose three relatively low population counties in a state with a vary large White majority, the conclusions made about the link between racial homogeneity and reliability of minority estimates is a limited conclusion."
  }
]